{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5fsltBscbDNdRDb4UefN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/pipelines/blob/main/pipelines_07_pytorch_pipeline_04_imbalanced_data_SMOTEENN_ADASYN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import torch\n",
        "from model_pipeline import load_data_from_url, clean_column_names, remove_id_column, convert_categorical, split_data, SklearnSimpleNN, train_model\n"
      ],
      "metadata": {
        "id": "o6EHTJ6itEj7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Preprocess the Data\n",
        "\n"
      ],
      "metadata": {
        "id": "JH7quCicyXiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset-specific parameters\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "\n",
        "# Load and preprocess data\n",
        "data = load_data_from_url(url)\n",
        "data = clean_column_names(data)\n",
        "data = remove_id_column(data)\n",
        "data = convert_categorical(data, categorical_columns=categorical_columns)\n",
        "X_train, X_test, y_train, y_test = split_data(data, target=target)\n",
        "\n",
        "# Function to convert DataFrames to tensors\n",
        "def convert_to_tensors(X, y):\n",
        "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1)\n",
        "    return X_tensor, y_tensor\n",
        "\n",
        "# Convert test data to tensors\n",
        "X_test_tensor, y_test_tensor = convert_to_tensors(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "99vK7bQbtEfd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function Definitions"
      ],
      "metadata": {
        "id": "0tkUaByhyota"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to apply SMOTEENN\n",
        "def apply_smoteenn(X_train, y_train):\n",
        "    smoteenn = SMOTEENN(random_state=42)\n",
        "    X_train_res, y_train_res = smoteenn.fit_resample(X_train, y_train)\n",
        "    return X_train_res, y_train_res\n",
        "\n",
        "# Function to apply ADASYN\n",
        "def apply_adasyn(X_train, y_train):\n",
        "    adasyn = ADASYN(random_state=42)\n",
        "    X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
        "    return X_train_res, y_train_res\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, pos_weight=1.0):\n",
        "    nn_estimator = SklearnSimpleNN(input_dim=X_train_tensor.shape[1], pos_weight=pos_weight)\n",
        "    nn_estimator = train_model(nn_estimator, X_train_tensor, y_train_tensor)\n",
        "    y_prob = nn_estimator.model(X_test_tensor).detach().numpy().squeeze()\n",
        "    return y_prob\n"
      ],
      "metadata": {
        "id": "X5wQakcVyk2Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate No Resampling"
      ],
      "metadata": {
        "id": "gj5A1mX1yuyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model with the best class weights (3.0) without resampling\n",
        "best_class_weight = 3.0\n",
        "X_train_tensor, y_train_tensor = convert_to_tensors(X_train, y_train)\n",
        "y_prob_no_resampling = evaluate_model(X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, pos_weight=best_class_weight)\n",
        "\n",
        "# Use the best lower threshold (0.10) to predict final labels\n",
        "best_lower_threshold = 0.10\n",
        "y_pred_no_resampling = (y_prob_no_resampling > best_lower_threshold).astype(int)\n",
        "\n",
        "# Evaluate and print final performance\n",
        "report_no_resampling = classification_report(y_test_tensor.numpy(), y_pred_no_resampling, output_dict=True)\n",
        "print(f\"Final Model Performance without Resampling at Best Lower Threshold {best_lower_threshold}:\\n\")\n",
        "print(classification_report(y_test_tensor.numpy(), y_pred_no_resampling))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6zPiSg4ytvY",
        "outputId": "b03a5f97-2dbe-4519-9584-cf01f74af451"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Model Performance without Resampling at Best Lower Threshold 0.1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.70      0.77      4673\n",
            "         1.0       0.36      0.58      0.44      1327\n",
            "\n",
            "    accuracy                           0.68      6000\n",
            "   macro avg       0.61      0.64      0.61      6000\n",
            "weighted avg       0.75      0.68      0.70      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply SMOTEENN"
      ],
      "metadata": {
        "id": "VpgWrjQSt_kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTEENN\n",
        "X_train_smoteenn, y_train_smoteenn = apply_smoteenn(X_train, y_train)\n",
        "X_train_tensor_smoteenn, y_train_tensor_smoteenn = convert_to_tensors(X_train_smoteenn, y_train_smoteenn)\n",
        "\n",
        "# Evaluate SMOTEENN\n",
        "y_prob_smoteenn = evaluate_model(X_train_tensor_smoteenn, y_train_tensor_smoteenn, X_test_tensor, y_test_tensor, pos_weight=best_class_weight)\n",
        "y_pred_smoteenn = (y_prob_smoteenn > best_lower_threshold).astype(int)\n",
        "report_smoteenn = classification_report(y_test_tensor.numpy(), y_pred_smoteenn, output_dict=True)\n",
        "print(f\"Final Model Performance with SMOTEENN at Best Lower Threshold {best_lower_threshold}:\\n\")\n",
        "print(classification_report(y_test_tensor.numpy(), y_pred_smoteenn))\n"
      ],
      "metadata": {
        "id": "S_bp63PztEdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply ADASYN"
      ],
      "metadata": {
        "id": "mx8tupZCuCuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply ADASYN\n",
        "X_train_adasyn, y_train_adasyn = apply_adasyn(X_train, y_train)\n",
        "X_train_tensor_adasyn, y_train_tensor_adasyn = convert_to_tensors(X_train_adasyn, y_train_adasyn)\n",
        "\n",
        "# Evaluate ADASYN\n",
        "y_prob_adasyn = evaluate_model(X_train_tensor_adasyn, y_train_tensor_adasyn, X_test_tensor, y_test_tensor, pos_weight=best_class_weight)\n",
        "y_pred_adasyn = (y_prob_adasyn > best_lower_threshold).astype(int)\n",
        "report_adasyn = classification_report(y_test_tensor.numpy(), y_pred_adasyn, output_dict=True)\n",
        "print(f\"Final Model Performance with ADASYN at Best Lower Threshold {best_lower_threshold}:\\n\")\n",
        "print(classification_report(y_test_tensor.numpy(), y_pred_adasyn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqryutOFtD_b",
        "outputId": "ac7bd5a5-406e-4f0e-f8b2-9b7b351e65b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Model Performance with SMOTEENN at Best Lower Threshold 0.1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.03      0.06      4673\n",
            "         1.0       0.23      0.99      0.37      1327\n",
            "\n",
            "    accuracy                           0.24      6000\n",
            "   macro avg       0.58      0.51      0.21      6000\n",
            "weighted avg       0.78      0.24      0.13      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare Results"
      ],
      "metadata": {
        "id": "z7yqYqw-uRit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert reports to DataFrames\n",
        "df_no_resampling = pd.DataFrame(report_no_resampling).transpose()\n",
        "df_smoteenn = pd.DataFrame(report_smoteenn).transpose()\n",
        "df_adasyn = pd.DataFrame(report_adasyn).transpose()\n",
        "\n",
        "# Add a column to identify the resampling technique\n",
        "df_no_resampling['resampling'] = 'No Resampling'\n",
        "df_smoteenn['resampling'] = 'SMOTEENN'\n",
        "df_adasyn['resampling'] = 'ADASYN'\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "df_comparison = pd.concat([df_no_resampling, df_smoteenn, df_adasyn])\n",
        "\n",
        "# Filter to relevant metrics\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "df_comparison = df_comparison[df_comparison.index.isin(['0.0', '1.0', 'macro avg', 'weighted avg'])][metrics + ['resampling']]\n",
        "\n",
        "# Reset index for easier plotting\n",
        "df_comparison.reset_index(inplace=True)\n",
        "\n",
        "# Plot the comparison\n",
        "def plot_comparison(df, metric):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=df, x='index', y=metric, hue='resampling', palette='viridis')\n",
        "    plt.title(f'Comparison of {metric.capitalize()} by Resampling Technique')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "    plt.legend(title='Resampling')\n",
        "    plt.show()\n",
        "\n",
        "# Plot precision, recall, and f1-score comparisons\n",
        "for metric in metrics:\n",
        "    plot_comparison(df_comparison, metric)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "tarhX_T7uTyO",
        "outputId": "75013eea-5e92-482e-ec07-a34a4e0096ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred_best_threshold' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-75a6084bf150>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert reports to DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreport_no_resampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_best_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_no_resampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_no_resampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_smoteenn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_smoteenn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_adasyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_adasyn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred_best_threshold' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dujmduXvuqme"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}