{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNKd7RqfD0VIe8vF8hjNkO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/pipelines/blob/main/pipelines_07_pytorch_pipeline_11_hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Hyperparameter Tuning\n",
        "\n",
        "#### What are Hyperparameters?\n",
        "\n",
        "In machine learning, hyperparameters are parameters that are set before the learning process begins. They control the behavior of the learning algorithm and influence the model's performance. Unlike model parameters (e.g., weights in a neural network), hyperparameters are not learned from the data during training. Examples of hyperparameters include:\n",
        "\n",
        "- **Learning Rate**: Controls how much to change the model in response to the estimated error each time the model weights are updated.\n",
        "- **Number of Epochs**: The number of complete passes through the training dataset.\n",
        "- **Batch Size**: The number of training examples used in one iteration.\n",
        "- **Network Architecture**: The number of layers and number of neurons per layer in a neural network.\n",
        "- **Regularization Parameters**: Parameters like dropout rate or L2 regularization that help prevent overfitting.\n",
        "\n",
        "#### Why is Hyperparameter Tuning Important?\n",
        "\n",
        "Hyperparameter tuning is crucial because it directly affects the performance and generalizability of a machine learning model. Poorly chosen hyperparameters can lead to:\n",
        "\n",
        "- **Overfitting**: The model performs well on training data but poorly on unseen data.\n",
        "- **Underfitting**: The model is too simple to capture the underlying patterns in the data.\n",
        "- **Slow Convergence**: Training takes longer than necessary due to inefficient learning rates or batch sizes.\n",
        "- **Poor Performance**: The model's overall accuracy, precision, recall, or other metrics are suboptimal.\n",
        "\n",
        "#### Methods for Hyperparameter Tuning\n",
        "\n",
        "1. **Grid Search**:\n",
        "   - **Definition**: An exhaustive search over a specified parameter grid.\n",
        "   - **Process**: Defines a set of hyperparameters and their possible values, then evaluates the model performance for all possible combinations.\n",
        "   - **Advantages**: Simple to understand and implement.\n",
        "   - **Disadvantages**: Computationally expensive, especially for large grids and datasets.\n",
        "\n",
        "2. **Random Search**:\n",
        "   - **Definition**: Randomly samples hyperparameters from a specified distribution.\n",
        "   - **Process**: Defines a range for each hyperparameter and randomly picks combinations to evaluate.\n",
        "   - **Advantages**: Often finds good hyperparameter combinations with less computation than grid search.\n",
        "   - **Disadvantages**: Still may require a significant number of evaluations for large hyperparameter spaces.\n",
        "\n",
        "3. **Bayesian Optimization**:\n",
        "   - **Definition**: Uses probabilistic models to find the optimal hyperparameters.\n",
        "   - **Process**: Builds a probabilistic model of the objective function and uses it to select the most promising hyperparameters to evaluate.\n",
        "   - **Advantages**: Efficient and effective for high-dimensional hyperparameter spaces.\n",
        "   - **Disadvantages**: More complex to implement and understand.\n",
        "\n",
        "4. **Gradient-Based Optimization**:\n",
        "   - **Definition**: Uses gradient information to optimize hyperparameters.\n",
        "   - **Process**: Adjusts hyperparameters based on the gradient of the performance metric with respect to the hyperparameters.\n",
        "   - **Advantages**: Can be very efficient for certain types of models.\n",
        "   - **Disadvantages**: Not applicable to all types of models and hyperparameters.\n",
        "\n",
        "5. **Automated Hyperparameter Tuning Tools**:\n",
        "   - **Examples**: HyperOpt, Optuna, AutoKeras, Auto-sklearn.\n",
        "   - **Advantages**: These tools often combine several advanced techniques to find optimal hyperparameters efficiently.\n",
        "   - **Disadvantages**: May require some setup and understanding of the tool.\n",
        "\n",
        "#### Key Considerations for Hyperparameter Tuning\n",
        "\n",
        "- **Performance Metric**: Choose an appropriate performance metric (e.g., F1 score, accuracy, AUC) that aligns with the business or research goals.\n",
        "- **Computational Resources**: Balance the thoroughness of the search with the available computational resources and time.\n",
        "- **Validation Strategy**: Use cross-validation or a separate validation set to ensure the hyperparameter tuning results generalize well to unseen data.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Hyperparameter tuning is a critical step in the machine learning pipeline that helps optimize model performance and generalizability. By carefully selecting and tuning hyperparameters, you can significantly enhance your model's effectiveness and efficiency."
      ],
      "metadata": {
        "id": "4r4n-Ge2-Tyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Preprocess the Data"
      ],
      "metadata": {
        "id": "j9oaeMSaoaS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import custom modules\n",
        "from data_utils import (\n",
        "    load_data_from_url, clean_column_names, remove_id_column, rename_columns,\n",
        "    convert_categorical, split_data, preprocess_data, define_preprocessor,\n",
        "    calculate_class_weights, convert_to_tensors, load_and_preprocess_data\n",
        ")\n",
        "from model_pipeline import (\n",
        "    apply_feature_engineering,\n",
        "    SklearnSimpleNN, train_model, evaluate_model\n",
        ")\n",
        "from resampling_utils import (\n",
        "    run_resampling_pipeline, reports_to_dataframe, apply_feature_set, plot_metric\n",
        ")\n",
        "from model_evaluation import evaluate_class_weights, class_weights_to_dataframe\n",
        "\n",
        "# Define Global Parameters\n",
        "best_class_weight = 3.0\n",
        "best_lower_threshold = 0.40\n",
        "\n",
        "# Load and Preprocess Data\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']  # Specify your categorical columns\n",
        "target = 'default_payment_next_month'  # Specify your target column\n",
        "\n",
        "data, target = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Apply feature engineering\n",
        "data = apply_feature_engineering(data)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = split_data(data, target=target)\n"
      ],
      "metadata": {
        "id": "v-0s1W4LZeJN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Rate\n",
        "\n",
        "#### What is the Learning Rate?\n",
        "\n",
        "The **learning rate** is a hyperparameter that controls how much to change the model's parameters (e.g., weights) in response to the estimated error each time the model weights are updated. It determines the size of the steps taken during gradient descent optimization.\n",
        "\n",
        "#### Impact of Learning Rate on Training\n",
        "\n",
        "1. **Too High Learning Rate**:\n",
        "   - **Overshooting**: If the learning rate is too high, the optimization process may overshoot the optimal parameters, leading to oscillations or divergence.\n",
        "   - **Unstable Training**: High learning rates can cause the model to become unstable and fail to converge.\n",
        "\n",
        "2. **Too Low Learning Rate**:\n",
        "   - **Slow Convergence**: If the learning rate is too low, the model will update the parameters very slowly, leading to prolonged training times.\n",
        "   - **Local Minima**: Low learning rates may also cause the model to get stuck in local minima, preventing it from finding the global optimum.\n",
        "\n",
        "3. **Optimal Learning Rate**:\n",
        "   - **Efficient Convergence**: An appropriately chosen learning rate will allow the model to converge efficiently to the optimal parameters.\n",
        "   - **Balanced Training**: The right learning rate balances the speed of convergence with the stability of the training process.\n",
        "\n",
        "#### Techniques for Adjusting Learning Rate\n",
        "\n",
        "1. **Learning Rate Schedules**:\n",
        "   - **Fixed Schedule**: Predefined adjustments to the learning rate at specific epochs (e.g., reducing the learning rate by half every 10 epochs).\n",
        "   - **Exponential Decay**: Gradually decreases the learning rate according to an exponential decay function.\n",
        "   - **Step Decay**: Reduces the learning rate by a factor at specific intervals.\n",
        "   - **Piecewise Constant Decay**: Applies different fixed learning rates for different ranges of epochs.\n",
        "\n",
        "2. **Adaptive Learning Rate Methods**:\n",
        "   - **AdaGrad**: Adjusts the learning rate based on the historical gradients.\n",
        "   - **RMSprop**: Uses a moving average of squared gradients to normalize the gradient.\n",
        "   - **Adam**: Combines the ideas of AdaGrad and RMSprop by maintaining a moving average of both the gradients and their squares.\n",
        "\n",
        "#### Practical Tips for Choosing Learning Rate\n",
        "\n",
        "1. **Start with a Range**: Experiment with a range of learning rates (e.g., 0.001, 0.01, 0.1) to find a good starting point.\n",
        "2. **Learning Rate Finder**: Use techniques like learning rate finder, which gradually increases the learning rate during training and plots the loss to identify the optimal range.\n",
        "3. **Monitor Training**: Keep an eye on training and validation loss curves to detect signs of instability (too high) or slow convergence (too low).\n",
        "4. **Adjust Dynamically**: Be prepared to adjust the learning rate dynamically based on the training progress.\n",
        "\n",
        "### Summary\n",
        "\n",
        "The learning rate is a crucial hyperparameter that significantly affects the training process of a machine learning model. Finding the right learning rate involves balancing the speed of convergence with the stability of the training process. By understanding the impact of the learning rate and using appropriate techniques to adjust it, you can improve the efficiency and effectiveness of your model training.\n",
        "\n",
        "Next, we can explore another hyperparameter, such as the number of epochs or batch size. Let me know which one you would like to learn about next!"
      ],
      "metadata": {
        "id": "-TpQhaZ1CngV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and Evaluate Learning Rates"
      ],
      "metadata": {
        "id": "E0Sc6zbWDEGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a range of learning rates\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "\n",
        "# Store the results\n",
        "learning_rate_results = []\n",
        "\n",
        "# Perform cross-validation for each learning rate\n",
        "for lr in learning_rates:\n",
        "    # Define the neural network estimator with the current learning rate\n",
        "    nn_estimator = SklearnSimpleNN(input_dim=X_train.shape[1], learning_rate=lr, pos_weight=best_class_weight, threshold=best_lower_threshold)\n",
        "\n",
        "    # Perform cross-validation\n",
        "    scores = cross_val_score(nn_estimator, X_train, y_train, cv=5, scoring='f1_macro')\n",
        "    mean_score = np.mean(scores)\n",
        "\n",
        "    # Store the results\n",
        "    learning_rate_results.append({'learning_rate': lr, 'f1_macro_mean': mean_score})\n",
        "\n",
        "# Convert results to DataFrame\n",
        "learning_rate_results_df = pd.DataFrame(learning_rate_results)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=learning_rate_results_df, x='learning_rate', y='f1_macro_mean', marker='o')\n",
        "plt.xlabel('Learning Rate')\n",
        "plt.ylabel('Mean F1 Macro Score')\n",
        "plt.title('Learning Rate Tuning')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "jeKgFxGdDDsP",
        "outputId": "47e1e4ed-0309-4b9a-f58e-b7ccd2721a5a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SklearnSimpleNN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-36b79b208866>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Define the neural network estimator with the current learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnn_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSklearnSimpleNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_lower_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Perform cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SklearnSimpleNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2gQrTYLDDpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9wtSQCoDDmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R4D1-XwMDDj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write Data Utils Script"
      ],
      "metadata": {
        "id": "MBB9RHMLD2Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to write script\n",
        "script_content = \"\"\"\n",
        "# data_utils.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Load the dataset from a URL\n",
        "def load_data_from_url(url):\n",
        "    df = pd.read_excel(url, header=1)\n",
        "    return df\n",
        "\n",
        "# Clean column names\n",
        "def clean_column_names(df):\n",
        "    df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
        "    return df\n",
        "\n",
        "# Remove the 'id' column\n",
        "def remove_id_column(df):\n",
        "    if 'id' in df.columns:\n",
        "        df = df.drop(columns=['id'])\n",
        "    return df\n",
        "\n",
        "# Rename columns (pay_0 not in dataset)\n",
        "def rename_columns(df):\n",
        "    rename_dict = {\n",
        "        'pay_0': 'pay_1'\n",
        "    }\n",
        "    df = df.rename(columns=rename_dict)\n",
        "    return df\n",
        "\n",
        "# Convert specified columns to categorical type\n",
        "def convert_categorical(df, categorical_columns):\n",
        "    df[categorical_columns] = df[categorical_columns].astype('category')\n",
        "    return df\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "def split_data(df, target):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Define the preprocessor\n",
        "def define_preprocessor(X_train):\n",
        "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "    return preprocessor\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(preprocessor, X_train, X_test):\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "    X_test_processed = preprocessor.transform(X_test)\n",
        "    return X_train_processed, X_test_processed\n",
        "\n",
        "# Calculate class weights for imbalanced datasets\n",
        "def calculate_class_weights(y_train):\n",
        "    return len(y_train) / (2 * np.bincount(y_train))\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "def convert_to_tensors(X_train_processed, y_train, X_test_processed, y_test):\n",
        "    X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
        "    X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
        "    return X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor\n",
        "\n",
        "# Load and Preprocess Data\n",
        "def load_and_preprocess_data(url, categorical_columns, target):\n",
        "    data = load_data_from_url(url)\n",
        "    data = clean_column_names(data)\n",
        "    data = rename_columns(data)\n",
        "    data = remove_id_column(data)\n",
        "    data = convert_categorical(data, categorical_columns=categorical_columns)\n",
        "    return data, target\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the script to a file\n",
        "with open(\"data_utils.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Script successfully written to data_utils.py\")\n",
        "\n",
        "# reload script to make function available for use\n",
        "import importlib\n",
        "import data_utils\n",
        "importlib.reload(data_utils)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3swQoFBV44A",
        "outputId": "4d0910de-f290-49a0-9727-caecd3592946"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script successfully written to data_utils.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'data_utils' from '/content/data_utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write Model Definition Script"
      ],
      "metadata": {
        "id": "OK5EVLIRXBTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_content = \"\"\"\n",
        "# model_definition.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32)\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class SklearnSimpleNN(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_dim, learning_rate=0.001, epochs=50, batch_size=64,\n",
        "                 pos_weight=1.0, threshold=0.5):\n",
        "        self.input_dim = input_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.pos_weight = pos_weight\n",
        "        self.threshold = threshold\n",
        "        self.model = SimpleNN(self.input_dim)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.pos_weight, dtype=torch.float32))\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        train_dataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32).unsqueeze(1))\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            self.model.train()\n",
        "            for inputs, targets in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = criterion(outputs, targets.view(-1, 1))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            if isinstance(X, np.ndarray):\n",
        "                X = torch.tensor(X, dtype=torch.float32)\n",
        "            elif isinstance(X, pd.DataFrame):\n",
        "                X = torch.tensor(X.values, dtype=torch.float32)\n",
        "            outputs = self.model(X)\n",
        "            probabilities = torch.sigmoid(outputs)\n",
        "            predictions = (probabilities > self.threshold).float()\n",
        "        return predictions.numpy().squeeze()\n",
        "\"\"\"\n",
        "\n",
        "# Write the script to a file\n",
        "with open(\"model_definition.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Script successfully written to model_definition.py\")\n",
        "\n",
        "# reload script to make function available for use\n",
        "import importlib\n",
        "import model_definition\n",
        "importlib.reload(model_definition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnklWBmuXFhe",
        "outputId": "77c90e12-6855-4f3f-ca49-b4ffd7ea97b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script successfully written to model_definition.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'model_definition' from '/content/model_definition.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write Feature Engineering Script"
      ],
      "metadata": {
        "id": "nycDA-vH9jZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_content = \"\"\"\n",
        "# feature_engineering.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from data_utils import split_data, preprocess_data, define_preprocessor, convert_to_tensors\n",
        "\n",
        "# Apply feature engineering to the entire dataset\n",
        "def create_interaction_features(df):\n",
        "    df['limit_bal_age'] = df['limit_bal'] * df['age']\n",
        "    return df\n",
        "\n",
        "def target_encode(df, target, categorical_columns):\n",
        "    for col in categorical_columns:\n",
        "        mean_target = df.groupby(col)[target].mean()\n",
        "        df[col + '_target_enc'] = df[col].map(mean_target)\n",
        "    return df\n",
        "\n",
        "def bin_features(df, column, bins):\n",
        "    df[column + '_binned'] = pd.cut(df[column], bins=bins)\n",
        "    return df\n",
        "\n",
        "def create_payment_to_bill_ratios(df):\n",
        "    for i in range(1, 7):\n",
        "        df[f'pay_to_bill_ratio_{i}'] = df[f'pay_amt{i}'] / df[f'bill_amt{i}'].replace(0, np.nan)\n",
        "    return df\n",
        "\n",
        "def create_payment_to_limit_ratios(df):\n",
        "    for i in range(1, 7):\n",
        "        df[f'pay_to_limit_ratio_{i}'] = df[f'pay_amt{i}'] / df['limit_bal']\n",
        "    return df\n",
        "\n",
        "def create_bill_to_limit_ratios(df):\n",
        "    for i in range(1, 7):\n",
        "        df[f'bill_to_limit_ratio_{i}'] = df[f'bill_amt{i}'] / df['limit_bal']\n",
        "    return df\n",
        "\n",
        "def create_lagged_payment_differences(df):\n",
        "    for i in range(1, 6):\n",
        "        df[f'pay_amt_diff_{i}'] = df[f'pay_amt{i+1}'] - df[f'pay_amt{i}']\n",
        "    return df\n",
        "\n",
        "def create_debt_ratio_features(df):\n",
        "    for i in range(1, 7):\n",
        "        df[f'debt_ratio_{i}'] = df[f'bill_amt{i}'] / df['limit_bal']\n",
        "    return df\n",
        "\n",
        "def create_average_payment_and_bill(df):\n",
        "    df['avg_payment'] = df[[f'pay_amt{i}' for i in range(1, 7)]].mean(axis=1)\n",
        "    df['avg_bill'] = df[[f'bill_amt{i}' for i in range(1, 7)]].mean(axis=1)\n",
        "    return df\n",
        "\n",
        "def create_payment_timeliness_features(df):\n",
        "    for i in range(1, 7):\n",
        "        df[f'pay_on_time_{i}'] = (df[f'pay_{i}'] <= 0).astype(int)\n",
        "    return df\n",
        "\n",
        "def create_total_payment_and_bill(df):\n",
        "    df['total_payment'] = df[[f'pay_amt{i}' for i in range(1, 7)]].sum(axis=1)\n",
        "    df['total_bill'] = df[[f'bill_amt{i}' for i in range(1, 7)]].sum(axis=1)\n",
        "    return df\n",
        "\n",
        "def create_bill_difference_features(df):\n",
        "    for i in range(1, 6):\n",
        "        df[f'bill_diff_{i}'] = df[f'bill_amt{i+1}'] - df[f'bill_amt{i}']\n",
        "    return df\n",
        "\n",
        "# Incrementally Add Features and Evaluate\n",
        "def add_features_incrementally(data, features_to_add, target, pos_weight, threshold):\n",
        "    from model_pipeline import SklearnSimpleNN, train_model, evaluate_model\n",
        "    results = []\n",
        "\n",
        "    for feature in features_to_add:\n",
        "        # Create a copy of the data to avoid modifying the original DataFrame\n",
        "        data_copy = data.copy()\n",
        "\n",
        "        # Apply the feature engineering function\n",
        "        print(f\"Adding feature: {feature['name']}\")\n",
        "        data_copy = feature['func'](data_copy)\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = split_data(data_copy, target=target)\n",
        "\n",
        "        # Preprocess the data\n",
        "        preprocessor = define_preprocessor(X_train)\n",
        "        X_train_processed, X_test_processed = preprocess_data(preprocessor, X_train, X_test)\n",
        "\n",
        "        # Convert data to tensors\n",
        "        X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = convert_to_tensors(X_train_processed, y_train, X_test_processed, y_test)\n",
        "\n",
        "        # Train the model\n",
        "        nn_estimator = SklearnSimpleNN(input_dim=X_train_tensor.shape[1], pos_weight=pos_weight, threshold=threshold)\n",
        "        nn_estimator = train_model(nn_estimator, X_train_tensor, y_train_tensor)\n",
        "\n",
        "        # Evaluate the model\n",
        "        report = evaluate_model(nn_estimator, X_test_tensor, y_test_tensor, label=feature['name'])\n",
        "        results.append({'feature': feature['name'], 'report': report})\n",
        "\n",
        "    return results\n",
        "\n",
        "def compare_classification_reports(report_before, report_after):\n",
        "    # Convert reports to DataFrame\n",
        "    report_before_df = pd.DataFrame(report_before).transpose()\n",
        "    report_after_df = pd.DataFrame(report_after).transpose()\n",
        "\n",
        "    # Merge reports\n",
        "    comparison_df = report_before_df.join(report_after_df, lsuffix='_before', rsuffix='_after')\n",
        "\n",
        "    # Calculate percentage change\n",
        "    comparison_df['precision_change'] = (comparison_df['precision_after'] - comparison_df['precision_before']) / comparison_df['precision_before'] * 100\n",
        "    comparison_df['recall_change'] = (comparison_df['recall_after'] - comparison_df['recall_before']) / comparison_df['recall_before'] * 100\n",
        "    comparison_df['f1-score_change'] = (comparison_df['f1-score_after'] - comparison_df['f1-score_before']) / comparison_df['f1-score_before'] * 100\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "def compare_incremental_reports(report_baseline, incremental_results):\n",
        "    # Convert the baseline report to DataFrame\n",
        "    report_baseline_df = pd.DataFrame(report_baseline).transpose()\n",
        "\n",
        "    # Initialize a list to store comparison results\n",
        "    all_comparisons = []\n",
        "\n",
        "    # Iterate through the incremental results\n",
        "    for result in incremental_results:\n",
        "        report_after = result['report']\n",
        "        feature_name = result['feature']\n",
        "\n",
        "        # Convert the current report to DataFrame\n",
        "        report_after_df = pd.DataFrame(report_after).transpose()\n",
        "\n",
        "        # Merge the baseline and current reports\n",
        "        comparison_df = report_baseline_df.join(report_after_df, lsuffix='_baseline', rsuffix=f'_{feature_name}')\n",
        "\n",
        "        # Calculate percentage change\n",
        "        comparison_df[f'precision_change_{feature_name}'] = (comparison_df[f'precision_{feature_name}'] - comparison_df['precision_baseline']) / comparison_df['precision_baseline'] * 100\n",
        "        comparison_df[f'recall_change_{feature_name}'] = (comparison_df[f'recall_{feature_name}'] - comparison_df['recall_baseline']) / comparison_df['recall_baseline'] * 100\n",
        "        comparison_df[f'f1-score_change_{feature_name}'] = (comparison_df[f'f1-score_{feature_name}'] - comparison_df['f1-score_baseline']) / comparison_df['f1-score_baseline'] * 100\n",
        "\n",
        "        # Add the comparison result to the list\n",
        "        all_comparisons.append(comparison_df)\n",
        "\n",
        "    # Concatenate all comparison DataFrames\n",
        "    all_comparisons_df = pd.concat(all_comparisons, axis=1)\n",
        "\n",
        "    return all_comparisons_df\n",
        "\n",
        "def plot_metric_changes(all_comparisons_df, metric):\n",
        "    # Extract percentage change columns for the specified metric\n",
        "    change_cols = [col for col in all_comparisons_df.columns if col.startswith(f'{metric}_change')]\n",
        "\n",
        "    # Extract feature names from the column headers\n",
        "    feature_names = [col.split('_')[-1] for col in change_cols]\n",
        "\n",
        "    # Plot the percentage changes\n",
        "    changes = all_comparisons_df.loc[:, change_cols].iloc[0]  # assuming we want the changes for the first class (or overall if it's a macro/micro average)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(feature_names, changes, color='skyblue')\n",
        "    plt.axvline(x=0, color='gray', linestyle='--')  # Add vertical line at 0\n",
        "    plt.xlabel('Percentage Change')\n",
        "    plt.title(f'Percentage Change in {metric.capitalize()} After Adding Each Feature')\n",
        "    plt.grid(axis='x')\n",
        "    plt.show()\n",
        "\n",
        "# Define a function to extract the metrics and convert to DataFrame\n",
        "def results_to_dataframe(incremental_results):\n",
        "    # List to hold the structured data\n",
        "    data = []\n",
        "\n",
        "    # Iterate over the results\n",
        "    for result in incremental_results:\n",
        "        feature_name = result['feature']\n",
        "        report = result['report']\n",
        "\n",
        "        # Initialize a dictionary to hold the flattened report\n",
        "        flattened_report = {'feature': feature_name}\n",
        "\n",
        "        # Flatten the report dictionary\n",
        "        for key, subdict in report.items():\n",
        "            if isinstance(subdict, dict):\n",
        "                for subkey, value in subdict.items():\n",
        "                    flattened_report[f\"{key}_{subkey}\"] = value\n",
        "            else:\n",
        "                flattened_report[key] = subdict\n",
        "\n",
        "        # Append the flattened report to the data list\n",
        "        data.append(flattened_report)\n",
        "\n",
        "    # Convert the data list to a DataFrame\n",
        "    results_df = pd.DataFrame(data)\n",
        "\n",
        "    return results_df\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the functions to feature_engineering.py script\n",
        "with open(\"feature_engineering.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Functions successfully written to feature_engineering.py\")\n",
        "\n",
        "# reload script to make function available for use\n",
        "import importlib\n",
        "import feature_engineering\n",
        "importlib.reload(feature_engineering)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i2VXSArPcwt",
        "outputId": "71327130-bfee-40fc-ee31-fe53340c9540"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions successfully written to feature_engineering.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'feature_engineering' from '/content/feature_engineering.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write Pipeline Script"
      ],
      "metadata": {
        "id": "JUjGgjt1pHpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_content = \"\"\"\n",
        "# model_pipeline.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from data_utils import (\n",
        "    load_data_from_url, clean_column_names, remove_id_column, rename_columns,\n",
        "    convert_categorical, split_data, preprocess_data, define_preprocessor,\n",
        "    calculate_class_weights, convert_to_tensors\n",
        ")\n",
        "from model_definition import SklearnSimpleNN\n",
        "from feature_engineering import (\n",
        "    create_bill_to_limit_ratios, create_payment_to_limit_ratios,\n",
        "    create_payment_timeliness_features, create_lagged_payment_differences\n",
        ")\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Apply feature engineering\n",
        "def apply_feature_engineering(data):\n",
        "    data = create_bill_to_limit_ratios(data)\n",
        "    data = create_payment_to_limit_ratios(data)\n",
        "    data = create_payment_timeliness_features(data)\n",
        "    data = create_lagged_payment_differences(data)\n",
        "    return data\n",
        "\n",
        "# Train the Model\n",
        "def train_model(nn_estimator, X_train_tensor, y_train_tensor):\n",
        "    nn_estimator.fit(X_train_tensor.numpy(), y_train_tensor.numpy())\n",
        "    return nn_estimator\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(nn_estimator, X_test_tensor, y_test_tensor, label=\"\"):\n",
        "    y_pred = nn_estimator.predict(X_test_tensor.numpy())\n",
        "    report = classification_report(y_test_tensor.numpy(), y_pred, output_dict=True)\n",
        "    print(f\"Classification Report ({label}):\")\n",
        "    print(classification_report(y_test_tensor.numpy(), y_pred))\n",
        "    return report\n",
        "\n",
        "# Function to run the full pipeline with resampling\n",
        "def run_full_pipeline_with_resampling(url, categorical_columns, target, resampling_method=None):\n",
        "    data = load_data_from_url(url)\n",
        "    data = clean_column_names(data)\n",
        "    data = rename_columns(data)\n",
        "    data = remove_id_column(data)\n",
        "    data = convert_categorical(data, categorical_columns=categorical_columns)\n",
        "    X_train, X_test, y_train, y_test = split_data(data, target=target)\n",
        "    preprocessor = define_preprocessor(X_train)\n",
        "\n",
        "    if resampling_method:\n",
        "        resampling_pipeline = ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', resampling_method)\n",
        "        ])\n",
        "        X_train_processed, y_train = resampling_pipeline.fit_resample(X_train, y_train)\n",
        "        X_test_processed = preprocessor.transform(X_test)\n",
        "    else:\n",
        "        X_train_processed, X_test_processed = preprocess_data(preprocessor, X_train, X_test)\n",
        "\n",
        "    class_weights = calculate_class_weights(y_train)\n",
        "\n",
        "    X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = convert_to_tensors(\n",
        "        X_train_processed, y_train, X_test_processed, y_test)\n",
        "\n",
        "    nn_estimator = SklearnSimpleNN(input_dim=X_train_tensor.shape[1], pos_weight=class_weights[1])\n",
        "    nn_estimator = train_model(nn_estimator, X_train_tensor, y_train_tensor)\n",
        "    evaluate_model(nn_estimator, X_test_tensor, y_test_tensor)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Run full pipeline with resampling\")\n",
        "    parser.add_argument(\"url\", type=str, help=\"URL of the dataset\")\n",
        "    parser.add_argument(\"categorical_columns\", type=str, nargs=\"+\", help=\"List of categorical columns\")\n",
        "    parser.add_argument(\"target\", type=str, help=\"Target column\")\n",
        "    parser.add_argument(\"--resampling\", type=str, choices=['smote', 'oversample', 'undersample'], help=\"Resampling method\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.resampling == 'smote':\n",
        "        resampling_method = SMOTE(random_state=42)\n",
        "    elif args.resampling == 'oversample':\n",
        "        resampling_method = RandomOverSampler(random_state=42)\n",
        "    elif args.resampling == 'undersample':\n",
        "        resampling_method = RandomUnderSampler(random_state=42)\n",
        "    else:\n",
        "        resampling_method = None\n",
        "\n",
        "    run_full_pipeline_with_resampling(args.url, args.categorical_columns, args.target, resampling_method)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the script to a file\n",
        "with open(\"model_pipeline.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Script successfully written to model_pipeline.py\")\n",
        "\n",
        "# reload script to make function available for use\n",
        "import importlib\n",
        "import model_pipeline\n",
        "importlib.reload(model_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk5WLcUKXkEL",
        "outputId": "20f07eea-7fb0-4088-ad9a-3a0d8871365e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script successfully written to model_pipeline.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'model_pipeline' from '/content/model_pipeline.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write Resampling Script"
      ],
      "metadata": {
        "id": "ItzeqPN_oJln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_content = \"\"\"\n",
        "# resampling_utils.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from model_pipeline import (\n",
        "    split_data, define_preprocessor, preprocess_data,\n",
        "    convert_to_tensors, SklearnSimpleNN, train_model, evaluate_model\n",
        ")\n",
        "from feature_engineering import (\n",
        "    create_bill_to_limit_ratios, create_payment_to_limit_ratios,\n",
        "    create_payment_timeliness_features, create_lagged_payment_differences\n",
        ")\n",
        "\n",
        "def run_resampling_pipeline(data, target, resampling_method=None, pos_weight=1.0, threshold=0.5):\n",
        "    X_train, X_test, y_train, y_test = split_data(data, target=target)\n",
        "    preprocessor = define_preprocessor(X_train)\n",
        "\n",
        "    if resampling_method:\n",
        "        resampling_pipeline = ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', resampling_method)\n",
        "        ])\n",
        "        X_train_processed, y_train = resampling_pipeline.fit_resample(X_train, y_train)\n",
        "        X_test_processed = preprocessor.transform(X_test)\n",
        "    else:\n",
        "        X_train_processed, X_test_processed = preprocess_data(preprocessor, X_train, X_test)\n",
        "\n",
        "    X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = convert_to_tensors(\n",
        "        X_train_processed, y_train, X_test_processed, y_test)\n",
        "\n",
        "    nn_estimator = SklearnSimpleNN(input_dim=X_train_tensor.shape[1], pos_weight=pos_weight, threshold=threshold)\n",
        "    nn_estimator = train_model(nn_estimator, X_train_tensor, y_train_tensor)\n",
        "    report = evaluate_model(nn_estimator, X_test_tensor, y_test_tensor, label=str(resampling_method))\n",
        "    return report\n",
        "\n",
        "def reports_to_dataframe(reports):\n",
        "    data = []\n",
        "    for method, report in reports.items():\n",
        "        flattened_report = {'method': method}\n",
        "        for key, subdict in report.items():\n",
        "            if isinstance(subdict, dict):\n",
        "                for subkey, value in subdict.items():\n",
        "                    flattened_report[f\"{key}_{subkey}\"] = value\n",
        "            else:\n",
        "                flattened_report[key] = subdict\n",
        "        data.append(flattened_report)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def apply_feature_set(data, feature_set):\n",
        "    if 'bill_to_limit_ratios' in feature_set:\n",
        "        data = create_bill_to_limit_ratios(data)\n",
        "    if 'pay_to_limit_ratios' in feature_set:\n",
        "        data = create_payment_to_limit_ratios(data)\n",
        "    if 'payment_timeliness_features' in feature_set:\n",
        "        data = create_payment_timeliness_features(data)\n",
        "    if 'lagged_payment_differences' in feature_set:\n",
        "        data = create_lagged_payment_differences(data)\n",
        "    return data\n",
        "\n",
        "def plot_metric(df, metric, title, ylabel):\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    sns.barplot(x='method', y=metric, hue='feature_set', data=df, palette='viridis')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Resampling Method')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend(title='Feature Set')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the script to a file\n",
        "with open(\"resampling_utils.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Functions successfully written to resampling_utils.py\")\n",
        "\n",
        "# Reload the script to make the functions available for use\n",
        "import importlib\n",
        "import resampling_utils\n",
        "importlib.reload(resampling_utils)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oA9sLXgZLdG",
        "outputId": "15ccb8a3-c2a6-4c44-893f-0800f60cbc75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions successfully written to resampling_utils.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'resampling_utils' from '/content/resampling_utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write Model Evaluation Script"
      ],
      "metadata": {
        "id": "VgbA9u_a8e_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_content = \"\"\"\n",
        "# model_evaluation.py\n",
        "\n",
        "import pandas as pd\n",
        "from model_pipeline import (\n",
        "    split_data, define_preprocessor, preprocess_data,\n",
        "    convert_to_tensors, SklearnSimpleNN, train_model, evaluate_model\n",
        ")\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "def evaluate_thresholds(data, target, thresholds, resampling_method=None, pos_weight=1.0):\n",
        "    X_train, X_test, y_train, y_test = split_data(data, target=target)\n",
        "    preprocessor = define_preprocessor(X_train)\n",
        "\n",
        "    if resampling_method:\n",
        "        resampling_pipeline = ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', resampling_method)\n",
        "        ])\n",
        "        X_train_processed, y_train = resampling_pipeline.fit_resample(X_train, y_train)\n",
        "        X_test_processed = preprocessor.transform(X_test)\n",
        "    else:\n",
        "        X_train_processed, X_test_processed = preprocess_data(preprocessor, X_train, X_test)\n",
        "\n",
        "    X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = convert_to_tensors(\n",
        "        X_train_processed, y_train, X_test_processed, y_test)\n",
        "\n",
        "    results = []\n",
        "    for threshold in thresholds:\n",
        "        nn_estimator = SklearnSimpleNN(input_dim=X_train_tensor.shape[1], pos_weight=pos_weight, threshold=threshold)\n",
        "        nn_estimator = train_model(nn_estimator, X_train_tensor, y_train_tensor)\n",
        "        report = evaluate_model(nn_estimator, X_test_tensor, y_test_tensor, label=f\"Threshold {threshold}\")\n",
        "        results.append({'threshold': threshold, 'report': report})\n",
        "\n",
        "    return results\n",
        "\n",
        "def thresholds_to_dataframe(results):\n",
        "    data = []\n",
        "    for result in results:\n",
        "        threshold = result['threshold']\n",
        "        report = result['report']\n",
        "        flattened_report = {'threshold': threshold}\n",
        "        for key, subdict in report.items():\n",
        "            if isinstance(subdict, dict):\n",
        "                for subkey, value in subdict.items():\n",
        "                    flattened_report[f\"{key}_{subkey}\"] = value\n",
        "            else:\n",
        "                flattened_report[key] = subdict\n",
        "        data.append(flattened_report)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def evaluate_class_weights(data, target, class_weights, threshold=0.5, resampling_method=None):\n",
        "    X_train, X_test, y_train, y_test = split_data(data, target=target)\n",
        "    preprocessor = define_preprocessor(X_train)\n",
        "\n",
        "    if resampling_method:\n",
        "        resampling_pipeline = ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', resampling_method)\n",
        "        ])\n",
        "        X_train_processed, y_train = resampling_pipeline.fit_resample(X_train, y_train)\n",
        "        X_test_processed = preprocessor.transform(X_test)\n",
        "    else:\n",
        "        X_train_processed, X_test_processed = preprocess_data(preprocessor, X_train, X_test)\n",
        "\n",
        "    X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor = convert_to_tensors(\n",
        "        X_train_processed, y_train, X_test_processed, y_test)\n",
        "\n",
        "    results = []\n",
        "    for weight in class_weights:\n",
        "        nn_estimator = SklearnSimpleNN(input_dim=X_train_tensor.shape[1], pos_weight=weight, threshold=threshold)\n",
        "        nn_estimator = train_model(nn_estimator, X_train_tensor, y_train_tensor)\n",
        "        report = evaluate_model(nn_estimator, X_test_tensor, y_test_tensor, label=f\"Class Weight {weight}\")\n",
        "        results.append({'class_weight': weight, 'report': report})\n",
        "\n",
        "    return results\n",
        "\n",
        "def class_weights_to_dataframe(results):\n",
        "    data = []\n",
        "    for result in results:\n",
        "        class_weight = result['class_weight']\n",
        "        report = result['report']\n",
        "        flattened_report = {'class_weight': class_weight}\n",
        "        for key, subdict in report.items():\n",
        "            if isinstance(subdict, dict):\n",
        "                for subkey, value in subdict.items():\n",
        "                    flattened_report[f\"{key}_{subkey}\"] = value\n",
        "            else:\n",
        "                flattened_report[key] = subdict\n",
        "        data.append(flattened_report)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write the script to a file\n",
        "with open(\"model_evaluation.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Script successfully written to model_evaluation.py\")\n",
        "\n",
        "# reload script to make function available for use\n",
        "import importlib\n",
        "import model_evaluation\n",
        "importlib.reload(model_evaluation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odvzuctjYnNz",
        "outputId": "0956f9be-0e42-42f9-a9be-a1a33a009a57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script successfully written to model_evaluation.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'model_evaluation' from '/content/model_evaluation.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkYBBMX0Dq7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}