{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcThXz82Y1ELJBgw2aX+20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/pipelines/blob/main/pipelines_09_class_imbalance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load & Preprocess Data"
      ],
      "metadata": {
        "id": "zx22VkQVFcIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K1RxZ4t4mHI",
        "outputId": "6c2302ff-37fb-4740-fcb0-3fafbdb01d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing pipeline created successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from data_utils import (load_data_from_url, clean_column_names, remove_id_column,\n",
        "                        rename_columns, convert_categorical, preprocess_data, split_data, plot_class_distribution,\n",
        "                        create_preprocessing_pipeline, add_model_to_pipeline, evaluate_model,\n",
        "                        hyperparameter_tuning)\n",
        "\n",
        "# Define your parameters\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "\n",
        "\n",
        "# Load and Preprocess Data\n",
        "data = preprocess_data(url, categorical_columns)\n",
        "\n",
        "# Check if data is loaded and preprocessed correctly\n",
        "if data is not None:\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = split_data(data, target=target)\n",
        "\n",
        "    # Define preprocessing steps for numerical and categorical columns\n",
        "    numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "    # Create preprocessing pipeline\n",
        "    pipeline = create_preprocessing_pipeline(numeric_features, categorical_features)\n",
        "else:\n",
        "    print(\"Data preprocessing failed. Please check the URL and preprocessing steps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Imbalance"
      ],
      "metadata": {
        "id": "FPyqgeu8Xt7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_class_distribution(y_train, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "y1bjS1pbc-WL",
        "outputId": "ad7f7de6-e3bd-41d0-f179-c1a6ae17851d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### evaluate model dictioonary of classifcation report"
      ],
      "metadata": {
        "id": "Bw-JTwVUZ6vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "# import pandas as pd\n",
        "\n",
        "# # def get_classification_report(y_true, y_pred, model_name):\n",
        "# #     report = classification_report(y_true, y_pred, output_dict=True)\n",
        "# #     df = pd.DataFrame(report).transpose()\n",
        "# #     df['model'] = model_name\n",
        "# #     return df\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "# import pandas as pd\n",
        "\n",
        "# # def get_classification_report(y_true, y_pred, model_name):\n",
        "# #     # Generate the classification report as a dictionary\n",
        "# #     report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "# #     # Convert the dictionary to a DataFrame\n",
        "# #     df = pd.DataFrame(report_dict).transpose()\n",
        "# #     df['model'] = model_name\n",
        "\n",
        "# #     # Print the classification report\n",
        "# #     print(f\"Classification Report for {model_name}:\\n\")\n",
        "# #     print(classification_report(y_true, y_pred))\n",
        "\n",
        "# #     return df\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# def get_classification_report_dict(y_true, y_pred, model_name):\n",
        "#     \"\"\"\n",
        "#     Generate the classification report as a dictionary.\n",
        "\n",
        "#     Parameters:\n",
        "#     - y_true: array-like, true labels\n",
        "#     - y_pred: array-like, predicted labels\n",
        "#     - model_name: str, name of the model\n",
        "\n",
        "#     Returns:\n",
        "#     - dict, classification report dictionary\n",
        "#     \"\"\"\n",
        "#     report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "#     # Print the classification report\n",
        "#     print(f\"Classification Report for {model_name}:\\n\")\n",
        "#     print(classification_report(y_true, y_pred))\n",
        "\n",
        "#     return report_dict\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# def extract_key_metrics_from_report(report_dict, model_name):\n",
        "#     \"\"\"\n",
        "#     Extract key metrics from the classification report dictionary.\n",
        "\n",
        "#     Parameters:\n",
        "#     - report_dict: dict, classification report dictionary\n",
        "#     - model_name: str, name of the model\n",
        "\n",
        "#     Returns:\n",
        "#     - pd.DataFrame, DataFrame with the selected metrics\n",
        "#     \"\"\"\n",
        "#     # Define the metrics and classes you want to focus on\n",
        "#     desired_metrics = ['recall', 'f1-score']\n",
        "#     desired_classes = ['0', '1', 'macro avg']\n",
        "\n",
        "#     # Extract the metrics\n",
        "#     metrics_data = {\n",
        "#         'model': model_name,\n",
        "#         'recall_0': report_dict['0']['recall'],\n",
        "#         'recall_1': report_dict['1']['recall'],\n",
        "#         'f1_score_0': report_dict['0']['f1-score'],\n",
        "#         'f1_score_1': report_dict['1']['f1-score'],\n",
        "#         'macro_avg_recall': report_dict['macro avg']['recall'],\n",
        "#         'macro_avg_f1_score': report_dict['macro avg']['f1-score']\n",
        "#     }\n",
        "\n",
        "#     return pd.DataFrame([metrics_data])\n",
        "\n",
        "# # Example usage\n",
        "# y_true = [0, 1, 0, 1, 0, 1, 1, 1]  # Example true labels\n",
        "# y_pred = [0, 0, 0, 1, 0, 1, 0, 1]  # Example predicted labels\n",
        "# model_name = \"Example Model\"\n",
        "\n",
        "# # Get the classification report dictionary\n",
        "# report_dict = get_classification_report_dict(y_true, y_pred, model_name)\n",
        "\n",
        "# # Extract key metrics and convert to DataFrame\n",
        "# key_metrics_df = extract_key_metrics_from_report(report_dict, model_name)\n",
        "# print(key_metrics_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMtRxrjfRbBy",
        "outputId": "a2758d5e-c00d-40c8-8c33-16f8d748a656"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Example Model:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75         3\n",
            "           1       1.00      0.60      0.75         5\n",
            "\n",
            "    accuracy                           0.75         8\n",
            "   macro avg       0.80      0.80      0.75         8\n",
            "weighted avg       0.85      0.75      0.75         8\n",
            "\n",
            "           model  recall_0  recall_1  f1_score_0  f1_score_1  \\\n",
            "0  Example Model       1.0       0.6        0.75        0.75   \n",
            "\n",
            "   macro_avg_recall  macro_avg_f1_score  \n",
            "0               0.8                0.75  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the key metrics and classes you want to focus on\n",
        "desired_metrics = ['recall', 'f1-score']\n",
        "desired_classes = ['0', '1', 'macro avg']\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    \"\"\"\n",
        "    Evaluate the model and return the classification report as a dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true: array-like, true labels\n",
        "    - y_pred: array-like, predicted labels\n",
        "    - model_name: str, name of the model\n",
        "\n",
        "    Returns:\n",
        "    - dict, classification report dictionary\n",
        "    \"\"\"\n",
        "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "    # Print the classification report\n",
        "    print(f\"Classification Report for {model_name}:\\n\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    # Add model name to the dictionary\n",
        "    report_dict['model'] = model_name\n",
        "\n",
        "    return report_dict\n",
        "\n",
        "# aggregate classificatio reports\n",
        "def aggregate_reports(reports_list, new_report):\n",
        "    \"\"\"\n",
        "    Aggregate classification reports into a list.\n",
        "\n",
        "    Parameters:\n",
        "    - reports_list: list, list of classification reports\n",
        "    - new_report: dict, new classification report to add\n",
        "\n",
        "    Returns:\n",
        "    - list, updated list of classification reports\n",
        "    \"\"\"\n",
        "    reports_list.append(new_report)\n",
        "    return reports_list\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def extract_key_metrics(reports_list, metrics, classes):\n",
        "    \"\"\"\n",
        "    Extract key metrics from the aggregated classification reports.\n",
        "\n",
        "    Parameters:\n",
        "    - reports_list: list, list of classification reports\n",
        "    - metrics: list of str, metrics to extract\n",
        "    - classes: list of str, classes to include in the comparison\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, DataFrame with the selected metrics\n",
        "    \"\"\"\n",
        "    extracted_metrics = []\n",
        "\n",
        "    for report in reports_list:\n",
        "        model_name = report['model']\n",
        "        for cls in classes:\n",
        "            for metric in metrics:\n",
        "                metric_value = report[cls][metric]\n",
        "                extracted_metrics.append({\n",
        "                    'model': model_name,\n",
        "                    'class': cls,\n",
        "                    'metric': metric,\n",
        "                    'value': metric_value\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(extracted_metrics)\n",
        "\n",
        "# Example usage\n",
        "desired_metrics = ['recall', 'f1-score']\n",
        "desired_classes = ['0', '1', 'macro avg']\n",
        "\n",
        "# # Assuming `all_reports` is a list of all classification reports\n",
        "# key_metrics_df = extract_key_metrics(all_reports, desired_metrics, desired_classes)\n",
        "# print(key_metrics_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "tYoj8scfZu77"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize an empty list to store all reports\n",
        "all_reports = []\n",
        "\n",
        "# Logistic Regression with SMOTE\n",
        "model = LogisticRegression(max_iter=500, random_state=42)\n",
        "smote = SMOTE(random_state=42)\n",
        "pipeline_with_smote = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('smote', smote),\n",
        "    ('model', model)\n",
        "])\n",
        "pipeline_with_smote.fit(X_train, y_train)\n",
        "y_pred_smote = pipeline_with_smote.predict(X_test)\n",
        "report_smote = evaluate_model(y_test, y_pred_smote, \"Logistic Regression with SMOTE\")\n",
        "all_reports = aggregate_reports(all_reports, report_smote)\n",
        "\n",
        "# Logistic Regression with Undersampling\n",
        "undersample = RandomUnderSampler(random_state=42)\n",
        "pipeline_with_undersample = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('undersample', undersample),\n",
        "    ('model', model)\n",
        "])\n",
        "pipeline_with_undersample.fit(X_train, y_train)\n",
        "y_pred_undersample = pipeline_with_undersample.predict(X_test)\n",
        "report_undersample = evaluate_model(y_test, y_pred_undersample, \"Logistic Regression with Undersampling\")\n",
        "all_reports = aggregate_reports(all_reports, report_undersample)\n",
        "\n",
        "# RandomForest with SMOTE\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "pipeline_with_rf_smote = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('smote', smote),\n",
        "    ('model', rf_model)\n",
        "])\n",
        "pipeline_with_rf_smote.fit(X_train, y_train)\n",
        "y_pred_rf_smote = pipeline_with_rf_smote.predict(X_test)\n",
        "report_rf_smote = evaluate_model(y_test, y_pred_rf_smote, \"RandomForest with SMOTE\")\n",
        "all_reports = aggregate_reports(all_reports, report_rf_smote)\n",
        "\n",
        "# RandomForest with Undersampling\n",
        "pipeline_with_rf_undersample = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('undersample', undersample),\n",
        "    ('model', rf_model)\n",
        "])\n",
        "pipeline_with_rf_undersample.fit(X_train, y_train)\n",
        "y_pred_rf_undersample = pipeline_with_rf_undersample.predict(X_test)\n",
        "report_rf_undersample = evaluate_model(y_test, y_pred_rf_undersample, \"RandomForest with Undersampling\")\n",
        "all_reports = aggregate_reports(all_reports, report_rf_undersample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkDei8cLaeNJ",
        "outputId": "d0b541b4-994f-487a-a6ba-724d6d1753b5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Logistic Regression with SMOTE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.68      0.76      4673\n",
            "           1       0.36      0.63      0.46      1327\n",
            "\n",
            "    accuracy                           0.67      6000\n",
            "   macro avg       0.61      0.66      0.61      6000\n",
            "weighted avg       0.76      0.67      0.70      6000\n",
            "\n",
            "Classification Report for Logistic Regression with Undersampling:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.69      0.77      4673\n",
            "           1       0.37      0.63      0.46      1327\n",
            "\n",
            "    accuracy                           0.68      6000\n",
            "   macro avg       0.62      0.66      0.62      6000\n",
            "weighted avg       0.76      0.68      0.70      6000\n",
            "\n",
            "Classification Report for RandomForest with SMOTE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87      4673\n",
            "           1       0.55      0.47      0.51      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.70      0.68      0.69      6000\n",
            "weighted avg       0.79      0.80      0.79      6000\n",
            "\n",
            "Classification Report for RandomForest with Undersampling:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.78      0.83      4673\n",
            "           1       0.45      0.62      0.52      1327\n",
            "\n",
            "    accuracy                           0.75      6000\n",
            "   macro avg       0.66      0.70      0.67      6000\n",
            "weighted avg       0.78      0.75      0.76      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and display the key metrics\n",
        "key_metrics_df = extract_key_metrics(all_reports, desired_metrics, desired_classes)\n",
        "print(key_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNtLdp0taiIe",
        "outputId": "265ea786-7efb-460a-bf9c-767adf193939"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     model      class    metric     value\n",
            "0           Logistic Regression with SMOTE          0    recall  0.680291\n",
            "1           Logistic Regression with SMOTE          0  f1-score  0.762624\n",
            "2           Logistic Regression with SMOTE          1    recall  0.634514\n",
            "3           Logistic Regression with SMOTE          1  f1-score  0.459732\n",
            "4           Logistic Regression with SMOTE  macro avg    recall  0.657402\n",
            "5           Logistic Regression with SMOTE  macro avg  f1-score  0.611178\n",
            "6   Logistic Regression with Undersampling          0    recall  0.693131\n",
            "7   Logistic Regression with Undersampling          0  f1-score  0.770823\n",
            "8   Logistic Regression with Undersampling          1    recall  0.629239\n",
            "9   Logistic Regression with Undersampling          1  f1-score  0.464405\n",
            "10  Logistic Regression with Undersampling  macro avg    recall  0.661185\n",
            "11  Logistic Regression with Undersampling  macro avg  f1-score  0.617614\n",
            "12                 RandomForest with SMOTE          0    recall  0.888080\n",
            "13                 RandomForest with SMOTE          0  f1-score  0.871574\n",
            "14                 RandomForest with SMOTE          1    recall  0.472494\n",
            "15                 RandomForest with SMOTE          1  f1-score  0.506258\n",
            "16                 RandomForest with SMOTE  macro avg    recall  0.680287\n",
            "17                 RandomForest with SMOTE  macro avg  f1-score  0.688916\n",
            "18         RandomForest with Undersampling          0    recall  0.779371\n",
            "19         RandomForest with Undersampling          0  f1-score  0.826506\n",
            "20         RandomForest with Undersampling          1    recall  0.624717\n",
            "21         RandomForest with Undersampling          1  f1-score  0.520238\n",
            "22         RandomForest with Undersampling  macro avg    recall  0.702044\n",
            "23         RandomForest with Undersampling  macro avg  f1-score  0.673372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression with SMOTE"
      ],
      "metadata": {
        "id": "mUvcSJlBTM0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(max_iter=500, random_state=42)\n",
        "\n",
        "# Resampling using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "pipeline_with_smote = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('smote', smote),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline with SMOTE\n",
        "pipeline_with_smote.fit(X_train, y_train)\n",
        "\n",
        "# Transform the test data and evaluate the model\n",
        "y_pred_smote = pipeline_with_smote.predict(X_test)\n",
        "report_smote = get_classification_report(y_test, y_pred_smote, \"Logistic Regression with SMOTE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehfzy6jxQlvJ",
        "outputId": "6b8bce8b-8d33-4d8c-ca15-cbb8d12ae786"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Logistic Regression with SMOTE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.68      0.76      4673\n",
            "           1       0.36      0.63      0.46      1327\n",
            "\n",
            "    accuracy                           0.67      6000\n",
            "   macro avg       0.61      0.66      0.61      6000\n",
            "weighted avg       0.76      0.67      0.70      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression with Undersampling"
      ],
      "metadata": {
        "id": "3AVFHtXdTPyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Resampling using RandomUnderSampler\n",
        "undersample = RandomUnderSampler(random_state=42)\n",
        "pipeline_with_undersample = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('undersample', undersample),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline with undersampling\n",
        "pipeline_with_undersample.fit(X_train, y_train)\n",
        "\n",
        "# Transform the test data and evaluate the model\n",
        "y_pred_undersample = pipeline_with_undersample.predict(X_test)\n",
        "report_undersample = get_classification_report(y_test, y_pred_undersample, \"Logistic Regression with Undersampling\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UFNkLNyXzBf",
        "outputId": "3b59c8b2-a721-488f-ec55-4cb57abf970f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Logistic Regression with Undersampling:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.69      0.77      4673\n",
            "           1       0.37      0.63      0.46      1327\n",
            "\n",
            "    accuracy                           0.68      6000\n",
            "   macro avg       0.62      0.66      0.62      6000\n",
            "weighted avg       0.76      0.68      0.70      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest with SMOTE"
      ],
      "metadata": {
        "id": "DWDz4rlJT7qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the RandomForest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Add the model to the pipeline\n",
        "pipeline_with_rf_smote = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('smote', smote),\n",
        "    ('model', rf_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline with RandomForest and SMOTE\n",
        "pipeline_with_rf_smote.fit(X_train, y_train)\n",
        "\n",
        "# Transform the test data and evaluate the model\n",
        "y_pred_rf_smote = pipeline_with_rf_smote.predict(X_test)\n",
        "report_rf_smote = get_classification_report(y_test, y_pred_rf_smote, \"RandomForest with SMOTE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47DNxT87RqVL",
        "outputId": "527315b6-98d1-4f2d-9d32-fb53d52fe469"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for RandomForest with SMOTE:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87      4673\n",
            "           1       0.55      0.47      0.51      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.70      0.68      0.69      6000\n",
            "weighted avg       0.79      0.80      0.79      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest with Undersampling"
      ],
      "metadata": {
        "id": "FeIdwBKMT_7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling using RandomUnderSampler\n",
        "pipeline_with_rf_undersample = ImbPipeline(steps=[\n",
        "    ('preprocessor', pipeline.named_steps['preprocessor']),\n",
        "    ('undersample', undersample),\n",
        "    ('model', rf_model)\n",
        "])\n",
        "\n",
        "# Fit the pipeline with RandomForest and undersampling\n",
        "pipeline_with_rf_undersample.fit(X_train, y_train)\n",
        "\n",
        "# Transform the test data and evaluate the model\n",
        "y_pred_rf_undersample = pipeline_with_rf_undersample.predict(X_test)\n",
        "report_rf_undersample = get_classification_report(y_test, y_pred_rf_undersample, \"RandomForest with Undersampling\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd1yvOSXT4yV",
        "outputId": "f8a83324-13c9-45da-f721-cead514f1a96"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for RandomForest with Undersampling:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.78      0.83      4673\n",
            "           1       0.45      0.62      0.52      1327\n",
            "\n",
            "    accuracy                           0.75      6000\n",
            "   macro avg       0.66      0.70      0.67      6000\n",
            "weighted avg       0.78      0.75      0.76      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all reports\n",
        "comparison_df = pd.concat([report_smote, report_undersample, report_rf_smote, report_rf_undersample])\n",
        "\n",
        "# Reset index for better readability\n",
        "comparison_df = comparison_df.reset_index()\n",
        "\n",
        "# Display the comparison DataFrame\n",
        "comparison_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "L9wdYEFpUDeL",
        "outputId": "f26fb257-d50a-4fba-f432-dd6066cbf066"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           index  precision    recall  f1-score      support  \\\n",
              "0              0   0.867631  0.680291  0.762624  4673.000000   \n",
              "1              1   0.360445  0.634514  0.459732  1327.000000   \n",
              "2       accuracy   0.670167  0.670167  0.670167     0.670167   \n",
              "3      macro avg   0.614038  0.657402  0.611178  6000.000000   \n",
              "4   weighted avg   0.755458  0.670167  0.695635  6000.000000   \n",
              "5              0   0.868132  0.693131  0.770823  4673.000000   \n",
              "6              1   0.368004  0.629239  0.464405  1327.000000   \n",
              "7       accuracy   0.679000  0.679000  0.679000     0.679000   \n",
              "8      macro avg   0.618068  0.661185  0.617614  6000.000000   \n",
              "9   weighted avg   0.757520  0.679000  0.703054  6000.000000   \n",
              "10             0   0.855670  0.888080  0.871574  4673.000000   \n",
              "11             1   0.545217  0.472494  0.506258  1327.000000   \n",
              "12      accuracy   0.796167  0.796167  0.796167     0.796167   \n",
              "13     macro avg   0.700444  0.680287  0.688916  6000.000000   \n",
              "14  weighted avg   0.787008  0.796167  0.790778  6000.000000   \n",
              "15             0   0.879710  0.779371  0.826506  4673.000000   \n",
              "16             1   0.445699  0.624717  0.520238  1327.000000   \n",
              "17      accuracy   0.745167  0.745167  0.745167     0.745167   \n",
              "18     macro avg   0.662705  0.702044  0.673372  6000.000000   \n",
              "19  weighted avg   0.783721  0.745167  0.758770  6000.000000   \n",
              "\n",
              "                                     model  \n",
              "0           Logistic Regression with SMOTE  \n",
              "1           Logistic Regression with SMOTE  \n",
              "2           Logistic Regression with SMOTE  \n",
              "3           Logistic Regression with SMOTE  \n",
              "4           Logistic Regression with SMOTE  \n",
              "5   Logistic Regression with Undersampling  \n",
              "6   Logistic Regression with Undersampling  \n",
              "7   Logistic Regression with Undersampling  \n",
              "8   Logistic Regression with Undersampling  \n",
              "9   Logistic Regression with Undersampling  \n",
              "10                 RandomForest with SMOTE  \n",
              "11                 RandomForest with SMOTE  \n",
              "12                 RandomForest with SMOTE  \n",
              "13                 RandomForest with SMOTE  \n",
              "14                 RandomForest with SMOTE  \n",
              "15         RandomForest with Undersampling  \n",
              "16         RandomForest with Undersampling  \n",
              "17         RandomForest with Undersampling  \n",
              "18         RandomForest with Undersampling  \n",
              "19         RandomForest with Undersampling  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59636560-61f3-4e06-a43b-31187cb4dc97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.867631</td>\n",
              "      <td>0.680291</td>\n",
              "      <td>0.762624</td>\n",
              "      <td>4673.000000</td>\n",
              "      <td>Logistic Regression with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.360445</td>\n",
              "      <td>0.634514</td>\n",
              "      <td>0.459732</td>\n",
              "      <td>1327.000000</td>\n",
              "      <td>Logistic Regression with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.670167</td>\n",
              "      <td>0.670167</td>\n",
              "      <td>0.670167</td>\n",
              "      <td>0.670167</td>\n",
              "      <td>Logistic Regression with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>macro avg</td>\n",
              "      <td>0.614038</td>\n",
              "      <td>0.657402</td>\n",
              "      <td>0.611178</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>Logistic Regression with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>weighted avg</td>\n",
              "      <td>0.755458</td>\n",
              "      <td>0.670167</td>\n",
              "      <td>0.695635</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>Logistic Regression with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0.868132</td>\n",
              "      <td>0.693131</td>\n",
              "      <td>0.770823</td>\n",
              "      <td>4673.000000</td>\n",
              "      <td>Logistic Regression with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0.368004</td>\n",
              "      <td>0.629239</td>\n",
              "      <td>0.464405</td>\n",
              "      <td>1327.000000</td>\n",
              "      <td>Logistic Regression with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>Logistic Regression with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>macro avg</td>\n",
              "      <td>0.618068</td>\n",
              "      <td>0.661185</td>\n",
              "      <td>0.617614</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>Logistic Regression with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>weighted avg</td>\n",
              "      <td>0.757520</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.703054</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>Logistic Regression with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0.855670</td>\n",
              "      <td>0.888080</td>\n",
              "      <td>0.871574</td>\n",
              "      <td>4673.000000</td>\n",
              "      <td>RandomForest with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0.545217</td>\n",
              "      <td>0.472494</td>\n",
              "      <td>0.506258</td>\n",
              "      <td>1327.000000</td>\n",
              "      <td>RandomForest with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.796167</td>\n",
              "      <td>0.796167</td>\n",
              "      <td>0.796167</td>\n",
              "      <td>0.796167</td>\n",
              "      <td>RandomForest with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>macro avg</td>\n",
              "      <td>0.700444</td>\n",
              "      <td>0.680287</td>\n",
              "      <td>0.688916</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>RandomForest with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>weighted avg</td>\n",
              "      <td>0.787008</td>\n",
              "      <td>0.796167</td>\n",
              "      <td>0.790778</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>RandomForest with SMOTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0.879710</td>\n",
              "      <td>0.779371</td>\n",
              "      <td>0.826506</td>\n",
              "      <td>4673.000000</td>\n",
              "      <td>RandomForest with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0.445699</td>\n",
              "      <td>0.624717</td>\n",
              "      <td>0.520238</td>\n",
              "      <td>1327.000000</td>\n",
              "      <td>RandomForest with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>accuracy</td>\n",
              "      <td>0.745167</td>\n",
              "      <td>0.745167</td>\n",
              "      <td>0.745167</td>\n",
              "      <td>0.745167</td>\n",
              "      <td>RandomForest with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>macro avg</td>\n",
              "      <td>0.662705</td>\n",
              "      <td>0.702044</td>\n",
              "      <td>0.673372</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>RandomForest with Undersampling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>weighted avg</td>\n",
              "      <td>0.783721</td>\n",
              "      <td>0.745167</td>\n",
              "      <td>0.758770</td>\n",
              "      <td>6000.000000</td>\n",
              "      <td>RandomForest with Undersampling</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59636560-61f3-4e06-a43b-31187cb4dc97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59636560-61f3-4e06-a43b-31187cb4dc97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59636560-61f3-4e06-a43b-31187cb4dc97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ddb2d22-9c3d-425f-a1e3-e94b15b33354\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ddb2d22-9c3d-425f-a1e3-e94b15b33354')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ddb2d22-9c3d-425f-a1e3-e94b15b33354 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e32b7e74-e6ac-406e-affa-e4bafdc7277c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e32b7e74-e6ac-406e-affa-e4bafdc7277c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1\",\n          \"weighted avg\",\n          \"accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15782051582929144,\n        \"min\": 0.3604452054794521,\n        \"max\": 0.8797101449275362,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.8676310043668122,\n          0.7451666666666666,\n          0.8797101449275362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08494826381920227,\n        \"min\": 0.4724943481537302,\n        \"max\": 0.888080462229831,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.6802910335972608,\n          0.6345139412207988,\n          0.6292388847023361\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11916062361860713,\n        \"min\": 0.45973245973245974,\n        \"max\": 0.8715740837971226,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.7626244452440926,\n          0.7451666666666666,\n          0.8265062975150347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2546.1076803785436,\n        \"min\": 0.6701666666666667,\n        \"max\": 6000.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4673.0,\n          1327.0,\n          0.7961666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Logistic Regression with Undersampling\",\n          \"RandomForest with Undersampling\",\n          \"Logistic Regression with SMOTE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_key_metrics(comparison_df, metrics, classes=['1', 'recall', 'f1', 'macro avg']):\n",
        "    \"\"\"\n",
        "    Extract key metrics from the comparison DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - comparison_df: pd.DataFrame, DataFrame containing the classification reports for different models\n",
        "    - metrics: list of str, metrics to extract (e.g., ['recall', 'f1-score'])\n",
        "    - classes: list of str, classes to include in the comparison (default is ['1', 'accuracy', 'macro avg'])\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, DataFrame with the selected metrics for the specified classes\n",
        "    \"\"\"\n",
        "    # Filter the DataFrame to include only the desired metrics and classes\n",
        "    filtered_df = comparison_df[comparison_df['index'].isin(classes)]\n",
        "\n",
        "    # Select only the desired metrics and the model column\n",
        "    filtered_df = filtered_df[['index'] + metrics + ['model']]\n",
        "\n",
        "    # Pivot the DataFrame for better comparison\n",
        "    pivot_df = filtered_df.pivot(index='index', columns='model', values=metrics)\n",
        "\n",
        "    return pivot_df\n",
        "\n",
        "# Define the metrics and classes you want to focus on\n",
        "desired_metrics = ['recall', 'f1-score']\n",
        "desired_classes = ['1', 'accuracy', 'macro avg']\n",
        "\n",
        "# Extract and display the key metrics\n",
        "key_metrics_df = extract_key_metrics(comparison_df, desired_metrics, desired_classes)\n",
        "print(key_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akg-U1PUW4Cc",
        "outputId": "451f30c1-fd93-4c07-c411-4430663135ff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  recall  \\\n",
            "model     Logistic Regression with SMOTE   \n",
            "index                                      \n",
            "1                               0.634514   \n",
            "accuracy                        0.670167   \n",
            "macro avg                       0.657402   \n",
            "\n",
            "                                                                          \\\n",
            "model     Logistic Regression with Undersampling RandomForest with SMOTE   \n",
            "index                                                                      \n",
            "1                                       0.629239                0.472494   \n",
            "accuracy                                0.679000                0.796167   \n",
            "macro avg                               0.661185                0.680287   \n",
            "\n",
            "                                                                f1-score  \\\n",
            "model     RandomForest with Undersampling Logistic Regression with SMOTE   \n",
            "index                                                                      \n",
            "1                                0.624717                       0.459732   \n",
            "accuracy                         0.745167                       0.670167   \n",
            "macro avg                        0.702044                       0.611178   \n",
            "\n",
            "                                                                          \\\n",
            "model     Logistic Regression with Undersampling RandomForest with SMOTE   \n",
            "index                                                                      \n",
            "1                                       0.464405                0.506258   \n",
            "accuracy                                0.679000                0.796167   \n",
            "macro avg                               0.617614                0.688916   \n",
            "\n",
            "                                           \n",
            "model     RandomForest with Undersampling  \n",
            "index                                      \n",
            "1                                0.520238  \n",
            "accuracy                         0.745167  \n",
            "macro avg                        0.673372  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_key_metrics(comparison_df, metrics, classes=['1', 'accuracy', 'macro avg']):\n",
        "    \"\"\"\n",
        "    Extract key metrics from the comparison DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - comparison_df: pd.DataFrame, DataFrame containing the classification reports for different models\n",
        "    - metrics: list of str, metrics to extract (e.g., ['recall', 'f1-score'])\n",
        "    - classes: list of str, classes to include in the comparison (default is ['1', 'accuracy', 'macro avg'])\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, DataFrame with the selected metrics for the specified classes\n",
        "    \"\"\"\n",
        "    # Filter the DataFrame to include only the desired metrics and classes\n",
        "    filtered_df = comparison_df[comparison_df['index'].isin(classes)]\n",
        "    filtered_df = filtered_df[metrics + ['model']]\n",
        "\n",
        "    # Pivot the DataFrame for better comparison\n",
        "    pivot_df = filtered_df.pivot(index='index', columns='model', values=metrics)\n",
        "\n",
        "    return pivot_df\n",
        "\n",
        "# Define the metrics and classes you want to focus on\n",
        "desired_metrics = ['recall', 'f1-score']\n",
        "desired_classes = ['1', 'macro avg']\n",
        "\n",
        "# Extract and display the key metrics\n",
        "key_metrics_df = extract_key_metrics(comparison_df, desired_metrics, desired_classes)\n",
        "print(key_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "mtX_vKhKWUk4",
        "outputId": "dff68380-66b9-43bf-f9e6-0f79586763cb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'index'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7e16ad278ea0>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Extract and display the key metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mkey_metrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_key_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparison_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_metrics_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-7e16ad278ea0>\u001b[0m in \u001b[0;36mextract_key_metrics\u001b[0;34m(comparison_df, metrics, classes)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Pivot the DataFrame for better comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpivot_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpivot_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   8412\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8414\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8416\u001b[0m     _shared_docs[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    538\u001b[0m                 \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mdata_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    538\u001b[0m                 \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mindex_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mdata_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns_listlike\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Extract Key Metrics\n",
        "def extract_key_metrics(comparison_df, metrics, classes=['1', 'accuracy']):\n",
        "    \"\"\"\n",
        "    Extract key metrics from the comparison DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - comparison_df: pd.DataFrame, DataFrame containing the classification reports for different models\n",
        "    - metrics: list of str, metrics to extract (e.g., ['recall', 'f1-score'])\n",
        "    - classes: list of str, classes to include in the comparison (default is ['1', 'accuracy'])\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, DataFrame with the selected metrics for the specified classes\n",
        "    \"\"\"\n",
        "    # Filter the DataFrame to include only the desired metrics and classes\n",
        "    filtered_df = comparison_df[comparison_df['index'].isin(classes)]\n",
        "    filtered_df = filtered_df[metrics + ['model']]\n",
        "\n",
        "    # Pivot the DataFrame for better comparison\n",
        "    pivot_df = filtered_df.pivot(index='index', columns='model', values=metrics)\n",
        "\n",
        "    return pivot_df\n",
        "\n",
        "# Define the metrics and classes you want to focus on\n",
        "desired_metrics = ['recall', 'f1-score', 'f1-score macro']\n",
        "desired_classes = ['1', 'accuracy']\n",
        "\n",
        "# Extract and display the key metrics\n",
        "key_metrics_df = extract_key_metrics(comparison_df, desired_metrics, desired_classes)\n",
        "print(key_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "bqmNZkJCVQQu",
        "outputId": "209943d3-ba7b-4f55-f464-979a94a54968"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['f1-score macro'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-0c33ac0a53c2>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Extract and display the key metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mkey_metrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_key_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparison_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_metrics_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-0c33ac0a53c2>\u001b[0m in \u001b[0;36mextract_key_metrics\u001b[0;34m(comparison_df, metrics, classes)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Filter the DataFrame to include only the desired metrics and classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfiltered_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomparison_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfiltered_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Pivot the DataFrame for better comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5943\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['f1-score macro'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Weights"
      ],
      "metadata": {
        "id": "Hnp-6xf8YVba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with class weights\n",
        "model_with_weights = LogisticRegression(max_iter=500, class_weight='balanced', random_state=42)\n",
        "pipeline_with_weights = add_model_to_pipeline(pipeline, model_with_weights)\n",
        "\n",
        "# Fit the pipeline with class weights\n",
        "pipeline_with_weights.fit(X_train, y_train)\n",
        "\n",
        "# Transform the test data and evaluate the model\n",
        "evaluate_model(pipeline_with_weights, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "XpW9xETZYUhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "k33PWuXFPLrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the performance of different methods\n",
        "# You can store the results of each method and plot them for comparison\n",
        "\n",
        "# Example: Logistic Regression without balancing\n",
        "print(\"Logistic Regression without balancing\")\n",
        "evaluate_model(pipeline_with_model, X_test, y_test)\n",
        "\n",
        "# Logistic Regression with SMOTE\n",
        "print(\"Logistic Regression with SMOTE\")\n",
        "evaluate_model(pipeline_with_smote, X_test, y_test)\n",
        "\n",
        "# Logistic Regression with undersampling\n",
        "print(\"Logistic Regression with undersampling\")\n",
        "evaluate_model(pipeline_with_undersample, X_test, y_test)\n",
        "\n",
        "# Logistic Regression with class weights\n",
        "print(\"Logistic Regression with class weights\")\n",
        "evaluate_model(pipeline_with_weights, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "Rb0narfHYbNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write Data Utils Script"
      ],
      "metadata": {
        "id": "9-P3rfxXFhO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to write script\n",
        "script_content = r'''\n",
        "\n",
        "# data_utils.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Load the dataset from a URL\n",
        "def load_data_from_url(url):\n",
        "    \"\"\"\n",
        "    Load the dataset from a specified URL.\n",
        "\n",
        "    Parameters:\n",
        "    - url: str, URL of the dataset\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, loaded dataset\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_excel(url, header=1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data from URL: {e}\")\n",
        "        return None\n",
        "    return df\n",
        "\n",
        "# Clean column names\n",
        "def clean_column_names(df):\n",
        "    \"\"\"\n",
        "    Clean the column names by converting to lowercase and replacing spaces with underscores.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pd.DataFrame, input dataframe\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, dataframe with cleaned column names\n",
        "    \"\"\"\n",
        "    df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
        "    return df\n",
        "\n",
        "# Remove the 'id' column\n",
        "def remove_id_column(df):\n",
        "    \"\"\"\n",
        "    Remove the 'id' column if it exists.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pd.DataFrame, input dataframe\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, dataframe without 'id' column\n",
        "    \"\"\"\n",
        "    if 'id' in df.columns:\n",
        "        df = df.drop(columns=['id'])\n",
        "    return df\n",
        "\n",
        "# Rename columns (pay_0 not in dataset)\n",
        "def rename_columns(df):\n",
        "    \"\"\"\n",
        "    Rename specific columns based on a predefined dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pd.DataFrame, input dataframe\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, dataframe with renamed columns\n",
        "    \"\"\"\n",
        "    rename_dict = {\n",
        "        'pay_0': 'pay_1'\n",
        "    }\n",
        "    df = df.rename(columns=rename_dict)\n",
        "    return df\n",
        "\n",
        "# Convert specified columns to categorical type\n",
        "def convert_categorical(df, categorical_columns):\n",
        "    \"\"\"\n",
        "    Convert specified columns to categorical type.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pd.DataFrame, input dataframe\n",
        "    - categorical_columns: list of str, columns to convert to categorical type\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, dataframe with converted columns\n",
        "    \"\"\"\n",
        "    df[categorical_columns] = df[categorical_columns].astype('category')\n",
        "    return df\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "def split_data(df, target):\n",
        "    \"\"\"\n",
        "    Split the data into training and testing sets.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pd.DataFrame, input dataframe\n",
        "    - target: str, name of the target column\n",
        "\n",
        "    Returns:\n",
        "    - tuple, (X_train, X_test, y_train, y_test)\n",
        "    \"\"\"\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def preprocess_data(url, categorical_columns):\n",
        "    \"\"\"\n",
        "    Load and preprocess the data.\n",
        "\n",
        "    Parameters:\n",
        "    - url: str, URL of the dataset\n",
        "    - categorical_columns: list of str, columns to convert to categorical type\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame, preprocessed data\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    data = load_data_from_url(url)\n",
        "\n",
        "    if data is None:\n",
        "        return None\n",
        "\n",
        "    # Clean column names\n",
        "    data = clean_column_names(data)\n",
        "\n",
        "    # Remove the 'id' column\n",
        "    data = remove_id_column(data)\n",
        "\n",
        "    # Rename columns\n",
        "    data = rename_columns(data)\n",
        "\n",
        "    # Convert specified columns to categorical type\n",
        "    data = convert_categorical(data, categorical_columns)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Plot class balance in the training set with ratio annotations\n",
        "def plot_class_distribution(y_train, target):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(x=y_train, hue=y_train, palette='PuRd')\n",
        "    plt.title(f'Class Distribution in Training Set ({target})')\n",
        "    plt.xlabel(target)\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend([],[], frameon=False)  # Turn off the legend\n",
        "\n",
        "    # Calculate the percentage for each class\n",
        "    total = len(y_train)\n",
        "    class_counts = y_train.value_counts()\n",
        "    for i, count in enumerate(class_counts):\n",
        "        percentage = 100 * count / total\n",
        "        plt.text(i, count, f'{percentage:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def create_preprocessing_pipeline(numeric_features, categorical_features):\n",
        "    \"\"\"\n",
        "    Create a preprocessing pipeline for numeric and categorical features.\n",
        "\n",
        "    Parameters:\n",
        "    - numeric_features: list of str, names of numeric features\n",
        "    - categorical_features: list of str, names of categorical features\n",
        "\n",
        "    Returns:\n",
        "    - sklearn.pipeline.Pipeline, the complete preprocessing pipeline\n",
        "    \"\"\"\n",
        "    # Define the transformers for numerical and categorical data\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # Combine the transformers using ColumnTransformer\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Create the full pipeline with preprocessing and a placeholder for the model\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor)\n",
        "        # You can add your model here, e.g., ('model', RandomForestClassifier())\n",
        "    ])\n",
        "\n",
        "    print(\"Preprocessing pipeline created successfully.\")\n",
        "    return pipeline\n",
        "\n",
        "def add_model_to_pipeline(pipeline, model):\n",
        "    \"\"\"\n",
        "    Add a model to the preprocessing pipeline.\n",
        "\n",
        "    Parameters:\n",
        "    - pipeline: sklearn.pipeline.Pipeline, the preprocessing pipeline\n",
        "    - model: sklearn estimator, the model to add to the pipeline\n",
        "\n",
        "    Returns:\n",
        "    - sklearn.pipeline.Pipeline, the complete pipeline with the model added\n",
        "    \"\"\"\n",
        "    return Pipeline(steps=pipeline.steps + [('model', model)])\n",
        "\n",
        "def evaluate_model(pipeline, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluate the model using the test data.\n",
        "\n",
        "    Parameters:\n",
        "    - pipeline: sklearn.pipeline.Pipeline, the complete pipeline with preprocessing and model\n",
        "    - X_test: pd.DataFrame or np.ndarray, the test features\n",
        "    - y_test: pd.Series or np.ndarray, the test labels\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray, the predicted labels\n",
        "    \"\"\"\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    # print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    return y_pred\n",
        "\n",
        "def hyperparameter_tuning(pipeline, param_grid, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Perform hyperparameter tuning using GridSearchCV.\n",
        "\n",
        "    Parameters:\n",
        "    - pipeline: sklearn.pipeline.Pipeline, the complete pipeline with preprocessing and model\n",
        "    - param_grid: dict, the parameter grid for GridSearchCV\n",
        "    - X_train: pd.DataFrame or np.ndarray, the training features\n",
        "    - y_train: pd.Series or np.ndarray, the training labels\n",
        "\n",
        "    Returns:\n",
        "    - sklearn estimator, the best estimator found by GridSearchCV\n",
        "    \"\"\"\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"Best Parameters:\\n\", grid_search.best_params_)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "'''\n",
        "\n",
        "# Write the script to a file\n",
        "with open(\"data_utils.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Script successfully written to data_utils.py\")\n",
        "\n",
        "# reload script to make function available for use\n",
        "import importlib\n",
        "import data_utils\n",
        "importlib.reload(data_utils)\n",
        "\n",
        "from data_utils import (load_data_from_url, clean_column_names, remove_id_column,\n",
        "                        rename_columns, convert_categorical, preprocess_data, split_data, plot_class_distribution,\n",
        "                        create_preprocessing_pipeline, add_model_to_pipeline, evaluate_model,\n",
        "                        hyperparameter_tuning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snub-sGXYjmK",
        "outputId": "e9a76889-8655-4a4a-a95a-3183e1684089"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script successfully written to data_utils.py\n"
          ]
        }
      ]
    }
  ]
}