{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPT1sqSHUS00qyLjwr4Tnuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/pipelines/blob/main/pipelines_16_ensemble_02_stacking_07_additional_modelsipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Models\n",
        "\n",
        "Adding more models to the VotingClassifier can help improve precision for class 1 and recall for class 0 by leveraging the strengths of different models. Here’s how you can add more models to your VotingClassifier:\n",
        "\n",
        "### Steps:\n",
        "1. **Identify Additional Models**: Select additional models that might complement the existing ones.\n",
        "2. **Train the New Models**: Train these models and include them in the VotingClassifier.\n",
        "3. **Evaluate the Combined Model**: Evaluate the performance of the VotingClassifier with the additional models.\n",
        "\n",
        "### Example Additional Models:\n",
        "- **XGBoost**: Another gradient boosting model that can help with precision and recall.\n",
        "- **Support Vector Machine (SVM)**: Known for classification tasks, particularly useful with appropriate kernel settings.\n",
        "- **Neural Network (MLPClassifier)**: Can capture complex patterns in the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ilTyucalAlv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How the Voting Classifier Weights Models\n",
        "\n",
        "The `VotingClassifier` in scikit-learn combines multiple models (classifiers) and predicts the class label based on the majority vote or the average of predicted probabilities. Here’s how it works:\n",
        "\n",
        "- **Hard Voting**: Each classifier votes for a class, and the class with the most votes wins. If there’s a tie, one of the tied classes is randomly selected.\n",
        "- **Soft Voting**: Each classifier predicts the probabilities of each class. These probabilities are averaged, and the class with the highest average probability is selected as the final prediction.\n",
        "\n",
        "### Weights in Voting Classifier\n",
        "\n",
        "The `VotingClassifier` can assign different weights to each model. These weights influence the contribution of each model’s prediction to the final prediction in the case of soft voting. The syntax for specifying weights is:\n",
        "\n",
        "```python\n",
        "voting_clf = VotingClassifier(estimators=[('model1', clf1), ('model2', clf2)], voting='soft', weights=[w1, w2])\n",
        "```\n",
        "\n",
        "In this syntax:\n",
        "- `estimators` is a list of tuples, where each tuple consists of a model name and the model itself.\n",
        "- `weights` is a list of weights corresponding to each model. The length of the weights list must match the number of models.\n",
        "\n",
        "### Impact of Model Duplication\n",
        "\n",
        "If you have a model that achieves high precision for class 1 and you add multiple copies of this model to the VotingClassifier, the following can occur:\n",
        "\n",
        "1. **Increased Influence**: The duplicated model(s) will have a greater influence on the final prediction. If this model consistently predicts class 1 with high precision, it can increase the precision of class 1 in the VotingClassifier.\n",
        "2. **Potential Overfitting**: Adding multiple copies of the same model can lead to overfitting. The ensemble may become less robust and more sensitive to the duplicated model’s predictions.\n",
        "3. **Bias Towards Duplicated Model**: The VotingClassifier may become biased towards the predictions of the duplicated model, potentially ignoring the diverse predictions from other models.\n",
        "\n",
        "### Example of Adding Weights to VotingClassifier\n",
        "\n",
        "Here’s how you can add weights to the VotingClassifier:\n",
        "\n",
        "```python\n",
        "# Example models\n",
        "clf1 = LogisticRegression(random_state=42)\n",
        "clf2 = RandomForestClassifier(random_state=42)\n",
        "clf3 = LGBMClassifier(random_state=42)\n",
        "\n",
        "# VotingClassifier with weights\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('lr', clf1),\n",
        "    ('rf', clf2),\n",
        "    ('lgbm', clf3),\n",
        "    ('lgbm2', clf3),  # Duplicate model for higher weight\n",
        "    ('lgbm3', clf3),  # Duplicate model for higher weight\n",
        "], voting='soft', weights=[1, 1, 1, 1, 1])\n",
        "\n",
        "# Fit and predict\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred = voting_clf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "In this example, `LGBMClassifier` has been added three times, giving it a higher weight in the VotingClassifier.\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **Soft Voting**: Probabilities are averaged, and the class with the highest average probability is selected.\n",
        "- **Weights**: You can assign different weights to each model to control their influence on the final prediction.\n",
        "- **Duplication**: Adding multiple copies of the same model can increase its influence but may also lead to overfitting.\n",
        "\n",
        "By appropriately weighting the models or adding more instances of a high-performing model, you can potentially improve specific performance metrics like precision for class 1."
      ],
      "metadata": {
        "id": "VlZP3_kQDqda"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hard Voting Classifier\n",
        "\n",
        "When using 'hard' voting in the VotingClassifier, the method predict_proba is not available because 'hard' voting only makes use of the class predictions from each model rather than their probabilities. Consequently, you cannot use the predict_with_class_specific_thresholds function that relies on predicted probabilities.\n",
        "\n",
        "Instead, you need to directly use the predict method of the VotingClassifier when using 'hard' voting."
      ],
      "metadata": {
        "id": "viTzFv_tD1CA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwnw7l36AULw",
        "outputId": "fc25c9a2-6b32-42b2-b31b-90e1f5f4f8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007270 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001954 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Updated VotingClassifier model saved to 'voting_classifier_extended.pkl'\n",
            "Recall Class 1: 0.5170\n",
            "Precision Class 1: 0.5555\n",
            "Recall Class 0: 0.8825\n",
            "Precision Class 0: 0.8655\n",
            "F1 Macro: 0.7047\n",
            "Accuracy: 0.8017\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      4673\n",
            "           1       0.56      0.52      0.54      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.71      0.70      0.70      6000\n",
            "weighted avg       0.80      0.80      0.80      6000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "\n",
        "# Load the preprocessed data (assuming the function is defined in loan_data_utils)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the column transformer\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Load the previous best models and parameters\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Define additional models without class weights\n",
        "additional_models = {\n",
        "    'XGB': XGBClassifier(random_state=42),\n",
        "    'MLP': MLPClassifier(random_state=42, max_iter=1000),\n",
        "    'SVM': SVC(probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "# Create pipelines for each additional model\n",
        "additional_pipelines = {name: Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
        "                        for name, model in additional_models.items()}\n",
        "\n",
        "# Add the additional models to the best models\n",
        "best_models.update(additional_pipelines)\n",
        "\n",
        "# Save the updated models and parameters\n",
        "joblib.dump(best_models, 'best_models_extended.pkl')\n",
        "with open('best_params_extended.json', 'w') as json_file:\n",
        "    json.dump(best_params, json_file, indent=4)\n",
        "\n",
        "# Create a list of (name, model) tuples for the VotingClassifier\n",
        "estimators = [\n",
        "    ('recall_class_1', best_models['recall_class_1']),\n",
        "    ('precision_class_1', best_models['precision_class_1']),\n",
        "    ('recall_class_0', best_models['recall_class_0']),\n",
        "    ('precision_class_0', best_models['precision_class_0']),\n",
        "    ('XGB', best_models['XGB']),\n",
        "    ('MLP', best_models['MLP']),\n",
        "    ('SVM', best_models['SVM'])\n",
        "]\n",
        "\n",
        "# Initialize the VotingClassifier with the best models\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the updated VotingClassifier model\n",
        "joblib.dump(voting_clf, 'voting_classifier_extended.pkl')\n",
        "\n",
        "print(\"Updated VotingClassifier model saved to 'voting_classifier_extended.pkl'\")\n",
        "\n",
        "# Load the optimal thresholds from the file\n",
        "with open('optimal_thresholds.json', 'r') as json_file:\n",
        "    optimal_thresholds = json.load(json_file)\n",
        "\n",
        "# Function to apply class-specific thresholds\n",
        "def predict_with_class_specific_thresholds(model, X, threshold_class_1, threshold_class_0):\n",
        "    y_proba = model.predict_proba(X)\n",
        "    y_pred = np.zeros(y_proba.shape[0])\n",
        "\n",
        "    # Apply thresholds to obtain predictions\n",
        "    y_pred[(y_proba[:, 1] >= threshold_class_1)] = 1  # Predict class 1 for probabilities above threshold_class_1\n",
        "    y_pred[(y_proba[:, 0] >= threshold_class_0)] = 0  # Predict class 0 for probabilities above threshold_class_0\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Predict with the updated VotingClassifier model using the optimal thresholds\n",
        "threshold_class_1 = optimal_thresholds['threshold_class_1']\n",
        "threshold_class_0 = optimal_thresholds['threshold_class_0']\n",
        "\n",
        "y_pred_voting = predict_with_class_specific_thresholds(voting_clf, X_test, threshold_class_1, threshold_class_0)\n",
        "\n",
        "# Evaluate the performance of the VotingClassifier\n",
        "recall_1 = recall_score(y_test, y_pred_voting, pos_label=1)\n",
        "precision_1 = precision_score(y_test, y_pred_voting, pos_label=1, zero_division=0)\n",
        "recall_0 = recall_score(y_test, y_pred_voting, pos_label=0)\n",
        "precision_0 = precision_score(y_test, y_pred_voting, pos_label=0, zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred_voting, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Recall Class 1: {recall_1:.4f}')\n",
        "print(f'Precision Class 1: {precision_1:.4f}')\n",
        "print(f'Recall Class 0: {recall_0:.4f}')\n",
        "print(f'Precision Class 0: {precision_0:.4f}')\n",
        "print(f'F1 Macro: {f1_macro:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load the preprocessed data (assuming the function is defined in loan_data_utils)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the column transformer\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Load the previous best models and parameters\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Create a list of (name, model) tuples for the VotingClassifier\n",
        "estimators = [\n",
        "    ('recall_class_1', best_models['recall_class_1']),\n",
        "    ('precision_class_1', best_models['precision_class_1']),\n",
        "    ('recall_class_0', best_models['recall_class_0']),\n",
        "    ('precision_class_0', best_models['precision_class_0'])\n",
        "]\n",
        "\n",
        "# Initialize the VotingClassifier with the best models using 'hard' voting\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='hard')\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the updated VotingClassifier model\n",
        "joblib.dump(voting_clf, 'voting_classifier_hard.pkl')\n",
        "\n",
        "print(\"Updated VotingClassifier model saved to 'voting_classifier_hard.pkl'\")\n",
        "\n",
        "# Predict with the updated VotingClassifier model\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the VotingClassifier\n",
        "recall_1 = recall_score(y_test, y_pred_voting, pos_label=1)\n",
        "precision_1 = precision_score(y_test, y_pred_voting, pos_label=1, zero_division=0)\n",
        "recall_0 = recall_score(y_test, y_pred_voting, pos_label=0)\n",
        "precision_0 = precision_score(y_test, y_pred_voting, pos_label=0, zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred_voting, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Recall Class 1: {recall_1:.4f}')\n",
        "print(f'Precision Class 1: {precision_1:.4f}')\n",
        "print(f'Recall Class 0: {recall_0:.4f}')\n",
        "print(f'Precision Class 0: {precision_0:.4f}')\n",
        "print(f'F1 Macro: {f1_macro:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0QIdYkcBZz7",
        "outputId": "8dc0152b-8e31-42fd-d9a1-943c4ff1cff4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002212 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Updated VotingClassifier model saved to 'voting_classifier_hard.pkl'\n",
            "Recall Class 1: 0.5705\n",
            "Precision Class 1: 0.5074\n",
            "Recall Class 0: 0.8427\n",
            "Precision Class 0: 0.8736\n",
            "F1 Macro: 0.6975\n",
            "Accuracy: 0.7825\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86      4673\n",
            "           1       0.51      0.57      0.54      1327\n",
            "\n",
            "    accuracy                           0.78      6000\n",
            "   macro avg       0.69      0.71      0.70      6000\n",
            "weighted avg       0.79      0.78      0.79      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load the preprocessed data (assuming the function is defined in loan_data_utils)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the column transformer\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Load the previous best models and parameters\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Define the models to be duplicated\n",
        "recall_class_1_model = best_models['recall_class_1']\n",
        "precision_class_1_model = best_models['precision_class_1']\n",
        "recall_class_0_model = best_models['recall_class_0']\n",
        "\n",
        "# Create a list of (name, model) tuples for the VotingClassifier\n",
        "estimators = [\n",
        "    ('recall_class_1_1', recall_class_1_model),\n",
        "    ('recall_class_1_2', recall_class_1_model),\n",
        "    ('recall_class_1_3', recall_class_1_model),\n",
        "    ('precision_class_1_1', precision_class_1_model),\n",
        "    ('precision_class_1_2', precision_class_1_model),\n",
        "    ('precision_class_1_3', precision_class_1_model),\n",
        "    ('recall_class_0_1', recall_class_0_model),\n",
        "    ('recall_class_0_2', recall_class_0_model)\n",
        "]\n",
        "\n",
        "# Initialize the VotingClassifier with the duplicated models using 'soft' voting\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the updated VotingClassifier model\n",
        "joblib.dump(voting_clf, 'voting_classifier_multiplied.pkl')\n",
        "\n",
        "print(\"Updated VotingClassifier model saved to 'voting_classifier_multiplied.pkl'\")\n",
        "\n",
        "# Load the optimal thresholds from the file\n",
        "with open('optimal_thresholds.json', 'r') as json_file:\n",
        "    optimal_thresholds = json.load(json_file)\n",
        "\n",
        "# Function to apply class-specific thresholds\n",
        "def predict_with_class_specific_thresholds(model, X, threshold_class_1, threshold_class_0):\n",
        "    y_proba = model.predict_proba(X)\n",
        "    y_pred = np.zeros(y_proba.shape[0])\n",
        "\n",
        "    # Apply thresholds to obtain predictions\n",
        "    y_pred[(y_proba[:, 1] >= threshold_class_1)] = 1  # Predict class 1 for probabilities above threshold_class_1\n",
        "    y_pred[(y_proba[:, 0] >= threshold_class_0)] = 0  # Predict class 0 for probabilities above threshold_class_0\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Predict with the updated VotingClassifier model using the optimal thresholds\n",
        "threshold_class_1 = optimal_thresholds['threshold_class_1']\n",
        "threshold_class_0 = optimal_thresholds['threshold_class_0']\n",
        "\n",
        "y_pred_voting = predict_with_class_specific_thresholds(voting_clf, X_test, threshold_class_1, threshold_class_0)\n",
        "\n",
        "# Evaluate the performance of the VotingClassifier\n",
        "recall_1 = recall_score(y_test, y_pred_voting, pos_label=1)\n",
        "precision_1 = precision_score(y_test, y_pred_voting, pos_label=1, zero_division=0)\n",
        "recall_0 = recall_score(y_test, y_pred_voting, pos_label=0)\n",
        "precision_0 = precision_score(y_test, y_pred_voting, pos_label=0, zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred_voting, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Recall Class 1: {recall_1:.4f}')\n",
        "print(f'Precision Class 1: {precision_1:.4f}')\n",
        "print(f'Recall Class 0: {recall_0:.4f}')\n",
        "print(f'Precision Class 0: {precision_0:.4f}')\n",
        "print(f'F1 Macro: {f1_macro:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHZiB6uvE2Os",
        "outputId": "679b8fdd-1cf2-4b3e-cfa6-427bb77127bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079441 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011635 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030574 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003354 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Updated VotingClassifier model saved to 'voting_classifier_multiplied.pkl'\n",
            "Recall Class 1: 0.6534\n",
            "Precision Class 1: 0.4331\n",
            "Recall Class 0: 0.7571\n",
            "Precision Class 0: 0.8849\n",
            "F1 Macro: 0.6685\n",
            "Accuracy: 0.7342\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82      4673\n",
            "           1       0.43      0.65      0.52      1327\n",
            "\n",
            "    accuracy                           0.73      6000\n",
            "   macro avg       0.66      0.71      0.67      6000\n",
            "weighted avg       0.79      0.73      0.75      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Analysis of Results\n",
        "\n",
        "The decrease in performance when duplicating the models suggests that the VotingClassifier might be overfitting to certain models, leading to a less robust ensemble.\n",
        "\n",
        "### Observations:\n",
        "\n",
        "1. **Decrease in Overall Metrics**:\n",
        "   - Precision for Class 1 dropped from 0.68 to 0.43.\n",
        "   - Recall for Class 1 dropped from 0.95 to 0.65.\n",
        "   - Precision and recall for Class 0 also decreased, though not as drastically.\n",
        "\n",
        "2. **Overfitting**:\n",
        "   - The addition of multiple identical models can lead to overfitting, as these models dominate the voting process, reducing the diversity and robustness of the ensemble.\n",
        "\n",
        "### Recommendations:\n",
        "\n",
        "1. **Revert to the Best Performing Model**:\n",
        "   - Given the performance drop, it’s advisable to revert to the best performing model without duplication.\n",
        "\n",
        "2. **Optimize Voting Weights**:\n",
        "   - Instead of duplicating models, consider optimizing the weights of each model in the VotingClassifier to give more influence to high-performing models.\n",
        "\n",
        "3. **Resampling Techniques**:\n",
        "   - Implement resampling techniques such as SMOTE, ADASYN, or undersampling to balance the class distribution, which might improve the recall and precision for class 1.\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "1. **Optimized Weights**: Adjust the weights assigned to each model to give more influence to models that perform well for specific metrics.\n",
        "2. **Train and Evaluate**: Train the updated VotingClassifier with the optimized weights and evaluate its performance.\n",
        "\n",
        "By running this code, you can see if optimizing the weights of the VotingClassifier improves precision for class 1 and recall for class 0 while maintaining overall performance."
      ],
      "metadata": {
        "id": "FRY72wdbFYZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load the preprocessed data (assuming the function is defined in loan_data_utils)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the column transformer\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Load the previous best models and parameters\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Create a list of (name, model) tuples for the VotingClassifier\n",
        "estimators = [\n",
        "    ('recall_class_1', best_models['recall_class_1']),\n",
        "    ('precision_class_1', best_models['precision_class_1']),\n",
        "    ('recall_class_0', best_models['recall_class_0']),\n",
        "    ('precision_class_0', best_models['precision_class_0'])\n",
        "]\n",
        "\n",
        "# Initialize the VotingClassifier with the best models using 'soft' voting and optimized weights\n",
        "weights = [2, 1, 2, 1]  # Adjust these weights as needed\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft', weights=weights)\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the updated VotingClassifier model\n",
        "joblib.dump(voting_clf, 'voting_classifier_weighted.pkl')\n",
        "\n",
        "print(\"Updated VotingClassifier model saved to 'voting_classifier_weighted.pkl'\")\n",
        "\n",
        "# Load the optimal thresholds from the file\n",
        "with open('optimal_thresholds.json', 'r') as json_file:\n",
        "    optimal_thresholds = json.load(json_file)\n",
        "\n",
        "# Function to apply class-specific thresholds\n",
        "def predict_with_class_specific_thresholds(model, X, threshold_class_1, threshold_class_0):\n",
        "    y_proba = model.predict_proba(X)\n",
        "    y_pred = np.zeros(y_proba.shape[0])\n",
        "\n",
        "    # Apply thresholds to obtain predictions\n",
        "    y_pred[(y_proba[:, 1] >= threshold_class_1)] = 1  # Predict class 1 for probabilities above threshold_class_1\n",
        "    y_pred[(y_proba[:, 0] >= threshold_class_0)] = 0  # Predict class 0 for probabilities above threshold_class_0\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Predict with the updated VotingClassifier model using the optimal thresholds\n",
        "threshold_class_1 = optimal_thresholds['threshold_class_1']\n",
        "threshold_class_0 = optimal_thresholds['threshold_class_0']\n",
        "\n",
        "y_pred_voting = predict_with_class_specific_thresholds(voting_clf, X_test, threshold_class_1, threshold_class_0)\n",
        "\n",
        "# Evaluate the performance of the VotingClassifier\n",
        "recall_1 = recall_score(y_test, y_pred_voting, pos_label=1)\n",
        "precision_1 = precision_score(y_test, y_pred_voting, pos_label=1, zero_division=0)\n",
        "recall_0 = recall_score(y_test, y_pred_voting, pos_label=0)\n",
        "precision_0 = precision_score(y_test, y_pred_voting, pos_label=0, zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred_voting, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Recall Class 1: {recall_1:.4f}')\n",
        "print(f'Precision Class 1: {precision_1:.4f}')\n",
        "print(f'Recall Class 0: {recall_0:.4f}')\n",
        "print(f'Precision Class 0: {precision_0:.4f}')\n",
        "print(f'F1 Macro: {f1_macro:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFGe85q8E25r",
        "outputId": "18629878-ec15-4847-f493-e4b136d8962d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009221 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002011 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Updated VotingClassifier model saved to 'voting_classifier_weighted.pkl'\n",
            "Recall Class 1: 0.6428\n",
            "Precision Class 1: 0.4302\n",
            "Recall Class 0: 0.7582\n",
            "Precision Class 0: 0.8820\n",
            "F1 Macro: 0.6654\n",
            "Accuracy: 0.7327\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82      4673\n",
            "           1       0.43      0.64      0.52      1327\n",
            "\n",
            "    accuracy                           0.73      6000\n",
            "   macro avg       0.66      0.70      0.67      6000\n",
            "weighted avg       0.78      0.73      0.75      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparison to Best Model:\n",
        "\n",
        "#### Best Model's Performance:\n",
        "- **Class 0**:\n",
        "  - Precision: 0.99\n",
        "  - Recall: 0.87\n",
        "  - F1-Score: 0.93\n",
        "- **Class 1**:\n",
        "  - Precision: 0.68\n",
        "  - Recall: 0.95\n",
        "  - F1-Score: 0.80\n",
        "- **Accuracy**: 0.89\n",
        "- **Macro Average**:\n",
        "  - Precision: 0.83\n",
        "  - Recall: 0.91\n",
        "  - F1-Score: 0.86\n",
        "- **Weighted Average**:\n",
        "  - Precision: 0.92\n",
        "  - Recall: 0.89\n",
        "  - F1-Score: 0.90\n",
        "\n",
        "### Analysis:\n",
        "1. **Decrease in Performance**:\n",
        "   - The optimized weights did not perform as well as the best model.\n",
        "   - Significant drops in precision, recall, and F1 scores for both classes.\n",
        "   - Overall accuracy dropped from 0.89 to 0.73.\n",
        "\n",
        "2. **Class 1 Precision**:\n",
        "   - Precision for class 1 dropped from 0.68 to 0.43, indicating that a higher number of false positives were introduced.\n",
        "   - Recall for class 1 also decreased from 0.95 to 0.64, showing that the model missed more actual class 1 instances.\n",
        "\n",
        "3. **Class 0 Metrics**:\n",
        "   - Precision for class 0 remained relatively high but dropped from 0.99 to 0.88.\n",
        "   - Recall for class 0 decreased from 0.87 to 0.76, indicating the model missed more class 0 instances.\n",
        "\n",
        "### Recommendations:\n",
        "1. **Revert to Best Model**: Given the significant drop in performance, reverting to the best model configuration without additional weights is advisable.\n",
        "2. **Resampling Techniques**: Implement resampling techniques such as SMOTE, ADASYN, or undersampling to balance the class distribution and potentially improve precision and recall for class 1.\n",
        "3. **Feature Engineering**: Consider additional feature engineering to improve model performance.\n",
        "4. **Parameter Tuning**: Further parameter tuning using cross-validation might help improve model performance.\n",
        "5. **Ensemble Techniques**: Explore other ensemble techniques, such as stacking, to combine the strengths of different models more effectively.\n",
        "\n",
        "By reverting to the best model and exploring these recommendations, you can aim to achieve better performance for both classes while maintaining overall accuracy."
      ],
      "metadata": {
        "id": "NDqLsbHTYvCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decrease in performance after modifying the VotingClassifier setup, including adding more models and adjusting weights, can be attributed to several factors:\n",
        "\n",
        "#### Potential Reasons for Performance Decrease:\n",
        "\n",
        "1. **Overfitting**:\n",
        "   - **Duplicating Models**: When duplicating models or adding too many similar models, the ensemble can become overfitted to the specific patterns these models capture, reducing the diversity and robustness of the ensemble.\n",
        "   - **Model Dominance**: By weighting certain models more heavily, the ensemble may become overly reliant on these models' predictions, leading to poorer generalization on unseen data.\n",
        "\n",
        "2. **Model Interaction**:\n",
        "   - **Conflict**: Different models may have conflicting predictions, and the process of averaging probabilities (soft voting) or majority voting (hard voting) might dilute the strengths of individual models.\n",
        "   - **Thresholds**: The class-specific thresholds might not work as effectively with the new ensemble configuration, especially if the model probabilities are being averaged differently due to the new weights or added models.\n",
        "\n",
        "3. **Model Quality**:\n",
        "   - **Model Performance**: If the added models or the adjusted weights are not well-calibrated, they may introduce more noise than signal, leading to poorer overall performance.\n",
        "   - **Class Imbalance**: Even with adjustments for class weights or thresholds, the inherent class imbalance might still pose a challenge, especially if the new models handle the imbalance differently than the original ones.\n",
        "\n",
        "### Recommendations to Address Performance Decrease:\n",
        "\n",
        "1. **Revert to Best Model Configuration**:\n",
        "   - Use the best performing models and parameters identified previously without additional modifications or duplications.\n",
        "\n",
        "2. **Ensure Proper Calibration**:\n",
        "   - **Calibrate Models**: Ensure that the probabilities output by each model are well-calibrated. This can be done using techniques like Platt Scaling or Isotonic Regression.\n",
        "   - **Cross-Validation**: Use cross-validation to tune the ensemble and model parameters more effectively.\n",
        "\n",
        "3. **Resampling Techniques**:\n",
        "   - **SMOTE/ADASYN**: Implement Synthetic Minority Over-sampling Technique (SMOTE) or Adaptive Synthetic Sampling (ADASYN) to create a more balanced training set.\n",
        "   - **Undersampling**: Consider undersampling the majority class to achieve a better balance, though this may lead to a loss of information.\n",
        "\n",
        "4. **Stacking Ensemble**:\n",
        "   - Use a stacking ensemble where a meta-model learns to combine the predictions of the base models. This can often outperform simple voting ensembles by learning to trust different models in different scenarios.\n",
        "\n",
        "5. **Feature Engineering**:\n",
        "   - Create additional features that might help improve model performance, such as interaction terms or higher-order features.\n",
        "\n"
      ],
      "metadata": {
        "id": "0SVhv_u1ZQ8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load the preprocessed data (assuming the function is defined in loan_data_utils)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the column transformer\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Load the previous best models and parameters\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Create a list of (name, model) tuples for the VotingClassifier\n",
        "estimators = [\n",
        "    ('recall_class_1', best_models['recall_class_1']),\n",
        "    ('precision_class_1', best_models['precision_class_1']),\n",
        "    ('recall_class_0', best_models['recall_class_0']),\n",
        "    ('precision_class_0', best_models['precision_class_0'])\n",
        "]\n",
        "\n",
        "# Initialize the VotingClassifier with the best models using 'soft' voting and optimized weights\n",
        "weights = [2, 1, 2, 1]  # Adjust these weights as needed\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='hard', weights=weights)\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the updated VotingClassifier model\n",
        "joblib.dump(voting_clf, 'voting_classifier_weighted.pkl')\n",
        "\n",
        "print(\"Updated VotingClassifier model saved to 'voting_classifier_weighted.pkl'\")\n",
        "\n",
        "# Load the optimal thresholds from the file\n",
        "with open('optimal_thresholds.json', 'r') as json_file:\n",
        "    optimal_thresholds = json.load(json_file)\n",
        "\n",
        "# Function to apply class-specific thresholds\n",
        "def predict_with_class_specific_thresholds(model, X, threshold_class_1, threshold_class_0):\n",
        "    y_proba = model.predict_proba(X)\n",
        "    y_pred = np.zeros(y_proba.shape[0])\n",
        "\n",
        "    # Apply thresholds to obtain predictions\n",
        "    y_pred[(y_proba[:, 1] >= threshold_class_1)] = 1  # Predict class 1 for probabilities above threshold_class_1\n",
        "    y_pred[(y_proba[:, 0] >= threshold_class_0)] = 0  # Predict class 0 for probabilities above threshold_class_0\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Predict with the updated VotingClassifier model using the optimal thresholds\n",
        "threshold_class_1 = optimal_thresholds['threshold_class_1']\n",
        "threshold_class_0 = optimal_thresholds['threshold_class_0']\n",
        "\n",
        "y_pred_voting = predict_with_class_specific_thresholds(voting_clf, X_test, threshold_class_1, threshold_class_0)\n",
        "\n",
        "# Evaluate the performance of the VotingClassifier\n",
        "recall_1 = recall_score(y_test, y_pred_voting, pos_label=1)\n",
        "precision_1 = precision_score(y_test, y_pred_voting, pos_label=1, zero_division=0)\n",
        "recall_0 = recall_score(y_test, y_pred_voting, pos_label=0)\n",
        "precision_0 = precision_score(y_test, y_pred_voting, pos_label=0, zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred_voting, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Recall Class 1: {recall_1:.4f}')\n",
        "print(f'Precision Class 1: {precision_1:.4f}')\n",
        "print(f'Recall Class 0: {recall_0:.4f}')\n",
        "print(f'Precision Class 0: {precision_0:.4f}')\n",
        "print(f'F1 Macro: {f1_macro:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "QaciD-dbFh6q",
        "outputId": "fc5f6171-8c26-4409-c558-dd99d78ffb5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011705 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003375 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Updated VotingClassifier model saved to 'voting_classifier_weighted.pkl'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "predict_proba is not available when voting='hard'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4fe438ab0463>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mthreshold_class_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_thresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'threshold_class_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0my_pred_voting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_class_specific_thresholds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoting_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_class_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_class_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Evaluate the performance of the VotingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4fe438ab0463>\u001b[0m in \u001b[0;36mpredict_with_class_specific_thresholds\u001b[0;34m(model, X, threshold_class_1, threshold_class_0)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Function to apply class-specific thresholds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_with_class_specific_thresholds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_class_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_class_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0my_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_available_if.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# delegate only on instances, not the classes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# this is to allow access to the docstrings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36m_check_voting\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_voting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"hard\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    387\u001b[0m                 \u001b[0;34mf\"predict_proba is not available when voting={repr(self.voting)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when voting='hard'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Voting Classifier with Hard Voting"
      ],
      "metadata": {
        "id": "iVY4V_z-aN2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load the preprocessed data (assuming the function is defined in loan_data_utils)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the column transformer\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Load the previous best models and parameters\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Create a list of (name, model) tuples for the VotingClassifier\n",
        "estimators = [\n",
        "    ('recall_class_1', best_models['recall_class_1']),\n",
        "    ('precision_class_1', best_models['precision_class_1']),\n",
        "    ('recall_class_0', best_models['recall_class_0']),\n",
        "    ('precision_class_0', best_models['precision_class_0'])\n",
        "]\n",
        "\n",
        "# Initialize the VotingClassifier with the best models using 'hard' voting\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='hard')\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the updated VotingClassifier model\n",
        "joblib.dump(voting_clf, 'voting_classifier_hard_best.pkl')\n",
        "\n",
        "print(\"Reverted to best VotingClassifier model with 'hard' voting saved to 'voting_classifier_hard_best.pkl'\")\n",
        "\n",
        "# Predict with the updated VotingClassifier model\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the VotingClassifier\n",
        "recall_1 = recall_score(y_test, y_pred_voting, pos_label=1)\n",
        "precision_1 = precision_score(y_test, y_pred_voting, pos_label=1, zero_division=0)\n",
        "recall_0 = recall_score(y_test, y_pred_voting, pos_label=0)\n",
        "precision_0 = precision_score(y_test, y_pred_voting, pos_label=0, zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred_voting, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Recall Class 1: {recall_1:.4f}')\n",
        "print(f'Precision Class 1: {precision_1:.4f}')\n",
        "print(f'Recall Class 0: {recall_0:.4f}')\n",
        "print(f'Precision Class 0: {precision_0:.4f}')\n",
        "print(f'F1 Macro: {f1_macro:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37iy3NszZfjg",
        "outputId": "db9b114a-3f2d-488b-9a86-2ca71d2f9b0b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003522 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Reverted to best VotingClassifier model with 'hard' voting saved to 'voting_classifier_hard_best.pkl'\n",
            "Recall Class 1: 0.5705\n",
            "Precision Class 1: 0.5074\n",
            "Recall Class 0: 0.8427\n",
            "Precision Class 0: 0.8736\n",
            "F1 Macro: 0.6975\n",
            "Accuracy: 0.7825\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86      4673\n",
            "           1       0.51      0.57      0.54      1327\n",
            "\n",
            "    accuracy                           0.78      6000\n",
            "   macro avg       0.69      0.71      0.70      6000\n",
            "weighted avg       0.79      0.78      0.79      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To incorporate optimal thresholds while including multiple models for each metric and effectively utilize class-specific thresholds, you can employ a more advanced approach than simple 'hard' voting. One effective method is to use a weighted average of probabilities with additional logic to apply class-specific thresholds.\n",
        "\n",
        "### Steps to Achieve This:\n",
        "\n",
        "1. **Soft Voting for Probability Calculation**: Use soft voting to get probabilities from multiple models.\n",
        "2. **Custom Threshold Application**: Apply custom class-specific thresholds based on the predicted probabilities.\n",
        "3. **Include Multiple Models for Each Metric**: Duplicate models to give more weight to those that perform well for specific metrics.\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "1. **Soft Voting**: Use soft voting to calculate probabilities from multiple models.\n",
        "2. **Custom Thresholds**: Apply class-specific thresholds to these probabilities to get the final predictions.\n",
        "3. **Include Multiple Models**: Duplicate models to give more weight to those that perform well for specific metrics.\n",
        "\n",
        "By running this code, you can evaluate the performance of the VotingClassifier with soft voting, class-specific thresholds, and multiple models for each metric. This approach combines the advantages of probability averaging with the benefits of class-specific thresholds and model weighting."
      ],
      "metadata": {
        "id": "N-zhqFNdcWUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load the preprocessed data (assuming the function is defined in loan_data_utils)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the column transformer\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Load the previous best models and parameters\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Define the models to be duplicated\n",
        "recall_class_1_model = best_models['recall_class_1']\n",
        "precision_class_1_model = best_models['precision_class_1']\n",
        "recall_class_0_model = best_models['recall_class_0']\n",
        "precision_class_0_model = best_models['precision_class_0']\n",
        "\n",
        "# Create a list of (name, model) tuples for the VotingClassifier\n",
        "estimators = [\n",
        "    ('recall_class_1_1', recall_class_1_model),\n",
        "    ('recall_class_1_2', recall_class_1_model),\n",
        "    # ('recall_class_1_3', recall_class_1_model),\n",
        "    ('precision_class_1_1', precision_class_1_model),\n",
        "    ('precision_class_1_2', precision_class_1_model),\n",
        "    # ('precision_class_1_3', precision_class_1_model),\n",
        "    ('recall_class_0_1', recall_class_0_model),\n",
        "    # ('recall_class_0_2', recall_class_0_model),\n",
        "    ('precision_class_0_1', precision_class_0_model)\n",
        "]\n",
        "\n",
        "# Initialize the VotingClassifier with the duplicated models using 'soft' voting\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the updated VotingClassifier model\n",
        "joblib.dump(voting_clf, 'voting_classifier_soft_multiplied.pkl')\n",
        "\n",
        "print(\"Updated VotingClassifier model with soft voting and duplicated models saved to 'voting_classifier_soft_multiplied.pkl'\")\n",
        "\n",
        "# Load the optimal thresholds from the file\n",
        "with open('optimal_thresholds.json', 'r') as json_file:\n",
        "    optimal_thresholds = json.load(json_file)\n",
        "\n",
        "# Function to apply class-specific thresholds\n",
        "def predict_with_class_specific_thresholds(model, X, threshold_class_1, threshold_class_0):\n",
        "    y_proba = model.predict_proba(X)\n",
        "    y_pred = np.zeros(y_proba.shape[0])\n",
        "\n",
        "    # Apply thresholds to obtain predictions\n",
        "    y_pred[(y_proba[:, 1] >= threshold_class_1)] = 1  # Predict class 1 for probabilities above threshold_class_1\n",
        "    y_pred[(y_proba[:, 0] >= threshold_class_0)] = 0  # Predict class 0 for probabilities above threshold_class_0\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Predict with the updated VotingClassifier model using the optimal thresholds\n",
        "threshold_class_1 = optimal_thresholds['threshold_class_1']\n",
        "threshold_class_0 = optimal_thresholds['threshold_class_0']\n",
        "\n",
        "y_pred_voting = predict_with_class_specific_thresholds(voting_clf, X_test, threshold_class_1, threshold_class_0)\n",
        "\n",
        "# Evaluate the performance of the VotingClassifier\n",
        "recall_1 = recall_score(y_test, y_pred_voting, pos_label=1)\n",
        "precision_1 = precision_score(y_test, y_pred_voting, pos_label=1, zero_division=0)\n",
        "recall_0 = recall_score(y_test, y_pred_voting, pos_label=0)\n",
        "precision_0 = precision_score(y_test, y_pred_voting, pos_label=0, zero_division=0)\n",
        "f1_macro = f1_score(y_test, y_pred_voting, average='macro')\n",
        "accuracy = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Recall Class 1: {recall_1:.4f}')\n",
        "print(f'Precision Class 1: {precision_1:.4f}')\n",
        "print(f'Recall Class 0: {recall_0:.4f}')\n",
        "print(f'Precision Class 0: {precision_0:.4f}')\n",
        "print(f'F1 Macro: {f1_macro:.4f}')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRFaDmtsZz36",
        "outputId": "29f705fc-6329-4504-9d66-a51e624ce475"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001884 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Updated VotingClassifier model with soft voting and duplicated models saved to 'voting_classifier_soft_multiplied.pkl'\n",
            "Recall Class 1: 0.6458\n",
            "Precision Class 1: 0.4408\n",
            "Recall Class 0: 0.7674\n",
            "Precision Class 0: 0.8841\n",
            "F1 Macro: 0.6728\n",
            "Accuracy: 0.7405\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.77      0.82      4673\n",
            "           1       0.44      0.65      0.52      1327\n",
            "\n",
            "    accuracy                           0.74      6000\n",
            "   macro avg       0.66      0.71      0.67      6000\n",
            "weighted avg       0.79      0.74      0.76      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZcFVcY_cG7Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}