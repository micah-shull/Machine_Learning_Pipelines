{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNn6+zQZzFJxyFT2ztoedvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/pipelines/blob/main/pipelines_16_ensemble_03_resampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0BZxJGdsCQG",
        "outputId": "81a8b224-a13b-4096-ccfd-86473de565fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load & Preprocess Data"
      ],
      "metadata": {
        "id": "sebvvvCtrrTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, classification_report, make_scorer\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from loan_data_utils import load_and_preprocess_data\n",
        "import joblib\n",
        "import json\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Load and preprocess data\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "\n",
        "# Assuming the `load_and_preprocess_data` function is defined elsewhere\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "# Define the column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "ZCSvnCZI2M5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1bddca-85b4-44c5-bdcc-6ac189cdf834"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Models"
      ],
      "metadata": {
        "id": "JtQHnykXbMmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best models information from the JSON file\n",
        "with open('best_models.json', 'r') as json_file:\n",
        "    best_models = json.load(json_file)\n",
        "\n",
        "# Print out the contents of the JSON file\n",
        "print(json.dumps(best_models, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6-CraWnamj-",
        "outputId": "4168fe49-7449-4c4e-c43a-3b2d7348b1d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"recall_class_1\": \"LGBMClassifier\",\n",
            "    \"precision_class_1\": \"RandomForestClassifier\",\n",
            "    \"recall_class_0\": \"RandomForestClassifier\",\n",
            "    \"precision_class_0\": \"HistGradientBoostingClassifier\",\n",
            "    \"best_params\": {\n",
            "        \"recall_class_1\": {\n",
            "            \"classifier__force_row_wise\": true,\n",
            "            \"classifier__learning_rate\": 0.01,\n",
            "            \"classifier__n_estimators\": 200\n",
            "        },\n",
            "        \"precision_class_1\": {\n",
            "            \"classifier__max_depth\": 20,\n",
            "            \"classifier__n_estimators\": 200\n",
            "        },\n",
            "        \"recall_class_0\": {\n",
            "            \"classifier__max_depth\": 20,\n",
            "            \"classifier__n_estimators\": 200\n",
            "        },\n",
            "        \"precision_class_0\": {\n",
            "            \"classifier__learning_rate\": 0.1,\n",
            "            \"classifier__max_iter\": 100\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Models, Resampling Techniques, and Pipelines"
      ],
      "metadata": {
        "id": "SCMFC1VXr1ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score\n",
        "\n",
        "# Assuming preprocessor and data loading functions are defined elsewhere\n",
        "\n",
        "# Define candidate models\n",
        "candidate_models = {\n",
        "    'LGBM': LGBMClassifier(random_state=42, class_weight='balanced', force_row_wise=True),\n",
        "    'RF': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "    'HGB': HistGradientBoostingClassifier(random_state=42, class_weight='balanced')\n",
        "}\n",
        "\n",
        "# Define resampling methods\n",
        "resampling_methods = {\n",
        "    'SMOTE': SMOTE(random_state=42),\n",
        "    'ADASYN': ADASYN(random_state=42),\n",
        "    'UnderSampling': RandomUnderSampler(random_state=42)\n",
        "}\n",
        "\n",
        "# Create pipelines for each candidate model with resampling\n",
        "pipelines = {}\n",
        "for resampling_name, resampler in resampling_methods.items():\n",
        "    for model_name, model in candidate_models.items():\n",
        "        pipeline_name = f'{resampling_name}_{model_name}'\n",
        "        pipelines[pipeline_name] = ImbPipeline(steps=[('preprocessor', preprocessor),\n",
        "                                                      ('resampler', resampler),\n",
        "                                                      ('classifier', model)])\n",
        "\n",
        "# Function to apply class-specific thresholds\n",
        "def predict_with_class_specific_thresholds(model, X, threshold_class_1, threshold_class_0):\n",
        "    y_proba = model.predict_proba(X)\n",
        "    y_pred = np.zeros(y_proba.shape[0])\n",
        "\n",
        "    # Apply thresholds to obtain predictions\n",
        "    y_pred[y_proba[:, 1] >= threshold_class_1] = 1  # Predict class 1 for probabilities above threshold_class_1\n",
        "    y_pred[y_proba[:, 0] >= threshold_class_0] = 0  # Predict class 0 for probabilities above threshold_class_0\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# Function to evaluate models with multiple thresholds\n",
        "def evaluate_models_with_multiple_thresholds(pipelines, X_train, y_train, X_test, y_test, thresholds_class_1, thresholds_class_0):\n",
        "    results = []\n",
        "    for name, pipeline in pipelines.items():\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        for threshold_class_1 in thresholds_class_1:\n",
        "            for threshold_class_0 in thresholds_class_0:\n",
        "                y_pred = predict_with_class_specific_thresholds(pipeline, X_test, threshold_class_1, threshold_class_0)\n",
        "                recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
        "                precision_1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "                recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "                precision_0 = precision_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
        "                results.append({\n",
        "                    'Model': name,\n",
        "                    'Threshold Class 1': threshold_class_1,\n",
        "                    'Threshold Class 0': threshold_class_0,\n",
        "                    'Recall Class 1': recall_1,\n",
        "                    'Precision Class 1': precision_1,\n",
        "                    'Recall Class 0': recall_0,\n",
        "                    'Precision Class 0': precision_0\n",
        "                })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Set thresholds for evaluation\n",
        "thresholds_class_1 = np.arange(0.2, 0.5, 0.05)\n",
        "thresholds_class_0 = np.arange(0.2, 0.5, 0.05)\n",
        "\n",
        "# Assuming data is loaded and split into X_train, X_test, y_train, y_test\n",
        "# Evaluate candidate models with multiple thresholds\n",
        "evaluation_results_multiple_thresholds = evaluate_models_with_multiple_thresholds(pipelines, X_train, y_train, X_test, y_test, thresholds_class_1, thresholds_class_0)\n",
        "\n",
        "# Find the best threshold combination for each model based on F1 Macro score\n",
        "evaluation_results_multiple_thresholds['F1 Macro'] = 2 * (evaluation_results_multiple_thresholds['Precision Class 1'] * evaluation_results_multiple_thresholds['Recall Class 1']) / (evaluation_results_multiple_thresholds['Precision Class 1'] + evaluation_results_multiple_thresholds['Recall Class 1'])\n",
        "best_thresholds = evaluation_results_multiple_thresholds.loc[evaluation_results_multiple_thresholds.groupby('Model')['F1 Macro'].idxmax()]\n",
        "\n",
        "# Save the best threshold combinations to a JSON file\n",
        "best_thresholds_dict = best_thresholds.to_dict(orient='records')\n",
        "\n",
        "with open('best_thresholds.json', 'w') as json_file:\n",
        "    json.dump(best_thresholds_dict, json_file, indent=4)\n",
        "\n",
        "print(\"Best threshold combinations saved to 'best_thresholds.json'\")\n",
        "print(\"Best threshold combinations for each model:\")\n",
        "best_thresholds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "wyEtOtHycLZa",
        "outputId": "3fcf903a-d54b-4a75-b404-c3136afdfbfd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6533\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 18146, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6544\n",
            "[LightGBM] [Info] Number of data points in the train set: 36837, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Best threshold combinations saved to 'best_thresholds.json'\n",
            "Best threshold combinations for each model:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Model  Threshold Class 1  Threshold Class 0  Recall Class 1  \\\n",
              "185          ADASYN_HGB                0.2               0.45        0.393369   \n",
              "113         ADASYN_LGBM                0.2               0.45        0.386586   \n",
              "149           ADASYN_RF                0.2               0.45        0.415976   \n",
              "77            SMOTE_HGB                0.2               0.45        0.400904   \n",
              "5            SMOTE_LGBM                0.2               0.45        0.387340   \n",
              "41             SMOTE_RF                0.2               0.45        0.423512   \n",
              "293   UnderSampling_HGB                0.2               0.45        0.581763   \n",
              "221  UnderSampling_LGBM                0.2               0.45        0.599096   \n",
              "256    UnderSampling_RF                0.2               0.40        0.531274   \n",
              "\n",
              "     Precision Class 1  Recall Class 0  Precision Class 0  F1 Macro  \n",
              "185           0.617751        0.930880           0.843841  0.480663  \n",
              "113           0.646096        0.939867           0.843642  0.483734  \n",
              "149           0.580442        0.914616           0.846504  0.484636  \n",
              "77            0.610092        0.927242           0.844969  0.483856  \n",
              "5             0.628362        0.934945           0.843111  0.479254  \n",
              "41            0.580579        0.913118           0.847973  0.489760  \n",
              "293           0.502277        0.836294           0.875644  0.539106  \n",
              "221           0.482403        0.817462           0.877757  0.534454  \n",
              "256           0.527695        0.864969           0.866638  0.529478  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3ec3acc-cf03-4c03-b1bb-c96548d92482\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Threshold Class 1</th>\n",
              "      <th>Threshold Class 0</th>\n",
              "      <th>Recall Class 1</th>\n",
              "      <th>Precision Class 1</th>\n",
              "      <th>Recall Class 0</th>\n",
              "      <th>Precision Class 0</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>ADASYN_HGB</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.393369</td>\n",
              "      <td>0.617751</td>\n",
              "      <td>0.930880</td>\n",
              "      <td>0.843841</td>\n",
              "      <td>0.480663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>ADASYN_LGBM</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.386586</td>\n",
              "      <td>0.646096</td>\n",
              "      <td>0.939867</td>\n",
              "      <td>0.843642</td>\n",
              "      <td>0.483734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>ADASYN_RF</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.415976</td>\n",
              "      <td>0.580442</td>\n",
              "      <td>0.914616</td>\n",
              "      <td>0.846504</td>\n",
              "      <td>0.484636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>SMOTE_HGB</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.400904</td>\n",
              "      <td>0.610092</td>\n",
              "      <td>0.927242</td>\n",
              "      <td>0.844969</td>\n",
              "      <td>0.483856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SMOTE_LGBM</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.387340</td>\n",
              "      <td>0.628362</td>\n",
              "      <td>0.934945</td>\n",
              "      <td>0.843111</td>\n",
              "      <td>0.479254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>SMOTE_RF</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.423512</td>\n",
              "      <td>0.580579</td>\n",
              "      <td>0.913118</td>\n",
              "      <td>0.847973</td>\n",
              "      <td>0.489760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>UnderSampling_HGB</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.581763</td>\n",
              "      <td>0.502277</td>\n",
              "      <td>0.836294</td>\n",
              "      <td>0.875644</td>\n",
              "      <td>0.539106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>UnderSampling_LGBM</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.599096</td>\n",
              "      <td>0.482403</td>\n",
              "      <td>0.817462</td>\n",
              "      <td>0.877757</td>\n",
              "      <td>0.534454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>UnderSampling_RF</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.531274</td>\n",
              "      <td>0.527695</td>\n",
              "      <td>0.864969</td>\n",
              "      <td>0.866638</td>\n",
              "      <td>0.529478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3ec3acc-cf03-4c03-b1bb-c96548d92482')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3ec3acc-cf03-4c03-b1bb-c96548d92482 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3ec3acc-cf03-4c03-b1bb-c96548d92482');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df13e040-2336-4501-b111-e0bcaa454978\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df13e040-2336-4501-b111-e0bcaa454978')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df13e040-2336-4501-b111-e0bcaa454978 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6e6a0811-6bd0-4506-b4c4-74894f5a8f33\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('best_thresholds')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6e6a0811-6bd0-4506-b4c4-74894f5a8f33 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('best_thresholds');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "best_thresholds",
              "summary": "{\n  \"name\": \"best_thresholds\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"UnderSampling_LGBM\",\n          \"ADASYN_LGBM\",\n          \"SMOTE_RF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Threshold Class 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Threshold Class 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016666666666666663,\n        \"min\": 0.39999999999999997,\n        \"max\": 0.44999999999999996,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.39999999999999997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Class 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08737795043106092,\n        \"min\": 0.386586284853052,\n        \"max\": 0.5990957045968349,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.5990957045968349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Class 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05822640866432498,\n        \"min\": 0.4824029126213592,\n        \"max\": 0.646095717884131,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.4824029126213592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Class 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04602030825351991,\n        \"min\": 0.8174620158356516,\n        \"max\": 0.9398673229188957,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.8174620158356516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Class 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014551201303194785,\n        \"min\": 0.8431107680432266,\n        \"max\": 0.8777573529411765,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.8777573529411765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025624747062184882,\n        \"min\": 0.47925407925407926,\n        \"max\": 0.5391061452513967,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.534453781512605\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating Models with Multiple Thresholds"
      ],
      "metadata": {
        "id": "Bd6-HDBIdfAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the range of thresholds to test\n",
        "thresholds_class_1 = np.arange(0.2, 0.5, 0.05)\n",
        "thresholds_class_0 = np.arange(0.2, 0.5, 0.05)\n",
        "\n",
        "# Evaluate candidate models with multiple thresholds\n",
        "evaluation_results_multiple_thresholds = evaluate_models_with_multiple_thresholds(pipelines, X_train, y_train, X_test, y_test, thresholds_class_1, thresholds_class_0)\n",
        "\n",
        "# Find the best threshold combination for each model based on F1 Macro score\n",
        "evaluation_results_multiple_thresholds['F1 Macro'] = 2 * (evaluation_results_multiple_thresholds['Precision Class 1'] * evaluation_results_multiple_thresholds['Recall Class 1']) / (evaluation_results_multiple_thresholds['Precision Class 1'] + evaluation_results_multiple_thresholds['Recall Class 1'])\n",
        "best_thresholds = evaluation_results_multiple_thresholds.loc[evaluation_results_multiple_thresholds.groupby('Model')['F1 Macro'].idxmax()]\n",
        "\n",
        "# Save the best threshold combinations to a JSON file\n",
        "best_thresholds_dict = best_thresholds.to_dict(orient='records')\n",
        "with open('best_thresholds.json', 'w') as json_file:\n",
        "    json.dump(best_thresholds_dict, json_file, indent=4)\n",
        "\n",
        "print(\"Best threshold combinations saved to 'best_thresholds.json'\")\n",
        "print(\"Best threshold combinations for each model:\")\n",
        "best_thresholds\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "zKW30KhGdeyC",
        "outputId": "0f3a46a0-9e4b-4e59-804c-192a80005c0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6533\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 18146, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6544\n",
            "[LightGBM] [Info] Number of data points in the train set: 36837, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Best threshold combinations saved to 'best_thresholds.json'\n",
            "Best threshold combinations for each model:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Model  Threshold Class 1  Threshold Class 0  Recall Class 1  \\\n",
              "185          ADASYN_HGB                0.2               0.45        0.393369   \n",
              "113         ADASYN_LGBM                0.2               0.45        0.386586   \n",
              "149           ADASYN_RF                0.2               0.45        0.415976   \n",
              "77            SMOTE_HGB                0.2               0.45        0.400904   \n",
              "5            SMOTE_LGBM                0.2               0.45        0.387340   \n",
              "41             SMOTE_RF                0.2               0.45        0.423512   \n",
              "293   UnderSampling_HGB                0.2               0.45        0.581763   \n",
              "221  UnderSampling_LGBM                0.2               0.45        0.599096   \n",
              "256    UnderSampling_RF                0.2               0.40        0.531274   \n",
              "\n",
              "     Precision Class 1  Recall Class 0  Precision Class 0  F1 Macro  \n",
              "185           0.617751        0.930880           0.843841  0.480663  \n",
              "113           0.646096        0.939867           0.843642  0.483734  \n",
              "149           0.580442        0.914616           0.846504  0.484636  \n",
              "77            0.610092        0.927242           0.844969  0.483856  \n",
              "5             0.628362        0.934945           0.843111  0.479254  \n",
              "41            0.580579        0.913118           0.847973  0.489760  \n",
              "293           0.502277        0.836294           0.875644  0.539106  \n",
              "221           0.482403        0.817462           0.877757  0.534454  \n",
              "256           0.527695        0.864969           0.866638  0.529478  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60a61db7-2525-4c7c-9477-51c143bf7925\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Threshold Class 1</th>\n",
              "      <th>Threshold Class 0</th>\n",
              "      <th>Recall Class 1</th>\n",
              "      <th>Precision Class 1</th>\n",
              "      <th>Recall Class 0</th>\n",
              "      <th>Precision Class 0</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>ADASYN_HGB</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.393369</td>\n",
              "      <td>0.617751</td>\n",
              "      <td>0.930880</td>\n",
              "      <td>0.843841</td>\n",
              "      <td>0.480663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>ADASYN_LGBM</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.386586</td>\n",
              "      <td>0.646096</td>\n",
              "      <td>0.939867</td>\n",
              "      <td>0.843642</td>\n",
              "      <td>0.483734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>ADASYN_RF</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.415976</td>\n",
              "      <td>0.580442</td>\n",
              "      <td>0.914616</td>\n",
              "      <td>0.846504</td>\n",
              "      <td>0.484636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>SMOTE_HGB</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.400904</td>\n",
              "      <td>0.610092</td>\n",
              "      <td>0.927242</td>\n",
              "      <td>0.844969</td>\n",
              "      <td>0.483856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SMOTE_LGBM</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.387340</td>\n",
              "      <td>0.628362</td>\n",
              "      <td>0.934945</td>\n",
              "      <td>0.843111</td>\n",
              "      <td>0.479254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>SMOTE_RF</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.423512</td>\n",
              "      <td>0.580579</td>\n",
              "      <td>0.913118</td>\n",
              "      <td>0.847973</td>\n",
              "      <td>0.489760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>UnderSampling_HGB</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.581763</td>\n",
              "      <td>0.502277</td>\n",
              "      <td>0.836294</td>\n",
              "      <td>0.875644</td>\n",
              "      <td>0.539106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>UnderSampling_LGBM</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.599096</td>\n",
              "      <td>0.482403</td>\n",
              "      <td>0.817462</td>\n",
              "      <td>0.877757</td>\n",
              "      <td>0.534454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>UnderSampling_RF</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.531274</td>\n",
              "      <td>0.527695</td>\n",
              "      <td>0.864969</td>\n",
              "      <td>0.866638</td>\n",
              "      <td>0.529478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60a61db7-2525-4c7c-9477-51c143bf7925')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60a61db7-2525-4c7c-9477-51c143bf7925 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60a61db7-2525-4c7c-9477-51c143bf7925');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2fd1f355-2258-4b53-98d6-1f67ce5ace30\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2fd1f355-2258-4b53-98d6-1f67ce5ace30')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2fd1f355-2258-4b53-98d6-1f67ce5ace30 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3490281e-485c-4dcd-87e5-a22681b0a85e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('best_thresholds')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3490281e-485c-4dcd-87e5-a22681b0a85e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('best_thresholds');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "best_thresholds",
              "summary": "{\n  \"name\": \"best_thresholds\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"UnderSampling_LGBM\",\n          \"ADASYN_LGBM\",\n          \"SMOTE_RF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Threshold Class 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Threshold Class 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016666666666666663,\n        \"min\": 0.39999999999999997,\n        \"max\": 0.44999999999999996,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.39999999999999997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Class 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08737795043106092,\n        \"min\": 0.386586284853052,\n        \"max\": 0.5990957045968349,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.5990957045968349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Class 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05822640866432498,\n        \"min\": 0.4824029126213592,\n        \"max\": 0.646095717884131,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.4824029126213592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Class 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04602030825351991,\n        \"min\": 0.8174620158356516,\n        \"max\": 0.9398673229188957,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.8174620158356516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Class 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014551201303194785,\n        \"min\": 0.8431107680432266,\n        \"max\": 0.8777573529411765,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.8777573529411765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025624747062184882,\n        \"min\": 0.47925407925407926,\n        \"max\": 0.5391061452513967,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.534453781512605\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Custom Scorers and the Tuning Function"
      ],
      "metadata": {
        "id": "0nwQl-SEdm3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer, recall_score, precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Custom scorers for recall and precision for class 0 and class 1\n",
        "scorers = {\n",
        "    'recall_class_1': make_scorer(recall_score, pos_label=1),\n",
        "    'precision_class_1': make_scorer(precision_score, pos_label=1),\n",
        "    'recall_class_0': make_scorer(recall_score, pos_label=0),\n",
        "    'precision_class_0': make_scorer(precision_score, pos_label=0)\n",
        "}\n",
        "\n",
        "# Function to perform grid search for a given model\n",
        "def tune_model(pipeline, param_grid, X_train, y_train, scoring):\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scoring)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search\n",
        "\n",
        "# Function to tune and save models\n",
        "def tune_and_save_models(pipelines, param_grids, X_train, y_train, best_thresholds_df, scorers):\n",
        "    best_models = {}\n",
        "    best_params = {}\n",
        "\n",
        "    for metric, scorer in scorers.items():\n",
        "        if 'recall' in metric:\n",
        "            class_num = metric.split('_')[-1]\n",
        "            model_name = best_thresholds_df.loc[best_thresholds_df[f'Recall Class {class_num}'].idxmax(), 'Model']\n",
        "        else:\n",
        "            class_num = metric.split('_')[-1]\n",
        "            model_name = best_thresholds_df.loc[best_thresholds_df[f'Precision Class {class_num}'].idxmax(), 'Model']\n",
        "\n",
        "        tuned_model = tune_model(pipelines[model_name], param_grids[model_name.split('_')[-1]], X_train, y_train, scoring=scorer)\n",
        "\n",
        "        best_models[metric] = tuned_model.best_estimator_\n",
        "        best_params[metric] = tuned_model.best_params_\n",
        "\n",
        "        # Save each model individually\n",
        "        joblib.dump(tuned_model.best_estimator_, f'best_model_{metric}.pkl')\n",
        "        print(f\"Best model for {metric} saved to 'best_model_{metric}.pkl'\")\n",
        "\n",
        "    with open('best_params.json', 'w') as json_file:\n",
        "        json.dump(best_params, json_file, indent=4)\n",
        "    print(f\"Best parameters saved to 'best_params.json'\")\n",
        "\n",
        "    return best_models, best_params\n"
      ],
      "metadata": {
        "id": "sXS5t4_gdevL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining Parameter Grids for Model Tuning"
      ],
      "metadata": {
        "id": "-B4DRM8Hej9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grids for the selected models\n",
        "param_grids = {\n",
        "    # 'LogReg': {'classifier__C': [0.1, 1, 10]},\n",
        "    'RF': {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]},\n",
        "    'LGBM': {'classifier__n_estimators': [100, 200], 'classifier__learning_rate': [0.01, 0.1]},\n",
        "    'HGB': {'classifier__max_iter': [100, 200], 'classifier__learning_rate': [0.01, 0.1]}\n",
        "}"
      ],
      "metadata": {
        "id": "mFClFWcqdetG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning and Saving Models (Step 1: Recall for Class 1)"
      ],
      "metadata": {
        "id": "J1JvMQ-feu7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best threshold combinations\n",
        "with open('best_thresholds.json', 'r') as json_file:\n",
        "    best_thresholds = json.load(json_file)\n",
        "best_thresholds_df = pd.DataFrame(best_thresholds)\n",
        "\n",
        "# File names for saving the best models and parameters\n",
        "best_models_file_recall_class_1 = 'best_model_recall_class_1.pkl'\n",
        "best_params_file_recall_class_1 = 'best_params_recall_class_1.json'\n",
        "\n",
        "# Tune and save models for recall for class 1\n",
        "best_models_recall_class_1 = {}\n",
        "best_params_recall_class_1 = {}\n",
        "\n",
        "# Get the best model name for recall class 1\n",
        "model_name_recall_class_1 = best_thresholds_df.loc[best_thresholds_df['Recall Class 1'].idxmax(), 'Model']\n",
        "\n",
        "# Perform tuning for recall class 1\n",
        "tuned_model_recall_class_1 = tune_model(pipelines[model_name_recall_class_1], param_grids[model_name_recall_class_1.split('_')[-1]], X_train, y_train, scoring=scorers['recall_class_1'])\n",
        "\n",
        "best_models_recall_class_1['recall_class_1'] = tuned_model_recall_class_1.best_estimator_\n",
        "best_params_recall_class_1['recall_class_1'] = tuned_model_recall_class_1.best_params_\n",
        "\n",
        "# Save the best models for recall class 1\n",
        "joblib.dump(best_models_recall_class_1, best_models_file_recall_class_1)\n",
        "print(f\"Best models for recall class 1 saved to '{best_models_file_recall_class_1}'\")\n",
        "\n",
        "# Save the best parameters for recall class 1\n",
        "with open(best_params_file_recall_class_1, 'w') as json_file:\n",
        "    json.dump(best_params_recall_class_1, json_file, indent=4)\n",
        "print(f\"Best parameters for recall class 1 saved to '{best_params_file_recall_class_1}'\")\n",
        "\n",
        "# Print the best parameters for recall for class 1\n",
        "for metric, params in best_params_recall_class_1.items():\n",
        "    print(f\"Best parameters for {metric}: {params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN6zLQCpderA",
        "outputId": "1ad3683a-df8d-4baa-aa01-194ce67afa22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Best models for recall class 1 saved to 'best_model_recall_class_1.pkl'\n",
            "Best parameters for recall class 1 saved to 'best_params_recall_class_1.json'\n",
            "Best parameters for recall_class_1: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning and Saving Models (Step 2: Precision for Class 1)"
      ],
      "metadata": {
        "id": "6m7eP67Fe3UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File names for saving the best models and parameters\n",
        "best_models_file_precision_class_1 = 'best_model_precision_class_1.pkl'\n",
        "best_params_file_precision_class_1 = 'best_params_precision_class_1.json'\n",
        "\n",
        "# Tune and save models for precision for class 1\n",
        "best_models_precision_class_1 = {}\n",
        "best_params_precision_class_1 = {}\n",
        "\n",
        "# Get the best model name for precision class 1\n",
        "model_name_precision_class_1 = best_thresholds_df.loc[best_thresholds_df['Precision Class 1'].idxmax(), 'Model']\n",
        "\n",
        "# Perform tuning for precision class 1\n",
        "tuned_model_precision_class_1 = tune_model(pipelines[model_name_precision_class_1], param_grids[model_name_precision_class_1.split('_')[-1]], X_train, y_train, scoring=scorers['precision_class_1'])\n",
        "\n",
        "best_models_precision_class_1['precision_class_1'] = tuned_model_precision_class_1.best_estimator_\n",
        "best_params_precision_class_1['precision_class_1'] = tuned_model_precision_class_1.best_params_\n",
        "\n",
        "# Save the best models for precision class 1\n",
        "joblib.dump(best_models_precision_class_1, best_models_file_precision_class_1)\n",
        "print(f\"Best models for precision class 1 saved to '{best_models_file_precision_class_1}'\")\n",
        "\n",
        "# Save the best parameters for precision class 1\n",
        "with open(best_params_file_precision_class_1, 'w') as json_file:\n",
        "    json.dump(best_params_precision_class_1, json_file, indent=4)\n",
        "print(f\"Best parameters for precision class 1 saved to '{best_params_file_precision_class_1}'\")\n",
        "\n",
        "# Print the best parameters for precision for class 1\n",
        "for metric, params in best_params_precision_class_1.items():\n",
        "    print(f\"Best parameters for {metric}: {params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hv8C7gIden4",
        "outputId": "fef8af9f-35ba-40a0-daee-6a2c93855a6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 18146, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6544\n",
            "[LightGBM] [Info] Number of data points in the train set: 36837, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "Best models for precision class 1 saved to 'best_model_precision_class_1.pkl'\n",
            "Best parameters for precision class 1 saved to 'best_params_precision_class_1.json'\n",
            "Best parameters for precision_class_1: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning and Saving Models (Step 3: Recall for Class 0)"
      ],
      "metadata": {
        "id": "jwGp18_we_xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File names for saving the best models and parameters\n",
        "best_models_file_recall_class_0 = 'best_model_recall_class_0.pkl'\n",
        "best_params_file_recall_class_0 = 'best_params_recall_class_0.json'\n",
        "\n",
        "# Tune and save models for recall for class 0\n",
        "best_models_recall_class_0 = {}\n",
        "best_params_recall_class_0 = {}\n",
        "\n",
        "# Get the best model name for recall class 0\n",
        "model_name_recall_class_0 = best_thresholds_df.loc[best_thresholds_df['Recall Class 0'].idxmax(), 'Model']\n",
        "\n",
        "# Perform tuning for recall class 0\n",
        "tuned_model_recall_class_0 = tune_model(pipelines[model_name_recall_class_0], param_grids[model_name_recall_class_0.split('_')[-1]], X_train, y_train, scoring=scorers['recall_class_0'])\n",
        "\n",
        "best_models_recall_class_0['recall_class_0'] = tuned_model_recall_class_0.best_estimator_\n",
        "best_params_recall_class_0['recall_class_0'] = tuned_model_recall_class_0.best_params_\n",
        "\n",
        "# Save the best models for recall class 0\n",
        "joblib.dump(best_models_recall_class_0, best_models_file_recall_class_0)\n",
        "print(f\"Best models for recall class 0 saved to '{best_models_file_recall_class_0}'\")\n",
        "\n",
        "# Save the best parameters for recall class 0\n",
        "with open(best_params_file_recall_class_0, 'w') as json_file:\n",
        "    json.dump(best_params_recall_class_0, json_file, indent=4)\n",
        "print(f\"Best parameters for recall class 0 saved to '{best_params_file_recall_class_0}'\")\n",
        "\n",
        "# Print the best parameters for recall for class 0\n",
        "for metric, params in best_params_recall_class_0.items():\n",
        "    print(f\"Best parameters for {metric}: {params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RJWYb_1delA",
        "outputId": "96403212-de7a-46da-861d-a899b5247eaf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14566, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6560\n",
            "[LightGBM] [Info] Number of data points in the train set: 29518, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14573, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "[LightGBM] [Info] Number of positive: 14508, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6543\n",
            "[LightGBM] [Info] Number of data points in the train set: 29461, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14633, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29586, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 14527, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6539\n",
            "[LightGBM] [Info] Number of data points in the train set: 29480, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 18146, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6544\n",
            "[LightGBM] [Info] Number of data points in the train set: 36837, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "Best models for recall class 0 saved to 'best_model_recall_class_0.pkl'\n",
            "Best parameters for recall class 0 saved to 'best_params_recall_class_0.json'\n",
            "Best parameters for recall_class_0: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning and Saving Models (Step 4: Precision for Class 0)"
      ],
      "metadata": {
        "id": "0ccBGIFVfEzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File names for saving the best models and parameters\n",
        "best_models_file_precision_class_0 = 'best_model_precision_class_0.pkl'\n",
        "best_params_file_precision_class_0 = 'best_params_precision_class_0.json'\n",
        "\n",
        "# Tune and save models for precision for class 0\n",
        "best_models_precision_class_0 = {}\n",
        "best_params_precision_class_0 = {}\n",
        "\n",
        "# Get the best model name for precision class 0\n",
        "model_name_precision_class_0 = best_thresholds_df.loc[best_thresholds_df['Precision Class 0'].idxmax(), 'Model']\n",
        "\n",
        "# Perform tuning for precision class 0\n",
        "tuned_model_precision_class_0 = tune_model(pipelines[model_name_precision_class_0], param_grids[model_name_precision_class_0.split('_')[-1]], X_train, y_train, scoring=scorers['precision_class_0'])\n",
        "\n",
        "best_models_precision_class_0['precision_class_0'] = tuned_model_precision_class_0.best_estimator_\n",
        "best_params_precision_class_0['precision_class_0'] = tuned_model_precision_class_0.best_params_\n",
        "\n",
        "# Save the best models for precision class 0\n",
        "joblib.dump(best_models_precision_class_0, best_models_file_precision_class_0)\n",
        "print(f\"Best models for precision class 0 saved to '{best_models_file_precision_class_0}'\")\n",
        "\n",
        "# Save the best parameters for precision class 0\n",
        "with open(best_params_file_precision_class_0, 'w') as json_file:\n",
        "    json.dump(best_params_precision_class_0, json_file, indent=4)\n",
        "print(f\"Best parameters for precision class 0 saved to '{best_params_file_precision_class_0}'\")\n",
        "\n",
        "# Print the best parameters for precision for class 0\n",
        "for metric, params in best_params_precision_class_0.items():\n",
        "    print(f\"Best parameters for {metric}: {params}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg9Tiv1pdei7",
        "outputId": "d3a6e2a3-f56e-4525-afbb-2e5001b8b528"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3254\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Best models for precision class 0 saved to 'best_model_precision_class_0.pkl'\n",
            "Best parameters for precision class 0 saved to 'best_params_precision_class_0.json'\n",
            "Best parameters for precision_class_0: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the best models and parameters for class 0 recall and precision\n",
        "best_models = joblib.load('best_models.pkl')\n",
        "with open('best_params.json', 'r') as json_file:\n",
        "    best_params = json.load(json_file)\n",
        "\n",
        "# Load the best threshold combinations\n",
        "with open('best_thresholds.json', 'r') as json_file:\n",
        "    best_thresholds = json.load(json_file)\n",
        "\n",
        "# Function to print model details\n",
        "def print_model_details(metric, model, params):\n",
        "    model_name = model.__class__.__name__\n",
        "    print(f\"{metric}: {model_name}\")\n",
        "    print(f\"Parameters:\")\n",
        "    for param, value in params.items():\n",
        "        print(f\"  {param}: {value}\")\n",
        "\n",
        "# Print best models and parameters\n",
        "print(\"Best Models and Parameters:\\n\")\n",
        "for metric in ['recall_class_1', 'precision_class_1', 'recall_class_0', 'precision_class_0']:\n",
        "    print_model_details(metric, best_models[metric], best_params[metric])\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Print best thresholds\n",
        "print(\"Best Thresholds:\\n\")\n",
        "best_thresholds_df = pd.DataFrame(best_thresholds)\n",
        "print(best_thresholds_df[['Model', 'Threshold Class 1', 'Threshold Class 0']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4LQI0qbmhZpp",
        "outputId": "08abfccd-af4b-4068-f1e9-7697688429b7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best_models.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-eb8f4b125899>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the best models and parameters for class 0 recall and precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbest_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_models.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_params.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_models.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Evaluate Voting Classifier"
      ],
      "metadata": {
        "id": "1BAjhMDns3Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Load the best models and parameters\n",
        "best_model_recall_class_1 = joblib.load('best_model_recall_class_1.pkl')\n",
        "best_model_precision_class_1 = joblib.load('best_model_precision_class_1.pkl')\n",
        "best_model_recall_class_0 = joblib.load('best_model_recall_class_0.pkl')\n",
        "best_model_precision_class_0 = joblib.load('best_model_precision_class_0.pkl')\n",
        "\n",
        "# Initialize the VotingClassifier with all four models\n",
        "voting_clf_optimized = VotingClassifier(estimators=[\n",
        "    ('recall_class_1', best_model_recall_class_1),\n",
        "    ('precision_class_1', best_model_precision_class_1),\n",
        "    ('recall_class_0', best_model_recall_class_0),\n",
        "    ('precision_class_0', best_model_precision_class_0)\n",
        "], voting='soft')\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Extract thresholds for evaluation\n",
        "with open('best_thresholds.json', 'r') as json_file:\n",
        "    best_thresholds = json.load(json_file)\n",
        "best_thresholds_df = pd.DataFrame(best_thresholds)\n",
        "\n",
        "THRESHOLD_CLASS_1 = best_thresholds_df.loc[best_thresholds_df['Model'] == 'LGBM', 'Threshold Class 1'].values[0]\n",
        "THRESHOLD_CLASS_0 = best_thresholds_df.loc[best_thresholds_df['Model'] == 'LGBM', 'Threshold Class 0'].values[0]\n",
        "\n",
        "# Predict with the VotingClassifier\n",
        "y_pred_voting_optimized = predict_with_class_specific_thresholds(voting_clf_optimized, X_test, THRESHOLD_CLASS_1, THRESHOLD_CLASS_0)\n",
        "\n",
        "def evaluate_and_print_performance(y_test, y_pred, classifier_name):\n",
        "    recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
        "    precision_1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "    precision_0 = precision_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{classifier_name} Performance:\")\n",
        "    print(f'Recall Class 1: {recall_1:.4f}')\n",
        "    print(f'Precision Class 1: {precision_1:.4f}')\n",
        "    print(f'Recall Class 0: {recall_0:.4f}')\n",
        "    print(f'Precision Class 0: {precision_0:.4f}')\n",
        "    print(f'F1 Macro: {f1_macro:.4f}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f\"\\nClassification Report for {classifier_name}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluate and print performance for VotingClassifier\n",
        "evaluate_and_print_performance(y_test, y_pred_voting_optimized, \"Optimized VotingClassifier\")\n",
        "\n",
        "# Combine the results into a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Recall Class 1', 'Precision Class 1', 'Recall Class 0', 'Precision Class 0', 'F1 Macro', 'Accuracy'],\n",
        "    'Optimized VotingClassifier': [recall_1, precision_1, recall_0, precision_0, f1_macro, accuracy]\n",
        "})\n",
        "\n",
        "# Set the Metric column as the index\n",
        "results.set_index('Metric', inplace=True)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.barplot(data=results.reset_index().melt(id_vars='Metric', var_name='Model', value_name='Score'),\n",
        "            x='Metric', y='Score', hue='Model', palette='viridis')\n",
        "\n",
        "plt.title('Performance Comparison: Optimized VotingClassifier', fontsize=16)\n",
        "plt.ylabel('Score', fontsize=14)\n",
        "plt.xlabel('Metric', fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(loc='upper right', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the final VotingClassifier model\n",
        "joblib.dump(voting_clf_optimized, 'voting_classifier_optimized.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "xaNMey-1q45Z",
        "outputId": "ddaf2df3-01df-42a0-8a9a-66a26c159c94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The estimator dict should be a classifier.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a44c812a0747>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Fit the VotingClassifier on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mvoting_clf_optimized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Extract thresholds for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"drop\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    283\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[1;32m    284\u001b[0m                         \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The estimator dict should be a classifier."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Load the best models and parameters\n",
        "best_models_recall_class_1 = joblib.load('best_model_recall_class_1.pkl')\n",
        "best_models_precision_class_1 = joblib.load('best_model_precision_class_1.pkl')\n",
        "best_models_recall_class_0 = joblib.load('best_model_recall_class_0.pkl')\n",
        "best_models_precision_class_0 = joblib.load('best_model_precision_class_0.pkl')\n",
        "\n",
        "# Initialize the VotingClassifier with all four models\n",
        "voting_clf_optimized = VotingClassifier(estimators=[\n",
        "    ('recall_class_1', best_models_recall_class_1['classifier']),\n",
        "    ('precision_class_1', best_models_precision_class_1['classifier']),\n",
        "    ('recall_class_0', best_models_recall_class_0['classifier']),\n",
        "    ('precision_class_0', best_models_precision_class_0['classifier'])\n",
        "], voting='soft')\n",
        "\n",
        "# Fit the VotingClassifier on the training data\n",
        "voting_clf_optimized.fit(X_train, y_train)\n",
        "\n",
        "# Set thresholds for evaluation\n",
        "THRESHOLD_CLASS_1 = best_thresholds_df.loc[best_thresholds_df['Model'] == 'LGBM', 'Threshold Class 1'].values[0]\n",
        "THRESHOLD_CLASS_0 = best_thresholds_df.loc[best_thresholds_df['Model'] == 'LGBM', 'Threshold Class 0'].values[0]\n",
        "\n",
        "# Predict with the VotingClassifier\n",
        "y_pred_voting_optimized = predict_with_class_specific_thresholds(voting_clf_optimized, X_test, THRESHOLD_CLASS_1, THRESHOLD_CLASS_0)\n",
        "\n",
        "def evaluate_and_print_performance(y_test, y_pred, classifier_name):\n",
        "    recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
        "    precision_1 = precision_score(y_test, y_pred, pos_label=1, zero_division=0)\n",
        "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
        "    precision_0 = precision_score(y_test, y_pred, pos_label=0, zero_division=0)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{classifier_name} Performance:\")\n",
        "    print(f'Recall Class 1: {recall_1:.4f}')\n",
        "    print(f'Precision Class 1: {precision_1:.4f}')\n",
        "    print(f'Recall Class 0: {recall_0:.4f}')\n",
        "    print(f'Precision Class 0: {precision_0:.4f}')\n",
        "    print(f'F1 Macro: {f1_macro:.4f}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f\"\\nClassification Report for {classifier_name}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluate and print performance for VotingClassifier\n",
        "evaluate_and_print_performance(y_test, y_pred_voting_optimized, \"Optimized VotingClassifier\")\n",
        "\n",
        "# Combine the results into a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Recall Class 1', 'Precision Class 1', 'Recall Class 0', 'Precision Class 0', 'F1 Macro', 'Accuracy'],\n",
        "    'Optimized VotingClassifier': [recall_1, precision_1, recall_0, precision_0, f1_macro, accuracy]\n",
        "})\n",
        "\n",
        "# Set the Metric column as the index\n",
        "results.set_index('Metric', inplace=True)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.barplot(data=results.reset_index().melt(id_vars='Metric', var_name='Model', value_name='Score'),\n",
        "            x='Metric', y='Score', hue='Model', palette='viridis')\n",
        "\n",
        "plt.title('Performance Comparison: Optimized VotingClassifier', fontsize=16)\n",
        "plt.ylabel('Score', fontsize=14)\n",
        "plt.xlabel('Metric', fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(loc='upper right', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the final VotingClassifier model\n",
        "joblib.dump(voting_clf_optimized, 'voting_classifier_optimized.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jN5whpoSim-2",
        "outputId": "c07ab205-4041-40f1-9c94-646c4b49ddaa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'classifier'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-133845f22045>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Initialize the VotingClassifier with all four models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m voting_clf_optimized = VotingClassifier(estimators=[\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'recall_class_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_models_recall_class_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'precision_class_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_models_precision_class_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'recall_class_0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_models_recall_class_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'classifier'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Evaluate Stacking Classifier"
      ],
      "metadata": {
        "id": "w80d2Wx8icSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare Classifiers"
      ],
      "metadata": {
        "id": "XiiWHad7if3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy for both models\n",
        "accuracy_voting = accuracy_score(y_test, y_pred_voting_optimized)\n",
        "accuracy_stacking = accuracy_score(y_test, y_pred_stacking_optimized)\n",
        "\n",
        "# Combine the results into a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Recall Class 1', 'Precision Class 1', 'Recall Class 0', 'Precision Class 0', 'F1 Macro', 'Accuracy'],\n",
        "    'VotingClassifier': [recall_score(y_test, y_pred_voting_optimized, pos_label=1),\n",
        "                         precision_score(y_test, y_pred_voting_optimized, pos_label=1, zero_division=0),\n",
        "                         recall_score(y_test, y_pred_voting_optimized, pos_label=0),\n",
        "                         precision_score(y_test, y_pred_voting_optimized, pos_label=0, zero_division=0),\n",
        "                         f1_score(y_test, y_pred_voting_optimized, average='macro'),\n",
        "                         accuracy_voting],\n",
        "    'StackingClassifier': [recall_score(y_test, y_pred_stacking_optimized, pos_label=1),\n",
        "                           precision_score(y_test, y_pred_stacking_optimized, pos_label=1, zero_division=0),\n",
        "                           recall_score(y_test, y_pred_stacking_optimized, pos_label=0),\n",
        "                           precision_score(y_test, y_pred_stacking_optimized, pos_label=0, zero_division=0),\n",
        "                           f1_score(y_test, y_pred_stacking_optimized, average='macro'),\n",
        "                           accuracy_stacking]\n",
        "})\n",
        "\n",
        "# Set the Metric column as the index\n",
        "results.set_index('Metric', inplace=True)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.barplot(data=results.reset_index().melt(id_vars='Metric', var_name='Model', value_name='Score'),\n",
        "            x='Metric', y='Score', hue='Model', palette='viridis')\n",
        "\n",
        "plt.title('Performance Comparison: VotingClassifier vs. StackingClassifier', fontsize=16)\n",
        "plt.ylabel('Score', fontsize=14)\n",
        "plt.xlabel('Metric', fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(loc='upper right', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QgG6RAyqisj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy for both models\n",
        "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
        "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
        "\n",
        "# Combine the results into a DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'Metric': ['Recall Class 1', 'Precision Class 1', 'Recall Class 0', 'Precision Class 0', 'F1 Macro', 'Accuracy'],\n",
        "    'VotingClassifier': [recall_1_voting, precision_1_voting, recall_0_voting, precision_0_voting, f1_macro_voting, accuracy_voting],\n",
        "    'StackingClassifier': [recall_1_stacking, precision_1_stacking, recall_0_stacking, precision_0_stacking, f1_macro_stacking, accuracy_stacking]\n",
        "})\n",
        "\n",
        "# Set the Metric column as the index\n",
        "results.set_index('Metric', inplace=True)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.barplot(data=results.reset_index().melt(id_vars='Metric', var_name='Model', value_name='Score'),\n",
        "            x='Metric', y='Score', hue='Model', palette='viridis')\n",
        "\n",
        "plt.title('Performance Comparison: VotingClassifier vs. StackingClassifier', fontsize=16)\n",
        "plt.ylabel('Score', fontsize=14)\n",
        "plt.xlabel('Metric', fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(loc='upper right', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FQJg5ebY-eQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "nHQeCznb-zcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation of Results\n",
        "\n",
        "1. **Recall for Class 1 (Loan Defaults)**:\n",
        "   - VotingClassifier: 0.583\n",
        "   - StackingClassifier: 0.399\n",
        "   - The VotingClassifier shows a higher recall for class 1, indicating it is better at identifying loan defaults.\n",
        "\n",
        "2. **Precision for Class 1 (Loan Defaults)**:\n",
        "   - VotingClassifier: 0.491\n",
        "   - StackingClassifier: 0.641\n",
        "   - The StackingClassifier has higher precision for class 1, meaning it has fewer false positives compared to the VotingClassifier.\n",
        "\n",
        "3. **Recall for Class 0 (Non-Defaults)**:\n",
        "   - VotingClassifier: 0.828\n",
        "   - StackingClassifier: 0.937\n",
        "   - The StackingClassifier shows higher recall for class 0, indicating it is better at identifying non-defaults.\n",
        "\n",
        "4. **Precision for Class 0 (Non-Defaults)**:\n",
        "   - VotingClassifier: 0.875\n",
        "   - StackingClassifier: 0.846\n",
        "   - The VotingClassifier has a slightly higher precision for class 0.\n",
        "\n",
        "5. **F1 Macro**:\n",
        "   - VotingClassifier: 0.692\n",
        "   - StackingClassifier: 0.690\n",
        "   - The F1 Macro scores are quite close, with the VotingClassifier having a marginally higher score.\n",
        "\n",
        "6. **Accuracy**:\n",
        "   - VotingClassifier: 0.774\n",
        "   - StackingClassifier: 0.818\n",
        "   - The StackingClassifier has higher overall accuracy.\n",
        "\n",
        "### Recommendations for Next Steps\n",
        "\n",
        "1. **Further Improve Recall for Class 1**:\n",
        "   - **Adjust Class Weights**: Consider adjusting the class weights further to give more importance to class 1 (loan defaults) in both classifiers.\n",
        "   - **Threshold Tuning**: Explore a wider range of thresholds specifically targeting the recall for class 1. Lower thresholds might help improve recall.\n",
        "\n",
        "2. **Balancing Precision and Recall**:\n",
        "   - **Combine Models**: Experiment with combining models that have high recall and high precision for class 1 in an ensemble.\n",
        "   - **Stacking with Weighted Voting**: Instead of simple stacking, try weighted voting where models that perform better on class 1 are given higher weights.\n",
        "\n",
        "3. **Use of Advanced Resampling Techniques**:\n",
        "   - **SMOTE with Tomek Links**: This combination can help improve the quality of the synthetic samples and remove borderline cases.\n",
        "   - **ADASYN**: Adaptive Synthetic Sampling can generate more synthetic data for minority class instances that are harder to learn.\n",
        "\n",
        "4. **Feature Engineering**:\n",
        "   - **Interaction Features**: Create new features by interacting existing features to capture complex relationships.\n",
        "   - **Domain-Specific Features**: Add domain-specific features that could provide better signals for loan defaults.\n",
        "\n",
        "5. **Hyperparameter Tuning**:\n",
        "   - **Grid Search**: Perform a more exhaustive grid search over hyperparameters, especially focusing on the parameters that control the balance between precision and recall.\n",
        "   - **Random Search**: Use random search for hyperparameter optimization over a broader range of values.\n",
        "\n",
        "6. **Model Interpretability**:\n",
        "   - **SHAP Values**: Use SHAP values to understand the impact of features on the predictions. This can provide insights into which features are most important for predicting loan defaults.\n",
        "\n",
        "By focusing on these areas, you can work towards achieving higher recall for class 1 while maintaining high precision, thereby improving the overall performance of your loan default prediction model."
      ],
      "metadata": {
        "id": "rnJNnv28_99_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uI8lk8M7__0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}