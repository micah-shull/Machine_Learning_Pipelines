{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGTtOIYdkndMhOhMPN4K9H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/pipelines/blob/main/pipelines_16_ensemble_046.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWdz2exivxPM",
        "outputId": "c09d6074-ea2c-492a-a9b0-4f049fab46f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Problem of Class Imbalance\n",
        "\n",
        "**Class imbalance** occurs when one class in a dataset significantly outnumbers the other classes. This is common in many real-world scenarios, such as fraud detection, medical diagnoses, and loan defaults. In such cases, the majority class (the more frequent class) dominates the dataset, while the minority class (the less frequent class) is underrepresented.\n",
        "\n",
        "### Impact on Model Performance\n",
        "\n",
        "When training a machine learning model on imbalanced data, the model tends to become biased towards the majority class. This bias can lead to the following issues:\n",
        "\n",
        "1. **High Accuracy but Poor Minority Class Performance**: The model may achieve high overall accuracy by simply predicting the majority class most of the time. However, it will likely perform poorly on the minority class, failing to identify critical instances.\n",
        "\n",
        "2. **High Precision and Recall for the Majority Class**: Precision and recall scores for the majority class may be high because the model is good at predicting the majority class correctly. However, this often comes at the expense of poor performance for the minority class.\n",
        "\n",
        "3. **Low Precision and Recall for the Minority Class**: Precision and recall scores for the minority class are typically low because the model struggles to correctly identify minority class instances. This is problematic in scenarios where identifying the minority class correctly is crucial (e.g., detecting fraudulent transactions or diagnosing diseases).\n",
        "\n",
        "### Checking for Class Imbalance Issues\n",
        "\n",
        "To check for the impact of class imbalance on model performance, you can:\n",
        "\n",
        "1. **Analyze Class Distribution**: Examine the distribution of classes in your dataset. If there is a significant imbalance, it indicates a potential issue.\n",
        "\n",
        "2. **Evaluate Precision and Recall Scores**: Assess precision and recall scores for both the majority and minority classes. High precision and recall for the majority class and low scores for the minority class suggest that the model is biased towards the majority class.\n",
        "\n",
        "3. **Confusion Matrix**: A confusion matrix provides a detailed breakdown of true positives, false positives, true negatives, and false negatives for each class. This helps in understanding how well the model performs on each class.\n",
        "\n",
        "4. **F1 Score**: The F1 score, which is the harmonic mean of precision and recall, can be calculated for both classes. A low F1 score for the minority class indicates poor performance.\n",
        "\n",
        "### Addressing Class Imbalance\n",
        "\n",
        "To address class imbalance and improve model performance on the minority class, you can:\n",
        "\n",
        "1. **Resampling Techniques**: Use techniques like oversampling (e.g., SMOTE) to increase the number of minority class instances, or undersampling to reduce the number of majority class instances.\n",
        "\n",
        "2. **Class Weight Adjustment**: Adjust class weights in your model to give more importance to the minority class. This helps the model focus on learning to identify minority class instances better.\n",
        "\n",
        "3. **Ensemble Methods**: Use ensemble methods like bagging and boosting, which can help improve the performance of models on imbalanced data.\n",
        "\n",
        "4. **Threshold Tuning**: Adjust the decision threshold to balance precision and recall for the minority class.\n",
        "\n",
        "By implementing these techniques, you can create more balanced models that perform well on both the majority and minority classes, leading to more reliable and accurate predictions."
      ],
      "metadata": {
        "id": "odOBjFPVv9ct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IY8VGvFQvnGA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "from loan_data_utils import load_and_preprocess_data, plot_class_distribution, plot_mean_class_metrics, get_top_performers, evaluate_model\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Define your URL, categorical columns, and target\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "\n",
        "# Load and preprocess data\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "# Define the column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from loan_data_utils import plot_mean_class_metrics\n",
        "# Load the CSV file into a DataFrame\n",
        "file_path = '/content/combined_model_metrics_with_resampling.csv'\n",
        "metrics_df = pd.read_csv(file_path)\n",
        "\n",
        "# plot metrics\n",
        "plot_class_distribution(y_train, target)\n",
        "plot_mean_class_metrics(metrics_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6M6kXDx8wAzP",
        "outputId": "adbeb05e-659c-49fd-8328-e42c9f5c8812"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top Performing Models"
      ],
      "metadata": {
        "id": "a7jNCqtLwrgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get_top_performers(metrics_df, top_n=3)\n",
        "from loan_data_utils import get_top_performers, select_and_sort_top_n\n",
        "\n",
        "columns_to_check = ['Recall_0', 'Precision_0', 'F1_0', 'Recall_1',\n",
        "                    'Precision_1', 'F1_1', 'F1_Macro', 'Accuracy']\n",
        "top3_combined_df = select_and_sort_top_n(metrics_df, columns_to_check, n=3)\n",
        "top3_combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "chOUc6OrwiMA",
        "outputId": "aa9aa043-04c7-4ded-f291-e82be9fe6f03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Model             Experiment  \\\n",
              "0                         Logistic Regression               baseline   \n",
              "1                                        LGBM               baseline   \n",
              "2                               Random Forest  class_weight_balanced   \n",
              "3                   LGBM (RandomUnderSampler)             resampling   \n",
              "4   HistGradientBoosting (RandomUnderSampler)             resampling   \n",
              "5          Random Forest (RandomUnderSampler)             resampling   \n",
              "6                        HistGradientBoosting               baseline   \n",
              "7                        HistGradientBoosting  class_weight_balanced   \n",
              "8                Logistic Regression (ADASYN)             resampling   \n",
              "9                 Logistic Regression (SMOTE)             resampling   \n",
              "10                                       LGBM  class_weight_balanced   \n",
              "11                               LGBM (SMOTE)             resampling   \n",
              "12              HistGradientBoosting (ADASYN)             resampling   \n",
              "13                      Random Forest (SMOTE)             resampling   \n",
              "\n",
              "    Recall_0  Precision_0      F1_0  Recall_1  Precision_1      F1_1  \\\n",
              "0   0.969399     0.818724  0.887713  0.244160     0.693790  0.361204   \n",
              "1   0.947143     0.840486  0.890633  0.366993     0.663488  0.472586   \n",
              "2   0.947143     0.835094  0.887597  0.341372     0.647143  0.446966   \n",
              "3   0.770383     0.882786  0.822763  0.639789     0.441727  0.522622   \n",
              "4   0.786433     0.881929  0.831448  0.629239     0.455537  0.528481   \n",
              "5   0.775947     0.880738  0.825028  0.629992     0.443972  0.520872   \n",
              "6   0.942863     0.840198  0.888575  0.368500     0.646825  0.469515   \n",
              "7   0.942863     0.840198  0.888575  0.368500     0.646825  0.469515   \n",
              "8   0.629360     0.869347  0.730139  0.666918     0.338173  0.448783   \n",
              "9   0.677509     0.867160  0.760692  0.634514     0.358450  0.458107   \n",
              "10  0.799700     0.880122  0.837986  0.616428     0.466363  0.530996   \n",
              "11  0.918682     0.851110  0.883606  0.434062     0.602510  0.504599   \n",
              "12  0.905414     0.852337  0.878074  0.447626     0.573359  0.502751   \n",
              "13  0.890434     0.854941  0.872327  0.467973     0.548102  0.504878   \n",
              "\n",
              "    F1_Macro  Accuracy  \n",
              "0   0.624459  0.809000  \n",
              "1   0.681609  0.818833  \n",
              "2   0.667281  0.813167  \n",
              "3   0.672693  0.741500  \n",
              "4   0.679964  0.751667  \n",
              "5   0.672950  0.743667  \n",
              "6   0.679045  0.815833  \n",
              "7   0.679045  0.815833  \n",
              "8   0.589461  0.637667  \n",
              "9   0.609399  0.668000  \n",
              "10  0.684491  0.759167  \n",
              "11  0.694103  0.811500  \n",
              "12  0.690412  0.804167  \n",
              "13  0.688603  0.797000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cdfca94-ab8f-4db6-af31-b6cfd799efe2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Experiment</th>\n",
              "      <th>Recall_0</th>\n",
              "      <th>Precision_0</th>\n",
              "      <th>F1_0</th>\n",
              "      <th>Recall_1</th>\n",
              "      <th>Precision_1</th>\n",
              "      <th>F1_1</th>\n",
              "      <th>F1_Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>baseline</td>\n",
              "      <td>0.969399</td>\n",
              "      <td>0.818724</td>\n",
              "      <td>0.887713</td>\n",
              "      <td>0.244160</td>\n",
              "      <td>0.693790</td>\n",
              "      <td>0.361204</td>\n",
              "      <td>0.624459</td>\n",
              "      <td>0.809000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>baseline</td>\n",
              "      <td>0.947143</td>\n",
              "      <td>0.840486</td>\n",
              "      <td>0.890633</td>\n",
              "      <td>0.366993</td>\n",
              "      <td>0.663488</td>\n",
              "      <td>0.472586</td>\n",
              "      <td>0.681609</td>\n",
              "      <td>0.818833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>class_weight_balanced</td>\n",
              "      <td>0.947143</td>\n",
              "      <td>0.835094</td>\n",
              "      <td>0.887597</td>\n",
              "      <td>0.341372</td>\n",
              "      <td>0.647143</td>\n",
              "      <td>0.446966</td>\n",
              "      <td>0.667281</td>\n",
              "      <td>0.813167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBM (RandomUnderSampler)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.770383</td>\n",
              "      <td>0.882786</td>\n",
              "      <td>0.822763</td>\n",
              "      <td>0.639789</td>\n",
              "      <td>0.441727</td>\n",
              "      <td>0.522622</td>\n",
              "      <td>0.672693</td>\n",
              "      <td>0.741500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HistGradientBoosting (RandomUnderSampler)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.786433</td>\n",
              "      <td>0.881929</td>\n",
              "      <td>0.831448</td>\n",
              "      <td>0.629239</td>\n",
              "      <td>0.455537</td>\n",
              "      <td>0.528481</td>\n",
              "      <td>0.679964</td>\n",
              "      <td>0.751667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random Forest (RandomUnderSampler)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.775947</td>\n",
              "      <td>0.880738</td>\n",
              "      <td>0.825028</td>\n",
              "      <td>0.629992</td>\n",
              "      <td>0.443972</td>\n",
              "      <td>0.520872</td>\n",
              "      <td>0.672950</td>\n",
              "      <td>0.743667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>baseline</td>\n",
              "      <td>0.942863</td>\n",
              "      <td>0.840198</td>\n",
              "      <td>0.888575</td>\n",
              "      <td>0.368500</td>\n",
              "      <td>0.646825</td>\n",
              "      <td>0.469515</td>\n",
              "      <td>0.679045</td>\n",
              "      <td>0.815833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>class_weight_balanced</td>\n",
              "      <td>0.942863</td>\n",
              "      <td>0.840198</td>\n",
              "      <td>0.888575</td>\n",
              "      <td>0.368500</td>\n",
              "      <td>0.646825</td>\n",
              "      <td>0.469515</td>\n",
              "      <td>0.679045</td>\n",
              "      <td>0.815833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Logistic Regression (ADASYN)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.629360</td>\n",
              "      <td>0.869347</td>\n",
              "      <td>0.730139</td>\n",
              "      <td>0.666918</td>\n",
              "      <td>0.338173</td>\n",
              "      <td>0.448783</td>\n",
              "      <td>0.589461</td>\n",
              "      <td>0.637667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Logistic Regression (SMOTE)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.677509</td>\n",
              "      <td>0.867160</td>\n",
              "      <td>0.760692</td>\n",
              "      <td>0.634514</td>\n",
              "      <td>0.358450</td>\n",
              "      <td>0.458107</td>\n",
              "      <td>0.609399</td>\n",
              "      <td>0.668000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>class_weight_balanced</td>\n",
              "      <td>0.799700</td>\n",
              "      <td>0.880122</td>\n",
              "      <td>0.837986</td>\n",
              "      <td>0.616428</td>\n",
              "      <td>0.466363</td>\n",
              "      <td>0.530996</td>\n",
              "      <td>0.684491</td>\n",
              "      <td>0.759167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LGBM (SMOTE)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.918682</td>\n",
              "      <td>0.851110</td>\n",
              "      <td>0.883606</td>\n",
              "      <td>0.434062</td>\n",
              "      <td>0.602510</td>\n",
              "      <td>0.504599</td>\n",
              "      <td>0.694103</td>\n",
              "      <td>0.811500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>HistGradientBoosting (ADASYN)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.905414</td>\n",
              "      <td>0.852337</td>\n",
              "      <td>0.878074</td>\n",
              "      <td>0.447626</td>\n",
              "      <td>0.573359</td>\n",
              "      <td>0.502751</td>\n",
              "      <td>0.690412</td>\n",
              "      <td>0.804167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Random Forest (SMOTE)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.890434</td>\n",
              "      <td>0.854941</td>\n",
              "      <td>0.872327</td>\n",
              "      <td>0.467973</td>\n",
              "      <td>0.548102</td>\n",
              "      <td>0.504878</td>\n",
              "      <td>0.688603</td>\n",
              "      <td>0.797000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cdfca94-ab8f-4db6-af31-b6cfd799efe2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cdfca94-ab8f-4db6-af31-b6cfd799efe2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cdfca94-ab8f-4db6-af31-b6cfd799efe2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bc8ed36c-882f-49ba-a288-de5899b2f6c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bc8ed36c-882f-49ba-a288-de5899b2f6c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bc8ed36c-882f-49ba-a288-de5899b2f6c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0af7aa0d-6af6-4301-b6fd-d9f6ec4bf96b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top3_combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0af7aa0d-6af6-4301-b6fd-d9f6ec4bf96b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('top3_combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "top3_combined_df",
              "summary": "{\n  \"name\": \"top3_combined_df\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"HistGradientBoosting (ADASYN)\",\n          \"LGBM (SMOTE)\",\n          \"Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Experiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"baseline\",\n          \"class_weight_balanced\",\n          \"resampling\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10976461016241296,\n        \"min\": 0.6293601540766103,\n        \"max\": 0.9693986732291888,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.9054140808902204,\n          0.918681789000642,\n          0.9693986732291888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020536102967916227,\n        \"min\": 0.8187240195192481,\n        \"max\": 0.8827856792545365,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.8523368251410153,\n          0.8801224682053698,\n          0.8187240195192481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05118569828649667,\n        \"min\": 0.7301390268123137,\n        \"max\": 0.8906328604487374,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.8780740894469233,\n          0.8379863213364728,\n          0.8877131099353321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14201351557411704,\n        \"min\": 0.2441597588545591,\n        \"max\": 0.6669178598342125,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.4476262245666917,\n          0.6164280331574982,\n          0.2441597588545591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1187556392935093,\n        \"min\": 0.338173481085212,\n        \"max\": 0.6937901498929336,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.5733590733590733,\n          0.4663625997719498,\n          0.6937901498929336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.045639129134644574,\n        \"min\": 0.3612040133779264,\n        \"max\": 0.5309964297306069,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.5027507405840034,\n          0.5309964297306069,\n          0.3612040133779264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_Macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03268966579359695,\n        \"min\": 0.58946099413638,\n        \"max\": 0.6941026314070589,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.6904124150154634,\n          0.6844913755335398,\n          0.6244585616566293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.057819901639842186,\n        \"min\": 0.6376666666666667,\n        \"max\": 0.8188333333333333,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.8041666666666667,\n          0.7591666666666667,\n          0.809\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Optimal Models and Params"
      ],
      "metadata": {
        "id": "_GzEWkCZxYWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_params(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "best_params = load_params('/content/optimal_model_params.json')\n",
        "\n",
        "def pretty_print_params(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        top_model_params = json.load(f)\n",
        "\n",
        "    for category, models in top_model_params.items():\n",
        "        print(f\"Category: {category}\")\n",
        "        for model_name, params in models.items():\n",
        "            print(f\"  Model: {model_name}\")\n",
        "            print(f\"    Best Params:\")\n",
        "            for param, value in params['best_params'].items():\n",
        "                print(f\"      {param}: {value}\")\n",
        "            if 'best_threshold' in params:\n",
        "                print(f\"    Best Threshold: {params['best_threshold']}\")\n",
        "\n",
        "# Example usage\n",
        "pretty_print_params('/content/optimal_model_params.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNr8dks1wyOY",
        "outputId": "c292af9e-4b76-4633-b9fd-07a29f778713"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category: Class 1 Recall\n",
            "  Model: Logistic Regression (ADASYN)\n",
            "    Best Params:\n",
            "      C: 6.7\n",
            "      solver: liblinear\n",
            "    Best Threshold: 0.2\n",
            "  Model: Logistic Regression (SMOTE)\n",
            "    Best Params:\n",
            "      C: 10.0\n",
            "      solver: liblinear\n",
            "    Best Threshold: 0.2\n",
            "  Model: LGBM (SMOTE)\n",
            "    Best Params:\n",
            "      learning_rate: 0.2\n",
            "      n_estimators: 300\n",
            "      num_leaves: 31\n",
            "    Best Threshold: 0.1\n",
            "Category: Class 1 Precision\n",
            "  Model: Logistic Regression (baseline)\n",
            "    Best Params:\n",
            "      C: 10.0\n",
            "      penalty: l2\n",
            "      solver: liblinear\n",
            "    Best Threshold: 0.5\n",
            "  Model: LGBM (baseline)\n",
            "    Best Params:\n",
            "      learning_rate: 0.01\n",
            "      n_estimators: 100\n",
            "      num_leaves: 70\n",
            "    Best Threshold: 0.5\n",
            "  Model: Random Forest (class_weight_balanced)\n",
            "    Best Params:\n",
            "      max_depth: None\n",
            "      min_samples_split: 2\n",
            "      n_estimators: 100\n",
            "    Best Threshold: 0.5\n",
            "Category: Class 0 Recall\n",
            "  Model: Logistic Regression (baseline)\n",
            "    Best Params:\n",
            "      C: 0.01\n",
            "      solver: liblinear\n",
            "    Best Threshold: 0.1\n",
            "  Model: LGBM (baseline)\n",
            "    Best Params:\n",
            "      learning_rate: 0.05\n",
            "      n_estimators: 100\n",
            "      num_leaves: 31\n",
            "    Best Threshold: 0.1\n",
            "  Model: Random Forest (class_weight_balanced)\n",
            "    Best Params:\n",
            "      max_depth: 10\n",
            "      min_samples_leaf: 10\n",
            "      min_samples_split: 2\n",
            "      n_estimators: 100\n",
            "    Best Threshold: 0.1\n",
            "Category: Class 0 Precision\n",
            "  Model: LGBM (RandomUnderSampler)\n",
            "    Best Params:\n",
            "      learning_rate: 0.01\n",
            "      n_estimators: 300\n",
            "      num_leaves: 31\n",
            "    Best Threshold: 0.85\n",
            "  Model: HistGradientBoosting (RandomUnderSampler)\n",
            "    Best Params:\n",
            "      learning_rate: 0.01\n",
            "      max_iter: 100\n",
            "      max_leaf_nodes: 31\n",
            "    Best Threshold: 0.7\n",
            "  Model: Random Forest (RandomUnderSampler)\n",
            "    Best Params:\n",
            "      max_depth: 10\n",
            "      min_samples_split: 10\n",
            "      n_estimators: 200\n",
            "    Best Threshold: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Models"
      ],
      "metadata": {
        "id": "oH4Eps7lxwln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# Define models with their respective preprocessing and resampling steps\n",
        "models = {\n",
        "    \"Logistic Regression (ADASYN)\": ImbPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('resampler', ADASYN()),\n",
        "        ('classifier', LogisticRegression(random_state=42, **best_params['Class 1 Recall']['Logistic Regression (ADASYN)']['best_params']))\n",
        "    ]),\n",
        "    \"Logistic Regression (SMOTE)\": ImbPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('resampler', SMOTE()),\n",
        "        ('classifier', LogisticRegression(random_state=42, **best_params['Class 1 Recall']['Logistic Regression (SMOTE)']['best_params']))\n",
        "    ]),\n",
        "    \"LGBM (SMOTE)\": ImbPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('resampler', SMOTE()),\n",
        "        ('classifier', LGBMClassifier(random_state=42, **best_params['Class 1 Recall']['LGBM (SMOTE)']['best_params'], force_row_wise=True))\n",
        "    ]),\n",
        "    \"Logistic Regression (baseline)\": Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LogisticRegression(random_state=42, **best_params['Class 1 Precision']['Logistic Regression (baseline)']['best_params']))\n",
        "    ]),\n",
        "    \"LGBM (baseline)\": Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LGBMClassifier(random_state=42, **best_params['Class 1 Precision']['LGBM (baseline)']['best_params'], force_row_wise=True))\n",
        "    ]),\n",
        "    \"Random Forest (class_weight_balanced)\": Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', **best_params['Class 1 Precision']['Random Forest (class_weight_balanced)']['best_params']))\n",
        "    ]),\n",
        "    \"Logistic Regression (baseline for Class 0 Recall)\": Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LogisticRegression(random_state=42, **best_params['Class 0 Recall']['Logistic Regression (baseline)']['best_params']))\n",
        "    ]),\n",
        "    \"LGBM (baseline for Class 0 Recall)\": Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', LGBMClassifier(random_state=42, **best_params['Class 0 Recall']['LGBM (baseline)']['best_params'], force_row_wise=True))\n",
        "    ]),\n",
        "    \"Random Forest (class_weight_balanced for Class 0 Recall)\": Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', **best_params['Class 0 Recall']['Random Forest (class_weight_balanced)']['best_params']))\n",
        "    ]),\n",
        "    \"LGBM (RandomUnderSampler)\": ImbPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('resampler', RandomUnderSampler()),\n",
        "        ('classifier', LGBMClassifier(random_state=42, **best_params['Class 0 Precision']['LGBM (RandomUnderSampler)']['best_params'], force_row_wise=True))\n",
        "    ]),\n",
        "    \"HistGradientBoosting (RandomUnderSampler)\": ImbPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('resampler', RandomUnderSampler()),\n",
        "        ('classifier', HistGradientBoostingClassifier(random_state=42, **best_params['Class 0 Precision']['HistGradientBoosting (RandomUnderSampler)']['best_params']))\n",
        "    ]),\n",
        "    \"Random Forest (RandomUnderSampler)\": ImbPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('resampler', RandomUnderSampler()),\n",
        "        ('classifier', RandomForestClassifier(random_state=42, **best_params['Class 0 Precision']['Random Forest (RandomUnderSampler)']['best_params']))\n",
        "    ])\n",
        "}\n"
      ],
      "metadata": {
        "id": "EllIRCDIwyMT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Voting Classifier"
      ],
      "metadata": {
        "id": "6eQYkrA2x7d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Select top 2 models for each class 0, 1 recall, and precision\n",
        "voting_models = [\n",
        "    ('lr_adasyn', models['Logistic Regression (ADASYN)']),\n",
        "    ('lgbm_smote', models['LGBM (SMOTE)']),\n",
        "    ('rf_class_weight_balanced', models['Random Forest (class_weight_balanced)']),\n",
        "    ('lgbm_baseline', models['LGBM (baseline)']),\n",
        "    ('lr_baseline_class_0_recall', models['Logistic Regression (baseline for Class 0 Recall)']),\n",
        "    ('lgbm_baseline_class_0_recall', models['LGBM (baseline for Class 0 Recall)']),\n",
        "    ('lgbm_randomundersampler', models['LGBM (RandomUnderSampler)']),\n",
        "    ('rf_randomundersampler', models['Random Forest (RandomUnderSampler)'])\n",
        "]\n",
        "\n",
        "# Extract the classifiers from the pipelines\n",
        "voting_estimators = [(name, pipe.named_steps['classifier']) for name, pipe in voting_models]\n",
        "\n",
        "# Define the voting classifier\n",
        "voting_clf = VotingClassifier(estimators=voting_estimators, voting='soft')\n",
        "\n",
        "# Define the voting pipeline\n",
        "voting_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', voting_clf)\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "voting_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate and capture metrics for the voting classifier\n",
        "voting_metrics = evaluate_model(voting_pipeline, X_train, X_test, y_train, y_test, 'Voting Classifier', 'ensemble')\n",
        "\n",
        "# Print classification report\n",
        "y_pred = voting_pipeline.predict(X_test)\n",
        "print(\"Voting Classifier Classification Report\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Combine metrics with existing DataFrame and save\n",
        "metrics_list = [voting_metrics]\n",
        "combined_df = pd.concat([top3_combined_df, pd.DataFrame(metrics_list)], ignore_index=True)\n",
        "# combined_df.to_csv('optimal_metrics.csv', index=False)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "print(combined_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozfLYENuwyJj",
        "outputId": "9399bbba-5caa-403d-d211-873c3dd47998"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "Voting Classifier Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.96      0.89      4673\n",
            "           1       0.69      0.34      0.45      1327\n",
            "\n",
            "    accuracy                           0.82      6000\n",
            "   macro avg       0.76      0.65      0.67      6000\n",
            "weighted avg       0.80      0.82      0.79      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Stacking Classifier"
      ],
      "metadata": {
        "id": "EH1SmtEhyDHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Select top 2 models for each class 0, 1 recall, and precision\n",
        "stacking_estimators = [\n",
        "    ('lr_adasyn', models['Logistic Regression (ADASYN)'].named_steps['classifier']),\n",
        "    ('lgbm_smote', models['LGBM (SMOTE)'].named_steps['classifier']),\n",
        "    ('rf_class_weight_balanced', models['Random Forest (class_weight_balanced)'].named_steps['classifier']),\n",
        "    ('lgbm_baseline', models['LGBM (baseline)'].named_steps['classifier']),\n",
        "    ('lr_baseline_class_0_recall', models['Logistic Regression (baseline for Class 0 Recall)'].named_steps['classifier']),\n",
        "    ('lgbm_baseline_class_0_recall', models['LGBM (baseline for Class 0 Recall)'].named_steps['classifier']),\n",
        "    ('lgbm_randomundersampler', models['LGBM (RandomUnderSampler)'].named_steps['classifier']),\n",
        "    ('rf_randomundersampler', models['Random Forest (RandomUnderSampler)'].named_steps['classifier'])\n",
        "]\n",
        "\n",
        "# Define the stacking classifier\n",
        "stacking_clf = StackingClassifier(estimators=stacking_estimators, final_estimator=LogisticRegression(random_state=42))\n",
        "\n",
        "# Define the stacking pipeline\n",
        "stacking_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', stacking_clf)\n",
        "])\n",
        "\n",
        "# Fit the pipeline\n",
        "stacking_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate and capture metrics for the stacking classifier\n",
        "stacking_metrics = evaluate_model(stacking_pipeline, X_train, X_test, y_train, y_test, 'Stacking Classifier', 'ensemble')\n",
        "\n",
        "# Print classification report\n",
        "y_pred = stacking_pipeline.predict(X_test)\n",
        "print(\"Stacking Classifier Classification Report\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlcwQYvryCpB",
        "outputId": "78c90ca0-b38f-4263-8371-e5865e1e7de7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "Stacking Classifier Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.95      0.89      4673\n",
            "           1       0.67      0.37      0.47      1327\n",
            "\n",
            "    accuracy                           0.82      6000\n",
            "   macro avg       0.75      0.66      0.68      6000\n",
            "weighted avg       0.80      0.82      0.80      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine and Save Final Metrics"
      ],
      "metadata": {
        "id": "-6zV4PMN43LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine metrics with existing DataFrame and save\n",
        "metrics_list.append(stacking_metrics)\n",
        "combined_df = pd.concat([top3_combined_df, pd.DataFrame(metrics_list)], ignore_index=True)\n",
        "combined_df.to_csv('optimal_metrics.csv', index=False)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "d-OmeOlq1yaU",
        "outputId": "7a2fab31-a287-4587-8976-9ecdef211417"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Model             Experiment  \\\n",
              "0                         Logistic Regression               baseline   \n",
              "1                                        LGBM               baseline   \n",
              "2                               Random Forest  class_weight_balanced   \n",
              "3                   LGBM (RandomUnderSampler)             resampling   \n",
              "4   HistGradientBoosting (RandomUnderSampler)             resampling   \n",
              "5          Random Forest (RandomUnderSampler)             resampling   \n",
              "6                        HistGradientBoosting               baseline   \n",
              "7                        HistGradientBoosting  class_weight_balanced   \n",
              "8                Logistic Regression (ADASYN)             resampling   \n",
              "9                 Logistic Regression (SMOTE)             resampling   \n",
              "10                                       LGBM  class_weight_balanced   \n",
              "11                               LGBM (SMOTE)             resampling   \n",
              "12              HistGradientBoosting (ADASYN)             resampling   \n",
              "13                      Random Forest (SMOTE)             resampling   \n",
              "14                          Voting Classifier               ensemble   \n",
              "15                        Stacking Classifier               ensemble   \n",
              "\n",
              "    Recall_0  Precision_0      F1_0  Recall_1  Precision_1      F1_1  \\\n",
              "0   0.969399     0.818724  0.887713  0.244160     0.693790  0.361204   \n",
              "1   0.947143     0.840486  0.890633  0.366993     0.663488  0.472586   \n",
              "2   0.947143     0.835094  0.887597  0.341372     0.647143  0.446966   \n",
              "3   0.770383     0.882786  0.822763  0.639789     0.441727  0.522622   \n",
              "4   0.786433     0.881929  0.831448  0.629239     0.455537  0.528481   \n",
              "5   0.775947     0.880738  0.825028  0.629992     0.443972  0.520872   \n",
              "6   0.942863     0.840198  0.888575  0.368500     0.646825  0.469515   \n",
              "7   0.942863     0.840198  0.888575  0.368500     0.646825  0.469515   \n",
              "8   0.629360     0.869347  0.730139  0.666918     0.338173  0.448783   \n",
              "9   0.677509     0.867160  0.760692  0.634514     0.358450  0.458107   \n",
              "10  0.799700     0.880122  0.837986  0.616428     0.466363  0.530996   \n",
              "11  0.918682     0.851110  0.883606  0.434062     0.602510  0.504599   \n",
              "12  0.905414     0.852337  0.878074  0.447626     0.573359  0.502751   \n",
              "13  0.890434     0.854941  0.872327  0.467973     0.548102  0.504878   \n",
              "14  0.956559     0.835202  0.891771  0.335343     0.686728  0.450633   \n",
              "15  0.948641     0.840379  0.891234  0.365486     0.668966  0.472710   \n",
              "\n",
              "    F1_Macro  Accuracy  \n",
              "0   0.624459  0.809000  \n",
              "1   0.681609  0.818833  \n",
              "2   0.667281  0.813167  \n",
              "3   0.672693  0.741500  \n",
              "4   0.679964  0.751667  \n",
              "5   0.672950  0.743667  \n",
              "6   0.679045  0.815833  \n",
              "7   0.679045  0.815833  \n",
              "8   0.589461  0.637667  \n",
              "9   0.609399  0.668000  \n",
              "10  0.684491  0.759167  \n",
              "11  0.694103  0.811500  \n",
              "12  0.690412  0.804167  \n",
              "13  0.688603  0.797000  \n",
              "14  0.671202  0.819167  \n",
              "15  0.681972  0.819667  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2877b55b-9deb-4a85-a8c9-af7375552f3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Experiment</th>\n",
              "      <th>Recall_0</th>\n",
              "      <th>Precision_0</th>\n",
              "      <th>F1_0</th>\n",
              "      <th>Recall_1</th>\n",
              "      <th>Precision_1</th>\n",
              "      <th>F1_1</th>\n",
              "      <th>F1_Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>baseline</td>\n",
              "      <td>0.969399</td>\n",
              "      <td>0.818724</td>\n",
              "      <td>0.887713</td>\n",
              "      <td>0.244160</td>\n",
              "      <td>0.693790</td>\n",
              "      <td>0.361204</td>\n",
              "      <td>0.624459</td>\n",
              "      <td>0.809000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>baseline</td>\n",
              "      <td>0.947143</td>\n",
              "      <td>0.840486</td>\n",
              "      <td>0.890633</td>\n",
              "      <td>0.366993</td>\n",
              "      <td>0.663488</td>\n",
              "      <td>0.472586</td>\n",
              "      <td>0.681609</td>\n",
              "      <td>0.818833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>class_weight_balanced</td>\n",
              "      <td>0.947143</td>\n",
              "      <td>0.835094</td>\n",
              "      <td>0.887597</td>\n",
              "      <td>0.341372</td>\n",
              "      <td>0.647143</td>\n",
              "      <td>0.446966</td>\n",
              "      <td>0.667281</td>\n",
              "      <td>0.813167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBM (RandomUnderSampler)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.770383</td>\n",
              "      <td>0.882786</td>\n",
              "      <td>0.822763</td>\n",
              "      <td>0.639789</td>\n",
              "      <td>0.441727</td>\n",
              "      <td>0.522622</td>\n",
              "      <td>0.672693</td>\n",
              "      <td>0.741500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HistGradientBoosting (RandomUnderSampler)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.786433</td>\n",
              "      <td>0.881929</td>\n",
              "      <td>0.831448</td>\n",
              "      <td>0.629239</td>\n",
              "      <td>0.455537</td>\n",
              "      <td>0.528481</td>\n",
              "      <td>0.679964</td>\n",
              "      <td>0.751667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random Forest (RandomUnderSampler)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.775947</td>\n",
              "      <td>0.880738</td>\n",
              "      <td>0.825028</td>\n",
              "      <td>0.629992</td>\n",
              "      <td>0.443972</td>\n",
              "      <td>0.520872</td>\n",
              "      <td>0.672950</td>\n",
              "      <td>0.743667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>baseline</td>\n",
              "      <td>0.942863</td>\n",
              "      <td>0.840198</td>\n",
              "      <td>0.888575</td>\n",
              "      <td>0.368500</td>\n",
              "      <td>0.646825</td>\n",
              "      <td>0.469515</td>\n",
              "      <td>0.679045</td>\n",
              "      <td>0.815833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>class_weight_balanced</td>\n",
              "      <td>0.942863</td>\n",
              "      <td>0.840198</td>\n",
              "      <td>0.888575</td>\n",
              "      <td>0.368500</td>\n",
              "      <td>0.646825</td>\n",
              "      <td>0.469515</td>\n",
              "      <td>0.679045</td>\n",
              "      <td>0.815833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Logistic Regression (ADASYN)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.629360</td>\n",
              "      <td>0.869347</td>\n",
              "      <td>0.730139</td>\n",
              "      <td>0.666918</td>\n",
              "      <td>0.338173</td>\n",
              "      <td>0.448783</td>\n",
              "      <td>0.589461</td>\n",
              "      <td>0.637667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Logistic Regression (SMOTE)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.677509</td>\n",
              "      <td>0.867160</td>\n",
              "      <td>0.760692</td>\n",
              "      <td>0.634514</td>\n",
              "      <td>0.358450</td>\n",
              "      <td>0.458107</td>\n",
              "      <td>0.609399</td>\n",
              "      <td>0.668000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LGBM</td>\n",
              "      <td>class_weight_balanced</td>\n",
              "      <td>0.799700</td>\n",
              "      <td>0.880122</td>\n",
              "      <td>0.837986</td>\n",
              "      <td>0.616428</td>\n",
              "      <td>0.466363</td>\n",
              "      <td>0.530996</td>\n",
              "      <td>0.684491</td>\n",
              "      <td>0.759167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LGBM (SMOTE)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.918682</td>\n",
              "      <td>0.851110</td>\n",
              "      <td>0.883606</td>\n",
              "      <td>0.434062</td>\n",
              "      <td>0.602510</td>\n",
              "      <td>0.504599</td>\n",
              "      <td>0.694103</td>\n",
              "      <td>0.811500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>HistGradientBoosting (ADASYN)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.905414</td>\n",
              "      <td>0.852337</td>\n",
              "      <td>0.878074</td>\n",
              "      <td>0.447626</td>\n",
              "      <td>0.573359</td>\n",
              "      <td>0.502751</td>\n",
              "      <td>0.690412</td>\n",
              "      <td>0.804167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Random Forest (SMOTE)</td>\n",
              "      <td>resampling</td>\n",
              "      <td>0.890434</td>\n",
              "      <td>0.854941</td>\n",
              "      <td>0.872327</td>\n",
              "      <td>0.467973</td>\n",
              "      <td>0.548102</td>\n",
              "      <td>0.504878</td>\n",
              "      <td>0.688603</td>\n",
              "      <td>0.797000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Voting Classifier</td>\n",
              "      <td>ensemble</td>\n",
              "      <td>0.956559</td>\n",
              "      <td>0.835202</td>\n",
              "      <td>0.891771</td>\n",
              "      <td>0.335343</td>\n",
              "      <td>0.686728</td>\n",
              "      <td>0.450633</td>\n",
              "      <td>0.671202</td>\n",
              "      <td>0.819167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Stacking Classifier</td>\n",
              "      <td>ensemble</td>\n",
              "      <td>0.948641</td>\n",
              "      <td>0.840379</td>\n",
              "      <td>0.891234</td>\n",
              "      <td>0.365486</td>\n",
              "      <td>0.668966</td>\n",
              "      <td>0.472710</td>\n",
              "      <td>0.681972</td>\n",
              "      <td>0.819667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2877b55b-9deb-4a85-a8c9-af7375552f3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2877b55b-9deb-4a85-a8c9-af7375552f3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2877b55b-9deb-4a85-a8c9-af7375552f3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d364fafd-7248-4205-ae49-456bdea829d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d364fafd-7248-4205-ae49-456bdea829d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d364fafd-7248-4205-ae49-456bdea829d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_127c9389-f35f-4651-8c9b-383c852cd3cc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_127c9389-f35f-4651-8c9b-383c852cd3cc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"LGBM (SMOTE)\",\n          \"Random Forest (SMOTE)\",\n          \"Logistic Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Experiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"class_weight_balanced\",\n          \"ensemble\",\n          \"baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10801136082880868,\n        \"min\": 0.6293601540766103,\n        \"max\": 0.9693986732291888,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.918681789000642,\n          0.8904344104429702,\n          0.9693986732291888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020212476961466788,\n        \"min\": 0.8187240195192481,\n        \"max\": 0.8827856792545365,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8801224682053698,\n          0.8523368251410153,\n          0.8187240195192481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04981974312271784,\n        \"min\": 0.7301390268123137,\n        \"max\": 0.8917705735660848,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.8379863213364728,\n          0.8780740894469233,\n          0.8877131099353321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14061680441451474,\n        \"min\": 0.2441597588545591,\n        \"max\": 0.6669178598342125,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6164280331574982,\n          0.4476262245666917,\n          0.2441597588545591\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12053250198957155,\n        \"min\": 0.338173481085212,\n        \"max\": 0.6937901498929336,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4663625997719498,\n          0.5733590733590733,\n          0.6937901498929336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0432158882040011,\n        \"min\": 0.3612040133779264,\n        \"max\": 0.5309964297306069,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5309964297306069,\n          0.5027507405840034,\n          0.3612040133779264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_Macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030740695715817036,\n        \"min\": 0.58946099413638,\n        \"max\": 0.6941026314070589,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6844913755335398,\n          0.6904124150154634,\n          0.6244585616566293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05636099645407535,\n        \"min\": 0.6376666666666667,\n        \"max\": 0.8196666666666667,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.7591666666666667,\n          0.8041666666666667,\n          0.809\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Performnance Analysis\n",
        "\n",
        "- **Highest Recall for Class 1**:\n",
        "  - The highest recall for class 1 among individual models is seen in `Logistic Regression (ADASYN)` with a recall of 0.666918.\n",
        "  - The voting and stacking classifiers do not outperform the best individual models in terms of class 1 recall. The voting classifier has a recall of 0.335343, and the stacking classifier has a recall of 0.365486.\n",
        "  \n",
        "- **Voting Classifier**:\n",
        "  - Recall_1: 0.335343, which is lower than many individual models.\n",
        "  - Precision_1: 0.686728, which is high, indicating it performs well in identifying true positives but misses more actual positives.\n",
        "\n",
        "- **Stacking Classifier**:\n",
        "  - Recall_1: 0.365486, which is better than the voting classifier but still lower than the top individual models.\n",
        "  - Precision_1: 0.668966, indicating a good balance but not the best for recall.\n",
        "\n",
        "- **Balanced Performance**:\n",
        "  - The `LGBM (RandomUnderSampler)` model strikes a balance with a high recall of 0.639789 and a reasonable precision of 0.441727.\n",
        "\n",
        "### Recommendations:\n",
        "- **Class 1 Recall Focus**: For a primary focus on class 1 recall, individual models such as `Logistic Regression (ADASYN)` and `LGBM (RandomUnderSampler)` outperform the ensemble methods in recall for class 1.\n",
        "- **Ensemble Methods**: The ensemble methods show balanced performance but do not achieve the highest recall for class 1. They may be useful when considering overall model performance, including precision and recall for both classes.\n",
        "- **Further Tuning**: Further tuning or adjusting the voting/stacking strategies might be necessary to achieve better performance specifically for class 1 recall.\n",
        "\n",
        "Overall, while the ensemble methods provide balanced performance, the individual models, particularly those using resampling techniques, show higher recall for class 1, which is crucial for identifying loan defaults."
      ],
      "metadata": {
        "id": "8Q2ZRjboECRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Utils Script"
      ],
      "metadata": {
        "id": "pHgxq0aswRnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_content=r'''\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "import json\n",
        "import logging\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#--------   Load and Preprocess Data   --------#\n",
        "\n",
        "def load_data_from_url(url):\n",
        "    try:\n",
        "        df = pd.read_excel(url, header=1)\n",
        "        logging.info(\"Data loaded successfully from URL.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading data from URL: {e}\")\n",
        "        return None\n",
        "    return df\n",
        "\n",
        "def clean_column_names(df):\n",
        "    df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
        "    return df\n",
        "\n",
        "def remove_id_column(df):\n",
        "    if 'id' in df.columns:\n",
        "        df = df.drop(columns=['id'])\n",
        "    return df\n",
        "\n",
        "def rename_columns(df):\n",
        "    rename_dict = {'pay_0': 'pay_1'}\n",
        "    df = df.rename(columns=rename_dict)\n",
        "    return df\n",
        "\n",
        "def convert_categorical(df, categorical_columns):\n",
        "    df[categorical_columns] = df[categorical_columns].astype('category')\n",
        "    return df\n",
        "\n",
        "def split_features_target(df, target):\n",
        "    X = df.drop(columns=[target])\n",
        "    y = df[target]\n",
        "    return X, y\n",
        "\n",
        "def load_and_preprocess_data(url, categorical_columns, target):\n",
        "    df = load_data_from_url(url)\n",
        "    if df is not None:\n",
        "        df = clean_column_names(df)\n",
        "        df = remove_id_column(df)\n",
        "        df = rename_columns(df)\n",
        "        df = convert_categorical(df, categorical_columns)\n",
        "        X, y = split_features_target(df, target)\n",
        "        return X, y\n",
        "    return None, None\n",
        "\n",
        "#--------   Plot Class Distribution   --------#\n",
        "\n",
        "\n",
        "def plot_class_distribution(y_train, target_name):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(x=y_train, hue=y_train, palette='mako')\n",
        "    plt.title(f'Class Distribution in Training Set: {target_name}')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend([], [], frameon=False)\n",
        "\n",
        "    # Calculate the percentage for each class\n",
        "    total = len(y_train)\n",
        "    class_counts = y_train.value_counts()\n",
        "    for i, count in enumerate(class_counts):\n",
        "        percentage = 100 * count / total\n",
        "        plt.text(i, count, f'{percentage:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_mean_class_metrics(df):\n",
        "    \"\"\"\n",
        "    Function to calculate and plot the mean recall and precision metrics for class 0 and class 1.\n",
        "    \"\"\"\n",
        "    # Calculate the mean of recall and precision for both classes\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Metric': ['Recall_0', 'Precision_0', 'Recall_1', 'Precision_1'],\n",
        "        'Mean Value': [\n",
        "            df['Recall_0'].mean(),\n",
        "            df['Precision_0'].mean(),\n",
        "            df['Recall_1'].mean(),\n",
        "            df['Precision_1'].mean()\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # Plot the mean of recall and precision for each class\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Metric', y='Mean Value', data=metrics_df, palette='mako')\n",
        "    plt.title('Mean Recall and Precision for Class 0 and Class 1')\n",
        "    plt.xlabel('Metric')\n",
        "    plt.ylabel('Mean Value')\n",
        "    for index, row in metrics_df.iterrows():\n",
        "        plt.text(index, row['Mean Value'], f'{row[\"Mean Value\"]:.2f}', ha='center', va='bottom')\n",
        "    plt.show()\n",
        "\n",
        "#--------   Evaluate and Capture Metrics   --------#\n",
        "\n",
        "# def evaluate_model(pipeline, X_train, X_test, y_train, y_test, model_name, experiment_name):\n",
        "#     logger.info(f\"Training and evaluating model: {model_name} ({experiment_name})\")\n",
        "\n",
        "#     # Fit the pipeline\n",
        "#     pipeline.fit(X_train, y_train)\n",
        "\n",
        "#     # Make predictions\n",
        "#     y_pred = pipeline.predict(X_test)\n",
        "\n",
        "#     # Capture classification report\n",
        "#     report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "#     # Extract relevant metrics\n",
        "#     metrics = {\n",
        "#         'Model': model_name,\n",
        "#         'Experiment': experiment_name,\n",
        "#         'Recall_0': report['0']['recall'],\n",
        "#         'Precision_0': report['0']['precision'],\n",
        "#         'F1_0': report['0']['f1-score'],\n",
        "#         'Recall_1': report['1']['recall'],\n",
        "#         'Precision_1': report['1']['precision'],\n",
        "#         'F1_1': report['1']['f1-score'],\n",
        "#         'F1_Macro': report['macro avg']['f1-score'],\n",
        "#         'Accuracy': report['accuracy']\n",
        "#     }\n",
        "\n",
        "#     logger.info(f\"Completed evaluation for model: {model_name} ({experiment_name})\")\n",
        "#     return metrics\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(pipeline, X_train, X_test, y_train, y_test, model_name, experiment_name):\n",
        "    logger.info(f\"Training and evaluating model: {model_name} ({experiment_name})\")\n",
        "\n",
        "    # Fit the pipeline\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Capture classification report\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Extract relevant metrics\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'Experiment': experiment_name,\n",
        "        'Recall_0': report['0']['recall'],\n",
        "        'Precision_0': report['0']['precision'],\n",
        "        'F1_0': report['0']['f1-score'],\n",
        "        'Recall_1': report['1']['recall'],\n",
        "        'Precision_1': report['1']['precision'],\n",
        "        'F1_1': report['1']['f1-score'],\n",
        "        'F1_Macro': report['macro avg']['f1-score'],\n",
        "        'Accuracy': report['accuracy']\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def compile_metrics(metrics_list, experiment_name='experiment_name'):\n",
        "    metrics_df = pd.DataFrame(metrics_list)\n",
        "    csv_filename = f'{experiment_name}_metrics.csv'\n",
        "    metrics_df.to_csv(csv_filename, index=False)\n",
        "    logger.info(f\"Metrics saved to {csv_filename}\")\n",
        "    return metrics_df\n",
        "\n",
        "\n",
        "def clean_params(params):\n",
        "    \"\"\"\n",
        "    Clean the model parameters by removing the 'classifier__' prefix.\n",
        "    \"\"\"\n",
        "    return {key.replace('classifier__', ''): value for key, value in params.items()}\n",
        "\n",
        "# --------   Get Top Performers   --------#\n",
        "\n",
        "import pandas as pd\n",
        "def get_top_performers(metrics_df, top_n=3):\n",
        "    metrics = ['Recall_0', 'Precision_0', 'Recall_1', 'Precision_1']\n",
        "    top_performers = []\n",
        "\n",
        "    for metric in metrics:\n",
        "        sorted_df = metrics_df[['Experiment', 'Model', metric]].sort_values(by=metric, ascending=False).head(top_n)\n",
        "        sorted_df['Metric'] = metric\n",
        "        sorted_df = sorted_df.rename(columns={metric: 'Value'})\n",
        "        top_performers.append(sorted_df)\n",
        "\n",
        "    # Concatenate all top performers into a single DataFrame\n",
        "    top_performers_df = pd.concat(top_performers, ignore_index=True)\n",
        "\n",
        "    # Save the results to a CSV file\n",
        "    top_performers_df.to_csv('top_performing_models.csv', index=False)\n",
        "    return top_performers_df\n",
        "\n",
        "def select_and_sort_top_n(df, columns, n=3):\n",
        "    \"\"\"\n",
        "    Selects the top n rows based on each specified column and returns a DataFrame with all columns.\n",
        "\n",
        "    Args:\n",
        "    df (pd.DataFrame): The input DataFrame.\n",
        "    columns (list of str): The columns to sort by.\n",
        "    n (int): The number of top rows to select for each column.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame containing the top n rows for each specified column, without duplicates.\n",
        "    \"\"\"\n",
        "    top_n_combined_df = pd.DataFrame()\n",
        "\n",
        "    for column in columns:\n",
        "        top_n = df.nlargest(n, column)\n",
        "        top_n_combined_df = pd.concat([top_n_combined_df, top_n])\n",
        "\n",
        "    # Drop duplicates and reset index\n",
        "    top_n_combined_df = top_n_combined_df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    return top_n_combined_df\n",
        "\n",
        "'''\n",
        "\n",
        "# Write the script to a file\n",
        "with open(\"loan_data_utils.py\", \"w\") as file:\n",
        "    file.write(script_content)\n",
        "\n",
        "print(\"Script successfully written to loan_data_utils.py\")\n",
        "# Reload script to make functions available for use\n",
        "import importlib\n",
        "import loan_data_utils\n",
        "importlib.reload(loan_data_utils)\n",
        "\n",
        "from loan_data_utils import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1SF-3I1wPs7",
        "outputId": "d25e3aec-511e-4db6-d339-03bdad4b634a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script successfully written to loan_data_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ygK1CTdkwQJF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}