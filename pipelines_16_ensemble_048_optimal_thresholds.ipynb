{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmLyIjEE8ruTOftZTqjhJD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/pipelines/blob/main/pipelines_16_ensemble_048_optimal_thresholds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifiers with Custom Threshold or Regularization"
      ],
      "metadata": {
        "id": "lv2tsB_kFWSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "from loan_data_utils import load_and_preprocess_data, plot_class_distribution, plot_mean_class_metrics, get_top_performers, evaluate_model\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Example usage with custom thresholds\n",
        "stacking_threshold = 0.3  # Set your custom threshold for stacking classifier\n",
        "voting_threshold = 0.3    # Set your custom threshold for voting classifier\n",
        "\n",
        "# Define your URL, categorical columns, and target\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "categorical_columns = ['sex', 'education', 'marriage']\n",
        "target = 'default_payment_next_month'\n",
        "\n",
        "# Load and preprocess data\n",
        "X, y = load_and_preprocess_data(url, categorical_columns, target)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
        "\n",
        "# Define the column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder(drop='first'))\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Define models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "def define_models(best_params):\n",
        "    models = {\n",
        "        \"Logistic Regression (ADASYN)\": ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', ADASYN()),\n",
        "            ('classifier', LogisticRegression(random_state=42, **best_params['Class 1 Recall']['Logistic Regression (ADASYN)']['best_params']))\n",
        "        ]),\n",
        "        \"Logistic Regression (SMOTE)\": ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', SMOTE()),\n",
        "            ('classifier', LogisticRegression(random_state=42, **best_params['Class 1 Recall']['Logistic Regression (SMOTE)']['best_params']))\n",
        "        ]),\n",
        "        \"LGBM (SMOTE)\": ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', SMOTE()),\n",
        "            ('classifier', LGBMClassifier(random_state=42, **best_params['Class 1 Recall']['LGBM (SMOTE)']['best_params'], force_row_wise=True))\n",
        "        ]),\n",
        "        \"Logistic Regression (baseline)\": Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', LogisticRegression(random_state=42, **best_params['Class 1 Precision']['Logistic Regression (baseline)']['best_params']))\n",
        "        ]),\n",
        "        \"LGBM (baseline)\": Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', LGBMClassifier(random_state=42, **best_params['Class 1 Precision']['LGBM (baseline)']['best_params'], force_row_wise=True))\n",
        "        ]),\n",
        "        \"Random Forest (class_weight_balanced)\": Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', **best_params['Class 1 Precision']['Random Forest (class_weight_balanced)']['best_params']))\n",
        "        ]),\n",
        "        \"Logistic Regression (baseline for Class 0 Recall)\": Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', LogisticRegression(random_state=42, **best_params['Class 0 Recall']['Logistic Regression (baseline)']['best_params']))\n",
        "        ]),\n",
        "        \"LGBM (baseline for Class 0 Recall)\": Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', LGBMClassifier(random_state=42, **best_params['Class 0 Recall']['LGBM (baseline)']['best_params'], force_row_wise=True))\n",
        "        ]),\n",
        "        \"Random Forest (class_weight_balanced for Class 0 Recall)\": Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced', **best_params['Class 0 Recall']['Random Forest (class_weight_balanced)']['best_params']))\n",
        "        ]),\n",
        "        \"LGBM (RandomUnderSampler)\": ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', RandomUnderSampler()),\n",
        "            ('classifier', LGBMClassifier(random_state=42, **best_params['Class 0 Precision']['LGBM (RandomUnderSampler)']['best_params'], force_row_wise=True))\n",
        "        ]),\n",
        "        \"HistGradientBoosting (RandomUnderSampler)\": ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', RandomUnderSampler()),\n",
        "            ('classifier', HistGradientBoostingClassifier(random_state=42, **best_params['Class 0 Precision']['HistGradientBoosting (RandomUnderSampler)']['best_params']))\n",
        "        ]),\n",
        "        \"Random Forest (RandomUnderSampler)\": ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', RandomUnderSampler()),\n",
        "            ('classifier', RandomForestClassifier(random_state=42, **best_params['Class 0 Precision']['Random Forest (RandomUnderSampler)']['best_params']))\n",
        "        ])\n",
        "    }\n",
        "    return models\n",
        "\n",
        "# Train and evaluate classifiers\n",
        "def save_results(results, filename):\n",
        "    # Strip 'optimal_model_params_thresholds_' and '.json' from the filename\n",
        "    method_name = filename.replace('optimal_model_params_thresholds_', '').replace('.json', '')\n",
        "    results_filename = f'voting_stacking_results_{method_name}.json'\n",
        "\n",
        "    # Save the results to a JSON file\n",
        "    with open(results_filename, 'w') as file:\n",
        "        json.dump(results, file, indent=4)\n",
        "\n",
        "# Function to predict with a custom threshold\n",
        "def predict_with_threshold(model, X, threshold=0.5):\n",
        "    probas = model.predict_proba(X)[:, 1]\n",
        "    return (probas >= threshold).astype(int)\n",
        "\n",
        "def train_and_evaluate_voting_stacking(models, X_train, y_train, X_test, y_test, filename, stacking_threshold=0.5, voting_threshold=0.5):\n",
        "    voting_clf = VotingClassifier(estimators=list(models.items()), voting='soft')\n",
        "    stacking_clf = StackingClassifier(estimators=list(models.items()), final_estimator=LogisticRegression(C=0.01, penalty='l2', solver='liblinear', random_state=42))\n",
        "\n",
        "    # Train the classifiers\n",
        "    voting_clf.fit(X_train, y_train)\n",
        "    stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict with custom thresholds\n",
        "    y_pred_voting = predict_with_threshold(voting_clf, X_test, voting_threshold)\n",
        "    y_pred_stacking = predict_with_threshold(stacking_clf, X_test, stacking_threshold)\n",
        "\n",
        "    # Evaluate performance\n",
        "    print(\"Voting Classifier Performance with Custom Threshold:\")\n",
        "    print(classification_report(y_test, y_pred_voting))\n",
        "\n",
        "    print(\"Stacking Classifier Performance with Custom Threshold:\")\n",
        "    print(classification_report(y_test, y_pred_stacking))\n",
        "\n",
        "    # Prepare results\n",
        "    results = {\n",
        "        'voting': classification_report(y_test, y_pred_voting, output_dict=True),\n",
        "        'stacking': classification_report(y_test, y_pred_stacking, output_dict=True)\n",
        "    }\n",
        "\n",
        "    # Save the results\n",
        "    save_results(results, filename)"
      ],
      "metadata": {
        "id": "nHUZ70DGDHzl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train & Evaluate Classifiers"
      ],
      "metadata": {
        "id": "w0PuWkP2imEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifiers_with_optimal_params(files, X_train, y_train, X_test, y_test):\n",
        "    for filename in files:\n",
        "        # Load optimal parameters and thresholds\n",
        "        with open(filename, 'r') as file:\n",
        "            best_params = json.load(file)\n",
        "\n",
        "        # Define models\n",
        "        models = define_models(best_params)\n",
        "\n",
        "        # Train and evaluate classifiers\n",
        "        train_and_evaluate_voting_stacking(models, X_train, y_train, X_test, y_test, filename, stacking_threshold, voting_threshold)\n",
        "\n",
        "        # Ensure the results file is saved correctly\n",
        "        results_filename = f'voting_stacking_results_{filename.replace(\"optimal_model_params_thresholds_\", \"\").replace(\".json\", \"\")}.json'\n",
        "        print(f'Results saved to {results_filename}')\n",
        "\n",
        "# List of files\n",
        "files = [\n",
        "    'optimal_model_params_thresholds_custom_loss.json',\n",
        "    'optimal_model_params_thresholds_f1.json',\n",
        "    'optimal_model_params_thresholds_grid_search.json',\n",
        "    'optimal_model_params_thresholds_recall.json',\n",
        "    'optimal_model_params_thresholds_roc.json'\n",
        "]\n",
        "\n",
        "# Call the function with the list of files and data\n",
        "train_classifiers_with_optimal_params(files, X_train, y_train, X_test, y_test)\n",
        "\n",
        "#-----------------\n",
        "\n",
        "# # Load optimal parameters and thresholds\n",
        "# filename = 'optimal_model_params_thresholds_f1.json'\n",
        "# with open(filename, 'r') as file:\n",
        "#     best_params = json.load(file)\n",
        "\n",
        "# # define model params\n",
        "# models = define_models(best_params)\n",
        "\n",
        "# train_and_evaluate_voting_stacking(models, X_train, y_train, X_test, y_test, filename, stacking_threshold, voting_threshold)\n",
        "\n",
        "# # Ensure the results file is saved correctly\n",
        "# results_filename = f'voting_stacking_results_{filename.replace(\"optimal_model_params_thresholds_\", \"\").replace(\".json\", \"\")}.json'\n",
        "# print(f'Results saved to {results_filename}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVC9-sl_k8o3",
        "outputId": "dcf6ec2f-be05-4a43-9983-e13e4d663161"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6553\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3262\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6559\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14952, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6549\n",
            "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6534\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6553\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6549\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3255\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Voting Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.63      0.74      4673\n",
            "           1       0.36      0.74      0.49      1327\n",
            "\n",
            "    accuracy                           0.66      6000\n",
            "   macro avg       0.63      0.69      0.61      6000\n",
            "weighted avg       0.78      0.66      0.69      6000\n",
            "\n",
            "Stacking Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      4673\n",
            "           1       0.55      0.52      0.54      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.71      0.70      0.70      6000\n",
            "weighted avg       0.80      0.80      0.80      6000\n",
            "\n",
            "Results saved to voting_stacking_results_custom_loss.json\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6519\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6542\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3261\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14952, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6528\n",
            "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6510\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6538\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6556\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6546\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3257\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 28\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3257\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3257\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Voting Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.64      0.74      4673\n",
            "           1       0.36      0.73      0.49      1327\n",
            "\n",
            "    accuracy                           0.66      6000\n",
            "   macro avg       0.63      0.69      0.62      6000\n",
            "weighted avg       0.78      0.66      0.69      6000\n",
            "\n",
            "Stacking Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      4673\n",
            "           1       0.55      0.52      0.53      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.71      0.70      0.70      6000\n",
            "weighted avg       0.80      0.80      0.80      6000\n",
            "\n",
            "Results saved to voting_stacking_results_f1.json\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6535\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3266\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6536\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14952, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6565\n",
            "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6522\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6562\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6573\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6555\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3260\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3251\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3255\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Voting Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.64      0.74      4673\n",
            "           1       0.37      0.74      0.49      1327\n",
            "\n",
            "    accuracy                           0.66      6000\n",
            "   macro avg       0.63      0.69      0.62      6000\n",
            "weighted avg       0.78      0.66      0.69      6000\n",
            "\n",
            "Stacking Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      4673\n",
            "           1       0.55      0.52      0.54      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.71      0.70      0.71      6000\n",
            "weighted avg       0.80      0.80      0.80      6000\n",
            "\n",
            "Results saved to voting_stacking_results_grid_search.json\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6537\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3261\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6511\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3263\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14952, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6535\n",
            "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6512\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6551\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6523\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6552\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3255\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 28\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3257\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3258\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Voting Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.64      0.74      4673\n",
            "           1       0.37      0.74      0.49      1327\n",
            "\n",
            "    accuracy                           0.66      6000\n",
            "   macro avg       0.63      0.69      0.62      6000\n",
            "weighted avg       0.78      0.66      0.69      6000\n",
            "\n",
            "Stacking Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      4673\n",
            "           1       0.56      0.52      0.54      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.71      0.70      0.71      6000\n",
            "weighted avg       0.80      0.80      0.80      6000\n",
            "\n",
            "Results saved to voting_stacking_results_recall.json\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6544\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3262\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 18691, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 6546\n",
            "[LightGBM] [Info] Number of data points in the train set: 37382, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 18691\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 24000, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221208 -> initscore=-1.258639\n",
            "[LightGBM] [Info] Start training from score -1.258639\n",
            "[LightGBM] [Info] Number of positive: 5309, number of negative: 5309\n",
            "[LightGBM] [Info] Total Bins 3263\n",
            "[LightGBM] [Info] Number of data points in the train set: 10618, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14952, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 6541\n",
            "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6520\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6557\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6554\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 14953, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 6534\n",
            "[LightGBM] [Info] Number of data points in the train set: 29906, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 14952\n",
            "[LightGBM] [Info] Total Bins 3276\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221250 -> initscore=-1.258397\n",
            "[LightGBM] [Info] Start training from score -1.258397\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3269\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3272\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3271\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 14953\n",
            "[LightGBM] [Info] Total Bins 3273\n",
            "[LightGBM] [Info] Number of data points in the train set: 19200, number of used features: 30\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.221198 -> initscore=-1.258699\n",
            "[LightGBM] [Info] Start training from score -1.258699\n",
            "[LightGBM] [Info] Number of positive: 4248, number of negative: 4248\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8496, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3253\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3256\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 4247, number of negative: 4247\n",
            "[LightGBM] [Info] Total Bins 3259\n",
            "[LightGBM] [Info] Number of data points in the train set: 8494, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Voting Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.63      0.74      4673\n",
            "           1       0.36      0.74      0.49      1327\n",
            "\n",
            "    accuracy                           0.66      6000\n",
            "   macro avg       0.63      0.69      0.61      6000\n",
            "weighted avg       0.78      0.66      0.69      6000\n",
            "\n",
            "Stacking Classifier Performance with Custom Threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87      4673\n",
            "           1       0.55      0.51      0.53      1327\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.71      0.70      0.70      6000\n",
            "weighted avg       0.79      0.80      0.80      6000\n",
            "\n",
            "Results saved to voting_stacking_results_roc.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CrDODuRAlMYd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}